{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:29.196238Z",
     "start_time": "2017-11-17T09:03:28.644004Z"
    },
    "_cell_guid": "679e0d3e-646d-4e96-9eb0-b362d8c6e51f",
    "_uuid": "0d05e5ce89af3e25d1c1fb244d021a1cfa1a058c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import array \n",
    "\n",
    "from pydub import AudioSegment\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Conv2D, Flatten, MaxPooling2D, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPool2D, concatenate, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Input, GRU, RepeatVector, BatchNormalization, TimeDistributed, Conv1D\n",
    "from keras import backend as K\n",
    "from keras.layers import  Conv2D, MaxPooling2D, MaxPooling1D,GlobalAveragePooling1D, GlobalMaxPooling1D, UpSampling2D, Lambda, Reshape\n",
    "\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:29.210749Z",
     "start_time": "2017-11-17T09:03:29.19832Z"
    },
    "_cell_guid": "8ab00801-08b9-44d3-a063-32e82dbf8f58",
    "_uuid": "53c19941676690454dd4b91109976b6c59cb7a40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "len(id2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 s, sys: 10.1 s, total: 22.7 s\n",
      "Wall time: 22.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "train_df = pickle.load( open(\"cache/train_df_waug.pik\",\"rb\"))\n",
    "valid_df = pickle.load( open(\"cache/valid_df.pik\",\"rb\"))\n",
    "silent_df = pickle.load(open(\"cache/silent_df.pik\",\"rb\"))\n",
    "unknown_df = pickle.load(open(\"cache/unknown_df_waug.pik\",\"rb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading test data for pseudo labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df =  pickle.load(open(\"cache/test_df.pik\",\"rb\"))\n",
    "\n",
    "test_preds = np.load('cache/predictions_mixtimefreq1ds_plus_conv1dlstm_plus_aebased_conv2d_finetuned.npy')\n",
    "\n",
    "\n",
    "test_df[\"id\"] = test_df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MixIterator(object):\n",
    "    def __init__(self, iters):\n",
    "        self.iters = iters\n",
    "        self.multi = type(iters) is list\n",
    "\n",
    "        self.N = 64 \n",
    "\n",
    "    def reset(self):\n",
    "        for it in self.iters: it.reset()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def next(self, *args, **kwargs):\n",
    "\n",
    "        nexts = [next(it) for it in self.iters]\n",
    "        n0 = np.concatenate([n[0] for n in nexts])\n",
    "        n1 = np.concatenate([n[1] for n in nexts])\n",
    "        return (n0, n1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:32.519795Z",
     "start_time": "2017-11-17T09:03:32.483881Z"
    },
    "_cell_guid": "144c6e60-8a83-437d-8b8a-ea065af90923",
    "_uuid": "22e0e6c718171167089fb6df36d3dc43a1029992"
   },
   "outputs": [],
   "source": [
    "#no augmentation since the auto encoder has already seen all the train AND test files \n",
    "\n",
    "def train_generator(train_batch_size):\n",
    "    while True:\n",
    "        \n",
    "        this_train = train_df.groupby('label_id').apply(lambda x: x.sample(n = 2000))\n",
    "        extra_data_size = int(this_train.shape[0]* 0.1)\n",
    "        this_train = pd.concat([silent_df.sample(extra_data_size),\n",
    "                                this_train],axis=0 )\n",
    "#         ,\n",
    "#                                 unknown_df.sample(extra_data_size*4)\n",
    "        this_train.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "        shuffled_ids = random.sample(range(this_train.shape[0]), this_train.shape[0])\n",
    "        \n",
    "        for start in range(0, len(shuffled_ids), train_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            end = min(start + train_batch_size, len(shuffled_ids))\n",
    "            i_train_batch = shuffled_ids[start:end]\n",
    "            for i in i_train_batch:\n",
    "                x_batch.append(this_train.loc[i,'raw'].T)\n",
    "#                 x_batch.append(process_wav_file(this_train.iloc[i], augment=True).T)\n",
    "\n",
    "                y_batch.append(this_train.label_id.values[i])\n",
    "                \n",
    "            x_batch = 1.- np.array(x_batch)/-80.\n",
    "            y_batch = to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            \n",
    "            yield x_batch, y_batch\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 8, 9],\n",
       "       [4, 5, 6],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2,3],[4,5,6],[7,8,9]])[::-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_df.reset_index().loc[0,'raw'].T[::-1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unknown_generator(train_batch_size):\n",
    "    while True:\n",
    "        \n",
    "        this_train = unknown_df.sample(n = int(train_df.shape[0]* 0.4))\n",
    "\n",
    "        this_train.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "        shuffled_ids = random.sample(range(this_train.shape[0]), this_train.shape[0])\n",
    "        \n",
    "        for start in range(0, len(shuffled_ids), train_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            end = min(start + train_batch_size, len(shuffled_ids))\n",
    "            i_train_batch = shuffled_ids[start:end]\n",
    "            for i in i_train_batch:\n",
    "                val  = this_train.loc[i,'raw'].T \n",
    "                val  = val if np.random.random()<0.5 else val[::-1,:]\n",
    "                x_batch.append(val)\n",
    "#                 x_batch.append(process_wav_file(this_train.iloc[i], augment=True).T)\n",
    "\n",
    "                y_batch.append(this_train.label_id.values[i])\n",
    "                \n",
    "            x_batch = 1.- np.array(x_batch)/-80.\n",
    "            y_batch = to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            \n",
    "            yield x_batch, y_batch\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pseudo_generator(test_batch_size):\n",
    "#     this_test = test_df #.sample(int(train_df.shape[0]//5* 0.1))\n",
    "#     this_test[\"id\"] = this_test.index.values\n",
    "    \n",
    "#     this_test.reset_index(inplace=True)\n",
    "    while True:\n",
    "\n",
    "        shuffled_ids = random.sample(range(test_df.shape[0]), test_df.shape[0])\n",
    "\n",
    "        for start in range(0, len(test_df), test_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "\n",
    "            end = min(start + test_batch_size, len(shuffled_ids))\n",
    "            i_test_batch = shuffled_ids[start:end]\n",
    "\n",
    "            for i in i_test_batch:\n",
    "                x_batch.append(test_df.loc[i,'raw'].T)\n",
    "    #                 x_batch.append(process_wav_file(this_train.iloc[i], augment=True).T)\n",
    "\n",
    "                y_batch.append(test_preds[test_df.loc[i,'id']])\n",
    "\n",
    "            x_batch = 1.- np.array(x_batch)/-80.\n",
    "            y_batch = np.array(y_batch)\n",
    "\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = MixIterator([train_generator(30),unknown_generator(20), test_pseudo_generator(14)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 60 ms, sys: 8 ms, total: 68 ms\n",
      "Wall time: 69.5 ms\n"
     ]
    }
   ],
   "source": [
    "%time t = next(train_generator(256))[0][0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:32.624289Z",
     "start_time": "2017-11-17T09:03:32.521828Z"
    },
    "_cell_guid": "59a13393-9bc3-4b27-abe2-9c78b3c32ead",
    "_uuid": "6f9a8fbf6e352b1c77b9c22dddf1c5d69382bd5b"
   },
   "outputs": [],
   "source": [
    "def valid_generator(val_batch_size):\n",
    "    while True:\n",
    "        ids = list(range(valid_df.shape[0]))\n",
    "        for start in range(0, len(ids), val_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + val_batch_size, len(ids))\n",
    "            i_val_batch = ids[start:end]\n",
    "            for i in i_val_batch:\n",
    "                x_batch.append(valid_df.loc[i,'raw'].T)\n",
    "                y_batch.append(valid_df.label_id.values[i])\n",
    "\n",
    "            x_batch = 1.- np.array(x_batch)/-80.\n",
    "            y_batch = to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a common practice is to choose a filter size in time which spans 2/3 o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps, input_dim , latent_dim = 32,128, 128\n",
    "\n",
    "input_img = Input(shape=(timesteps, input_dim))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Reshape((timesteps, input_dim,1))(input_img)\n",
    "\n",
    "x = Conv2D(64, (10, 10), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (5, 5), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same',name='latent_rep')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (5, 5), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (10, 10), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "decoded  = Reshape((timesteps, input_dim))(decoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights(\"./weights/starter_ae_wtest_conv_rmse_c6.hdf5\")\n",
    "\n",
    "for l in autoencoder.layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.3\n",
    "\n",
    "x = BatchNormalization()(autoencoder.get_layer(\"latent_rep\").output)\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p/2)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p/2)(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p/2)(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p/2)(x)\n",
    "\n",
    "x_max = GlobalMaxPool2D()(x)\n",
    "x_avg = GlobalAveragePooling2D()(x)\n",
    "\n",
    "ae_model =  x_max #concatenate([x_max,x_avg])\n",
    "\n",
    "\n",
    "# x = Dense(128, activation = 'relu')(x)\n",
    "# x = Dropout(p)(x)\n",
    "\n",
    "# x = Dense(len(POSSIBLE_LABELS), activation = 'softmax', name='targets')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_stacks( x_in, filter_size=2):\n",
    "    \n",
    "    x = BatchNormalization()(x_in)\n",
    "    x = Conv1D(32,filter_size,activation='relu')(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "    x = Conv1D(32,filter_size,activation='relu')(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "\n",
    "\n",
    "\n",
    "#     x = LSTM(128,return_sequences=True)(x)\n",
    "\n",
    "    x = Conv1D(64,filter_size,activation='relu',dilation_rate=2)(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "    x = Conv1D(64,filter_size,activation='relu',dilation_rate=2)(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "#     x = LSTM(128,return_sequences=True)(x)\n",
    "\n",
    "    x = Conv1D(128,filter_size,activation='relu',dilation_rate=2)(x)\n",
    "    x = Dropout(p/2)(x)    \n",
    "    x = Conv1D(128,filter_size,activation='relu',dilation_rate=2)(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "    x = Conv1D(128,filter_size,activation='relu',dilation_rate=2)(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "    x = Conv1D(128,filter_size,activation='relu',dilation_rate=2)(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "\n",
    "    x_max = GlobalMaxPooling1D()(x)\n",
    "    x_avg = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x = concatenate([x_max,x_avg])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1dconvs_maxpool( x_in, filter_size=2):\n",
    "    \n",
    "    x = BatchNormalization()(x_in)\n",
    "    x = Conv1D(64,filter_size,activation='relu',padding='same')(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "    x = Conv1D(64,filter_size,activation='relu',padding='same')(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "    x = Conv1D(64,filter_size,activation='relu',padding='same')(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "\n",
    "    x  = MaxPooling1D()(x)   \n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "\n",
    "    x = Conv1D(128,filter_size,activation='relu',padding='same')(x)\n",
    "    x = Dropout(p/2)(x)    \n",
    "    x = Conv1D(128,filter_size,activation='relu',padding='same')(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "    x = Conv1D(128,filter_size,activation='relu',padding='same')(x)\n",
    "    x = Dropout(p/2)(x)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    \n",
    "    \n",
    "    x_max = GlobalMaxPooling1D()(x)\n",
    "#     x_avg = GlobalAveragePooling1D()(x)\n",
    "\n",
    "#     x = concatenate([x_max,x_avg])\n",
    "    \n",
    "    return x_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps, input_dim , latent_dim = 32,128, 128\n",
    "\n",
    "\n",
    "\n",
    "x_3 = get_1dconvs_maxpool(input_img,10)\n",
    "x_2 = get_1dconvs_maxpool(input_img,5)\n",
    "x_1 = get_1dconvs_maxpool(input_img,2)\n",
    "\n",
    "x = concatenate([x_1,x_2,x_3,\n",
    "                 ae_model])\n",
    "\n",
    "#original \n",
    "# x_2 = get_conv_stacks(input_img,2)\n",
    "# x_3 = get_conv_stacks(input_img,3)\n",
    "\n",
    "\n",
    "\n",
    "# x_freq = Reshape((input_dim, timesteps))(input_img)\n",
    "# xf_8 = get_conv_stacks(x_freq,8)\n",
    "\n",
    "\n",
    "# x = concatenate([x_2,x_3,\n",
    "#                  xf_8,ae_model])\n",
    "\n",
    "\n",
    "\n",
    "x = Dense(128, activation = 'relu')(x) #\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "\n",
    "x = Dense(len(POSSIBLE_LABELS), activation = 'softmax', name='targets')(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Model(inputs=[input_img], outputs = x)\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:33.180074Z",
     "start_time": "2017-11-17T09:03:32.625939Z"
    },
    "_cell_guid": "0e13c01e-5662-4679-9b31-bf9347080ae5",
    "_uuid": "a17b3ea5c15c781260f3473f37dd0d36a932a565"
   },
   "outputs": [],
   "source": [
    "# p = 0.5\n",
    "\n",
    "# x_in = Input(shape = (128,32,1)) #1 channel, 99 time, 161 freqs # S : np.ndarray [shape=(n_mels, t)]\n",
    "\n",
    "# x = BatchNormalization()(x_in)\n",
    "\n",
    "# x = Conv2D(64, (9,10),activation='relu',padding='same')(x)\n",
    "# x = Dropout(p)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = MaxPooling2D((3,2),padding='same')(x)\n",
    "\n",
    "# x = Conv2D(128, (4,5),activation='relu',padding='same')(x)\n",
    "# x = Dropout(p)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = MaxPooling2D((3,2),padding='same')(x)\n",
    "\n",
    "\n",
    "# x = Conv2D(128, (2,2),activation='relu',padding='same')(x)\n",
    "# x = Dropout(p)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = MaxPooling2D(padding='same')(x)\n",
    "\n",
    "\n",
    "\n",
    "# x = GlobalMaxPool2D()(x)\n",
    "\n",
    "# # x = Flatten()(x)\n",
    "# x = Dense(64, activation = 'relu')(x) #\n",
    "# x = Dropout(p)(x)\n",
    "\n",
    "# # x = Dense(64, activation = 'relu')(x)\n",
    "# # x = Dropout(0.3)(x)\n",
    "\n",
    "# x = Dense(len(POSSIBLE_LABELS), activation = 'softmax', name='targets')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = Model(inputs = x_in, outputs = x)\n",
    "# model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# # model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 14/100\n",
    "300/300 [==============================] - 214s - loss: 0.7612 - acc: 0.7370 - val_loss: 1.0481 - val_acc: 0.6508\n",
    "\n",
    "\n",
    "\n",
    "Epoch 31/100\n",
    "350/350 [==============================] - 227s - loss: 0.4294 - acc: 0.8518 - val_loss: 0.9436 - val_acc: 0.7179\n",
    "Epoch 32/100\n",
    "\n",
    "\n",
    "\n",
    "Epoch 00058: reducing learning rate to 1.00000006569e-06.\n",
    "329/329 [==============================] - 191s - loss: 0.7292 - acc: 0.7521 - val_loss: 0.7132 - val_acc: 0.8770\n",
    "\n",
    "\n",
    "with ae, p=0.\n",
    "Epoch 28/100\n",
    "329/329 [==============================] - 7s - loss: 0.3312 - acc: 0.8829 - val_loss: 0.4124 - val_acc: 0.8579\n",
    "\n",
    "with p=0.4 and /2 for convs \n",
    "Epoch 28/100\n",
    "329/329 [==============================] - 7s - loss: 0.5534 - acc: 0.8056 - val_loss: 0.5074 - val_acc: 0.8312\n",
    "\n",
    "with p=0.2 and /2\n",
    "Epoch 00035: reducing learning rate to 1.0000000475e-05.\n",
    "329/329 [==============================] - 7s - loss: 0.2414 - acc: 0.9137 - val_loss: 0.3686 - val_acc: 0.8811\n",
    "\n",
    "\n",
    "original aebased p.3\n",
    "frozen:\n",
    "Epoch 19/100\n",
    "989/989 [==============================] - 37s - loss: 0.4131 - acc: 0.8549 - val_loss: 0.3392 - val_acc: 0.8849\n",
    "with finetuning\n",
    "Epoch 5/100\n",
    "989/989 [==============================] - 85s - loss: 0.3845 - acc: 0.8654 - val_loss: 0.3238 - val_acc: 0.8920\n",
    "\n",
    "increase filter size, less max, more layers (aebase_aug_drp3_frozen_extralayers)\n",
    "Epoch 10/100\n",
    "1978/1978 [==============================] - 64s - loss: 0.2238 - acc: 0.9242 - val_loss: 0.2565 - val_acc: 0.9253\n",
    "\n",
    "\n",
    "\n",
    "-- time and frequency 1dconvs (v1) with frozen ae base (aebase_mix_1dconvs_on_timenfreq_frozen_c2)\n",
    "\n",
    "Epoch 10/100\n",
    "1978/1978 [==============================] - 193s - loss: 0.1665 - acc: 0.9453 - val_loss: 0.1689 - val_acc: 0.9511\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-- aebase_mix_1dtimeconvswithmaxpool_frozen\n",
    "\n",
    "Epoch 32/100\n",
    "395/395 [==============================] - 34s - loss: 0.2949 - acc: 0.9321 - val_loss: 0.1594 - val_acc: 0.9475\n",
    "\n",
    "finetuned\n",
    "Epoch 8/100\n",
    "395/395 [==============================] - 46s - loss: 0.2926 - acc: 0.9302 - val_loss: 0.1564 - val_acc: 0.9501\n",
    "\n",
    "\n",
    "reverse unknown \n",
    "Epoch 36/100\n",
    "395/395 [==============================] - 34s - loss: 0.2846 - acc: 0.9346 - val_loss: 0.1558 - val_acc: 0.9481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"aebase_mix_1dtimeconvswithmaxpool_reverseunknown_frozen\"\n",
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=5,\n",
    "                           verbose=1),\n",
    "             \n",
    "             ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               epsilon=0.01,\n",
    "                              min_lr=1e-5),\n",
    "             ModelCheckpoint(monitor='val_loss',\n",
    "                             filepath='weights/{}.hdf5'.format(exp_name),\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True)]\n",
    "#              ,      TensorBoard(log_dir='./logs/logs_{}'.format(exp_name), histogram_freq=0, batch_size=64, write_graph=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('weights/{}.hdf5'.format(exp_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:42:31.48233Z",
     "start_time": "2017-11-17T09:03:33.355603Z"
    },
    "_cell_guid": "5f3d1b09-500f-410e-820a-8eaab24b6ebb",
    "_uuid": "528ec66a0a6caca952273ab916e609625839b19e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "395/395 [==============================] - 42s - loss: 1.6934 - acc: 0.5021 - val_loss: 1.1513 - val_acc: 0.5755\n",
      "Epoch 2/100\n",
      "395/395 [==============================] - 35s - loss: 0.9702 - acc: 0.6893 - val_loss: 0.7820 - val_acc: 0.7380\n",
      "Epoch 3/100\n",
      "395/395 [==============================] - 35s - loss: 0.7460 - acc: 0.7734 - val_loss: 0.4675 - val_acc: 0.8540\n",
      "Epoch 4/100\n",
      "395/395 [==============================] - 35s - loss: 0.6554 - acc: 0.8094 - val_loss: 0.4192 - val_acc: 0.8616\n",
      "Epoch 5/100\n",
      "395/395 [==============================] - 36s - loss: 0.5843 - acc: 0.8325 - val_loss: 0.3895 - val_acc: 0.8834\n",
      "Epoch 6/100\n",
      "395/395 [==============================] - 35s - loss: 0.5483 - acc: 0.8476 - val_loss: 0.3620 - val_acc: 0.8834\n",
      "Epoch 7/100\n",
      "395/395 [==============================] - 36s - loss: 0.5066 - acc: 0.8614 - val_loss: 0.2906 - val_acc: 0.9032\n",
      "Epoch 8/100\n",
      "395/395 [==============================] - 35s - loss: 0.4948 - acc: 0.8652 - val_loss: 0.2901 - val_acc: 0.9078\n",
      "Epoch 9/100\n",
      "395/395 [==============================] - 36s - loss: 0.4682 - acc: 0.8776 - val_loss: 0.2710 - val_acc: 0.9138\n",
      "Epoch 10/100\n",
      "395/395 [==============================] - 35s - loss: 0.4488 - acc: 0.8789 - val_loss: 0.2414 - val_acc: 0.9240\n",
      "Epoch 11/100\n",
      "395/395 [==============================] - 34s - loss: 0.4307 - acc: 0.8884 - val_loss: 0.2562 - val_acc: 0.9174\n",
      "Epoch 12/100\n",
      "395/395 [==============================] - 34s - loss: 0.4235 - acc: 0.8896 - val_loss: 0.2322 - val_acc: 0.9243\n",
      "Epoch 13/100\n",
      "395/395 [==============================] - 34s - loss: 0.4208 - acc: 0.8919 - val_loss: 0.2648 - val_acc: 0.9184\n",
      "Epoch 14/100\n",
      "395/395 [==============================] - 35s - loss: 0.3905 - acc: 0.8999 - val_loss: 0.2246 - val_acc: 0.9286\n",
      "Epoch 15/100\n",
      "395/395 [==============================] - 34s - loss: 0.3950 - acc: 0.8979 - val_loss: 0.2300 - val_acc: 0.9286\n",
      "Epoch 16/100\n",
      "395/395 [==============================] - 36s - loss: 0.3834 - acc: 0.9034 - val_loss: 0.2162 - val_acc: 0.9313\n",
      "Epoch 17/100\n",
      "395/395 [==============================] - 34s - loss: 0.3680 - acc: 0.9084 - val_loss: 0.2218 - val_acc: 0.9286\n",
      "Epoch 18/100\n",
      "394/395 [============================>.] - ETA: 0s - loss: 0.3754 - acc: 0.9078\n",
      "Epoch 00017: reducing learning rate to 0.00010000000475.\n",
      "395/395 [==============================] - 35s - loss: 0.3750 - acc: 0.9079 - val_loss: 0.2273 - val_acc: 0.9267\n",
      "Epoch 19/100\n",
      "395/395 [==============================] - 34s - loss: 0.3370 - acc: 0.9166 - val_loss: 0.1801 - val_acc: 0.9382\n",
      "Epoch 20/100\n",
      "395/395 [==============================] - 34s - loss: 0.3216 - acc: 0.9231 - val_loss: 0.1704 - val_acc: 0.9422\n",
      "Epoch 21/100\n",
      "395/395 [==============================] - 34s - loss: 0.3038 - acc: 0.9281 - val_loss: 0.1733 - val_acc: 0.9419\n",
      "Epoch 22/100\n",
      "395/395 [==============================] - 34s - loss: 0.3030 - acc: 0.9272 - val_loss: 0.1725 - val_acc: 0.9419\n",
      "Epoch 23/100\n",
      "395/395 [==============================] - 34s - loss: 0.3020 - acc: 0.9298 - val_loss: 0.1696 - val_acc: 0.9442\n",
      "Epoch 24/100\n",
      "395/395 [==============================] - 34s - loss: 0.3023 - acc: 0.9285 - val_loss: 0.1663 - val_acc: 0.9432\n",
      "Epoch 25/100\n",
      "395/395 [==============================] - 34s - loss: 0.3015 - acc: 0.9290 - val_loss: 0.1664 - val_acc: 0.9448\n",
      "Epoch 26/100\n",
      "395/395 [==============================] - 34s - loss: 0.2911 - acc: 0.9313 - val_loss: 0.1660 - val_acc: 0.9445\n",
      "Epoch 27/100\n",
      "394/395 [============================>.] - ETA: 0s - loss: 0.3030 - acc: 0.9283\n",
      "Epoch 00026: reducing learning rate to 1.0000000475e-05.\n",
      "395/395 [==============================] - 34s - loss: 0.3029 - acc: 0.9284 - val_loss: 0.1666 - val_acc: 0.9445\n",
      "Epoch 28/100\n",
      "395/395 [==============================] - 34s - loss: 0.2914 - acc: 0.9337 - val_loss: 0.1638 - val_acc: 0.9452\n",
      "Epoch 29/100\n",
      "395/395 [==============================] - 35s - loss: 0.2861 - acc: 0.9335 - val_loss: 0.1634 - val_acc: 0.9462\n",
      "Epoch 30/100\n",
      "395/395 [==============================] - 35s - loss: 0.2966 - acc: 0.9312 - val_loss: 0.1627 - val_acc: 0.9452\n",
      "Epoch 31/100\n",
      "395/395 [==============================] - 35s - loss: 0.2911 - acc: 0.9337 - val_loss: 0.1580 - val_acc: 0.9471\n",
      "Epoch 32/100\n",
      "395/395 [==============================] - 34s - loss: 0.2921 - acc: 0.9321 - val_loss: 0.1569 - val_acc: 0.9478\n",
      "Epoch 33/100\n",
      "395/395 [==============================] - 34s - loss: 0.2771 - acc: 0.9353 - val_loss: 0.1653 - val_acc: 0.9442\n",
      "Epoch 34/100\n",
      "395/395 [==============================] - 34s - loss: 0.2924 - acc: 0.9330 - val_loss: 0.1632 - val_acc: 0.9448\n",
      "Epoch 35/100\n",
      "395/395 [==============================] - 34s - loss: 0.2866 - acc: 0.9331 - val_loss: 0.1625 - val_acc: 0.9455\n",
      "Epoch 36/100\n",
      "395/395 [==============================] - 34s - loss: 0.2846 - acc: 0.9346 - val_loss: 0.1558 - val_acc: 0.9481\n",
      "Epoch 37/100\n",
      "395/395 [==============================] - 34s - loss: 0.2861 - acc: 0.9339 - val_loss: 0.1620 - val_acc: 0.9465\n",
      "Epoch 38/100\n",
      "395/395 [==============================] - 35s - loss: 0.2859 - acc: 0.9346 - val_loss: 0.1592 - val_acc: 0.9468\n",
      "Epoch 39/100\n",
      "395/395 [==============================] - 36s - loss: 0.2943 - acc: 0.9343 - val_loss: 0.1607 - val_acc: 0.9452\n",
      "Epoch 40/100\n",
      "395/395 [==============================] - 35s - loss: 0.2824 - acc: 0.9356 - val_loss: 0.1595 - val_acc: 0.9462\n",
      "Epoch 41/100\n",
      "395/395 [==============================] - 35s - loss: 0.2879 - acc: 0.9338 - val_loss: 0.1567 - val_acc: 0.9471\n",
      "Epoch 42/100\n",
      "395/395 [==============================] - 34s - loss: 0.2844 - acc: 0.9362 - val_loss: 0.1586 - val_acc: 0.9468\n",
      "Epoch 00041: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "history = model.fit_generator(generator=mi,#train_generator(batch_size),\n",
    "                              steps_per_epoch=train_df.shape[0]*(1.2/5)//batch_size,\n",
    "                              epochs=100,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=valid_generator(batch_size),\n",
    "                              validation_steps=int(np.ceil(valid_df.shape[0]/batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.layers:\n",
    "    l.trainable = True\n",
    "    \n",
    "    \n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:24:59.198625Z",
     "start_time": "2017-11-17T10:24:59.081762Z"
    },
    "_cell_guid": "0c99ba3b-e8ca-40cb-8d29-2b0e89a385c7",
    "_uuid": "429139ca4f71487c6cfe3e8dfbb6a659eb9bb9c8"
   },
   "outputs": [],
   "source": [
    "model.load_weights('./weights/{}.hdf5'.format(exp_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"aebase_mix_1dtimeconvswithmaxpool_reverseunknown_finetune\"\n",
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=5,\n",
    "                           verbose=1),\n",
    "             \n",
    "             ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               epsilon=0.01,\n",
    "                              min_lr=1e-5),\n",
    "             ModelCheckpoint(monitor='val_loss',\n",
    "                             filepath='weights/{}.hdf5'.format(exp_name),\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "395/395 [==============================] - 50s - loss: 0.2963 - acc: 0.9299 - val_loss: 0.1657 - val_acc: 0.9447\n",
      "Epoch 2/100\n",
      "395/395 [==============================] - 48s - loss: 0.2931 - acc: 0.9322 - val_loss: 0.1603 - val_acc: 0.9462\n",
      "Epoch 3/100\n",
      "395/395 [==============================] - 47s - loss: 0.2900 - acc: 0.9343 - val_loss: 0.1630 - val_acc: 0.9455\n",
      "Epoch 4/100\n",
      "395/395 [==============================] - 47s - loss: 0.2891 - acc: 0.9341 - val_loss: 0.1620 - val_acc: 0.9435\n",
      "Epoch 5/100\n",
      "394/395 [============================>.] - ETA: 0s - loss: 0.2944 - acc: 0.9325\n",
      "Epoch 00004: reducing learning rate to 1e-05.\n",
      "395/395 [==============================] - 48s - loss: 0.2941 - acc: 0.9326 - val_loss: 0.1601 - val_acc: 0.9491\n",
      "Epoch 6/100\n",
      "395/395 [==============================] - 47s - loss: 0.2854 - acc: 0.9356 - val_loss: 0.1585 - val_acc: 0.9488\n",
      "Epoch 7/100\n",
      "395/395 [==============================] - 48s - loss: 0.2818 - acc: 0.9363 - val_loss: 0.1571 - val_acc: 0.9491\n",
      "Epoch 8/100\n",
      "395/395 [==============================] - 47s - loss: 0.2828 - acc: 0.9386 - val_loss: 0.1574 - val_acc: 0.9491\n",
      "Epoch 9/100\n",
      "395/395 [==============================] - 47s - loss: 0.2783 - acc: 0.9368 - val_loss: 0.1569 - val_acc: 0.9501\n",
      "Epoch 10/100\n",
      "395/395 [==============================] - 47s - loss: 0.2814 - acc: 0.9360 - val_loss: 0.1575 - val_acc: 0.9498\n",
      "Epoch 11/100\n",
      "395/395 [==============================] - 47s - loss: 0.2841 - acc: 0.9346 - val_loss: 0.1592 - val_acc: 0.9501\n",
      "Epoch 12/100\n",
      "395/395 [==============================] - 47s - loss: 0.2755 - acc: 0.9391 - val_loss: 0.1586 - val_acc: 0.9488\n",
      "Epoch 13/100\n",
      "395/395 [==============================] - 47s - loss: 0.2843 - acc: 0.9339 - val_loss: 0.1585 - val_acc: 0.9498\n",
      "Epoch 14/100\n",
      "395/395 [==============================] - 47s - loss: 0.2808 - acc: 0.9359 - val_loss: 0.1553 - val_acc: 0.9508\n",
      "Epoch 15/100\n",
      "395/395 [==============================] - 47s - loss: 0.2814 - acc: 0.9366 - val_loss: 0.1564 - val_acc: 0.9498\n",
      "Epoch 16/100\n",
      "395/395 [==============================] - 48s - loss: 0.2823 - acc: 0.9360 - val_loss: 0.1549 - val_acc: 0.9518\n",
      "Epoch 17/100\n",
      "395/395 [==============================] - 47s - loss: 0.2795 - acc: 0.9368 - val_loss: 0.1556 - val_acc: 0.9501\n",
      "Epoch 18/100\n",
      "395/395 [==============================] - 48s - loss: 0.2792 - acc: 0.9348 - val_loss: 0.1569 - val_acc: 0.9495\n",
      "Epoch 19/100\n",
      "395/395 [==============================] - 47s - loss: 0.2797 - acc: 0.9380 - val_loss: 0.1582 - val_acc: 0.9488\n",
      "Epoch 20/100\n",
      "395/395 [==============================] - 47s - loss: 0.2808 - acc: 0.9365 - val_loss: 0.1554 - val_acc: 0.9504\n",
      "Epoch 21/100\n",
      "395/395 [==============================] - 47s - loss: 0.2818 - acc: 0.9350 - val_loss: 0.1571 - val_acc: 0.9485\n",
      "Epoch 22/100\n",
      "395/395 [==============================] - 47s - loss: 0.2783 - acc: 0.9369 - val_loss: 0.1596 - val_acc: 0.9488\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=mi, #train_generator(batch_size),\n",
    "                              steps_per_epoch=train_df.shape[0]*(1.2/5)//batch_size,\n",
    "                              epochs=100,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=valid_generator(batch_size),\n",
    "                              validation_steps=int(np.ceil(valid_df.shape[0]/batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./weights/{}.hdf5'.format(exp_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### valid evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def augment_wav(wav,pval=0.5):\n",
    "    sample_rate = 16000\n",
    "    L = 1000 #16000  # 1 sec\n",
    "    \n",
    "    #adjust speed, with 50% chance\n",
    "#     wav = speed_change(wav,1.+random.uniform(-1, 1)*0.05) if np.random.random() < pval else wav\n",
    "    \n",
    "    \n",
    "    #adjust volume\n",
    "    db_adjustment = random.uniform(-1, 1)*10\n",
    "    wav = wav + db_adjustment if np.random.random() < pval else wav\n",
    "     \n",
    "        \n",
    "    #fill to 1 second\n",
    "    wav = fill_to_1sec(wav)        \n",
    "        \n",
    "    #shift the audio by 10 ms\n",
    "    shift_length = 100\n",
    "    if np.random.random() < 0.5: #shift to left\n",
    "        wav = wav[:L-shift_length]+ AudioSegment.silent(shift_length,frame_rate=sample_rate)\n",
    "    else: #shift to right\n",
    "        wav = AudioSegment.silent(shift_length,frame_rate=sample_rate) + wav[shift_length:]\n",
    "        \n",
    "        \n",
    "        \n",
    "    #blend original file with background noise     \n",
    "    if np.random.random() < pval:\n",
    "        noise = random.choice(silence_files_AS)\n",
    "        db_delta = (wav.dBFS - noise.dBFS) -10.\n",
    "\n",
    "        if db_delta< 0: #reduce intensity of loud background; if it's too silent, leave it be\n",
    "            noise = noise  + db_delta\n",
    "        wav = wav.overlay(noise)\n",
    " \n",
    "    return wav\n",
    "\n",
    "\n",
    "\n",
    "def process_wav_file(record, reshape=False, augment=False,pval=0.5 ,output_format='logmel',n_mels=128 ):\n",
    "    \n",
    "    if type(record) == str: # test files\n",
    "        fname = record\n",
    "        label = \"test\"\n",
    "    else:    \n",
    "        fname  = record.wav_file\n",
    "        label = record.label\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    if \"raw_AS_wav\" in record: \n",
    "        wav = record.raw_AS_wav\n",
    "    else:\n",
    "        wav = AudioSegment.from_wav(fname.replace(\"\\\\\",\"/\"))\n",
    "        \n",
    "        \n",
    "    \n",
    "    if (not label in [\"silence\"]) and augment: #no augmentation for sample files \n",
    "        wav = augment_wav(wav,pval)\n",
    "\n",
    "    else: #make sure segment is 1 second\n",
    "        wav = fill_to_1sec(wav)\n",
    "\n",
    "        \n",
    "    samples = AS_to_raw(wav)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if output_format == \"logmel\":\n",
    "        output = log_mel(samples,reshape=reshape,n_mels=n_mels)\n",
    "        \n",
    "    elif output_format == \"mfcc\":\n",
    "        log_S = log_mel(samples,reshape=False,n_mels=n_mels)\n",
    "        mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=40) #hirese mfcc\n",
    "        delta1 = librosa.feature.delta(mfcc, order=1)#hirese mfcc\n",
    "        delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "        output = np.stack([mfcc,delta1,delta2])\n",
    "        \n",
    "    elif  output_format == \"cqt\":   \n",
    "        output = librosa.cqt(samples, sr=16000)\n",
    "    else:\n",
    "        output = samples\n",
    "    \n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_aug_generator(val_batch_size):\n",
    "    while True:\n",
    "        ids = list(range(valid_df.shape[0]))\n",
    "        for start in range(0, len(ids), val_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + val_batch_size, len(ids))\n",
    "            i_val_batch = ids[start:end]\n",
    "            for i in i_val_batch:\n",
    "                x_batch.append(process_wav_file(valid_df.iloc[i],augment=True).T)\n",
    "                y_batch.append(valid_df.label_id.values[i])\n",
    "\n",
    "            x_batch = 1.- np.array(x_batch)/-80.\n",
    "            y_batch = to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "silence_files_AS = [AudioSegment.from_wav(x) for x in silent_df.wav_file.values]\n",
    "\n",
    "filler = AudioSegment.silent(duration=1000, frame_rate = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict_generator(valid_generator(64),steps=int(np.ceil(valid_df.shape[0]/64.)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds += model.predict_generator(valid_aug_generator(64),steps=int(np.ceil(valid_df.shape[0]/64.)))\n",
    "val_preds += model.predict_generator(valid_aug_generator(64),steps=int(np.ceil(valid_df.shape[0]/64.)))\n",
    "val_preds += model.predict_generator(valid_aug_generator(64),steps=int(np.ceil(valid_df.shape[0]/64.)))\n",
    "val_preds += model.predict_generator(valid_aug_generator(64),steps=int(np.ceil(valid_df.shape[0]/64.)))\n",
    "val_preds += model.predict_generator(valid_aug_generator(64),steps=int(np.ceil(valid_df.shape[0]/64.)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds/=6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = np.argmax(val_preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3091,)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = oe.fit_transform(valid_df.label_id.values.reshape(-1, 1)).todense()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = oe.transform(val_preds.reshape(-1, 1)).todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.99      0.94      0.97       261\n",
      "         no       0.91      0.93      0.92       270\n",
      "         up       0.91      0.93      0.92       260\n",
      "       down       0.98      0.92      0.95       264\n",
      "       left       0.96      0.99      0.97       247\n",
      "      right       0.98      0.95      0.97       256\n",
      "         on       0.98      0.93      0.96       257\n",
      "        off       0.93      0.93      0.93       256\n",
      "       stop       0.99      0.93      0.96       246\n",
      "         go       0.96      0.87      0.91       260\n",
      "    silence       0.98      1.00      0.99       257\n",
      "    unknown       0.76      0.95      0.85       257\n",
      "\n",
      "avg / total       0.94      0.94      0.94      3091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       1.00      0.96      0.98       261\n",
      "         no       0.92      0.95      0.94       270\n",
      "         up       0.93      0.96      0.94       260\n",
      "       down       0.98      0.94      0.96       264\n",
      "       left       0.97      0.99      0.98       247\n",
      "      right       0.99      0.96      0.97       256\n",
      "         on       0.98      0.95      0.96       257\n",
      "        off       0.96      0.93      0.94       256\n",
      "       stop       0.99      0.93      0.96       246\n",
      "         go       0.97      0.90      0.93       260\n",
      "    silence       0.96      1.00      0.98       257\n",
      "    unknown       0.80      0.95      0.87       257\n",
      "\n",
      "avg / total       0.95      0.95      0.95      3091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'left'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2name[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_val_preds = np.array(np.argmax(val_preds,axis=1).reshape(1,-1).tolist()[0])\n",
    "class_val_actual =  np.array(np.argmax(y_true,axis=1).reshape(1,-1).tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 125,  167,  173,  255,  264,  265,  277,  347,  360,  362,  369,\n",
       "        375,  439,  446,  494,  501,  521,  524,  557,  566,  580,  642,\n",
       "        647,  649,  658,  702,  709,  718,  760,  769,  787,  793,  831,\n",
       "        837,  851,  859,  959, 1011, 1014, 1020, 1029, 1031, 1046, 1049,\n",
       "       1050, 1073, 1082, 1092, 1135, 1151, 1162, 1167, 1173, 1180, 1230,\n",
       "       1270, 1275, 1301, 1302, 1305, 1307, 1308, 1321, 1334, 1339, 1353,\n",
       "       1365, 1369, 1372, 1381, 1385, 1397, 1414, 1421, 1427, 1433, 1496,\n",
       "       1499, 1520, 1531, 1533, 1538, 1548, 1550, 1568, 1605, 1608, 1633,\n",
       "       1671, 1723, 1741, 1746, 1780, 1791, 1798, 1822, 1835, 1850, 1851,\n",
       "       1868, 1892, 1936, 1949, 2014, 2045, 2073, 2089, 2113, 2114, 2116,\n",
       "       2118, 2124, 2128, 2134, 2150, 2174, 2201, 2248, 2271, 2274, 2298,\n",
       "       2306, 2320, 2327, 2331, 2345, 2349, 2350, 2356, 2370, 2376, 2412,\n",
       "       2445, 2450, 2462, 2485, 2512, 2532, 2541, 2561, 2568, 2575, 2863,\n",
       "       2912, 2927, 2940, 2943, 2945, 2955, 2961, 2980, 3038, 3039, 3052])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['silence',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'go',\n",
       " 'down',\n",
       " 'unknown',\n",
       " 'go',\n",
       " 'go',\n",
       " 'unknown',\n",
       " 'left',\n",
       " 'go',\n",
       " 'down',\n",
       " 'unknown',\n",
       " 'go',\n",
       " 'off',\n",
       " 'unknown',\n",
       " 'silence',\n",
       " 'silence',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'off',\n",
       " 'silence',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'off',\n",
       " 'unknown',\n",
       " 'up',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'left',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'left',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'go',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'no',\n",
       " 'unknown',\n",
       " 'no',\n",
       " 'stop',\n",
       " 'no',\n",
       " 'no',\n",
       " 'go',\n",
       " 'unknown',\n",
       " 'no',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'no',\n",
       " 'unknown',\n",
       " 'no',\n",
       " 'up',\n",
       " 'down',\n",
       " 'off',\n",
       " 'silence',\n",
       " 'no',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'down',\n",
       " 'silence',\n",
       " 'off',\n",
       " 'no',\n",
       " 'no',\n",
       " 'unknown',\n",
       " 'no',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'no',\n",
       " 'unknown',\n",
       " 'no',\n",
       " 'right',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'up',\n",
       " 'silence',\n",
       " 'silence',\n",
       " 'unknown',\n",
       " 'left',\n",
       " 'no',\n",
       " 'left',\n",
       " 'silence',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'on',\n",
       " 'unknown',\n",
       " 'off',\n",
       " 'unknown',\n",
       " 'off',\n",
       " 'stop',\n",
       " 'unknown',\n",
       " 'no',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'off',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'silence',\n",
       " 'up',\n",
       " 'unknown',\n",
       " 'up',\n",
       " 'off',\n",
       " 'up',\n",
       " 'up',\n",
       " 'unknown',\n",
       " 'up',\n",
       " 'up',\n",
       " 'unknown',\n",
       " 'up',\n",
       " 'on',\n",
       " 'up',\n",
       " 'up',\n",
       " 'up',\n",
       " 'up',\n",
       " 'go',\n",
       " 'up',\n",
       " 'up',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'up',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'up',\n",
       " 'up',\n",
       " 'on',\n",
       " 'on',\n",
       " 'no',\n",
       " 'right',\n",
       " 'off',\n",
       " 'no',\n",
       " 'on',\n",
       " 'left',\n",
       " 'left',\n",
       " 'on',\n",
       " 'up',\n",
       " 'right']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id2name[i] for i in class_val_preds[np.where(class_val_actual!=class_val_preds)[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>wav_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>left</td>\n",
       "      <td>./data/train/audio/left/a6d586b7_nohash_4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>left</td>\n",
       "      <td>./data/train/audio/left/471a0925_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>left</td>\n",
       "      <td>./data/train/audio/left/dbb40d24_nohash_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>no</td>\n",
       "      <td>./data/train/audio/no/bdee441c_nohash_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>no</td>\n",
       "      <td>./data/train/audio/no/bdee441c_nohash_4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>no</td>\n",
       "      <td>./data/train/audio/no/7c1d8533_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>no</td>\n",
       "      <td>./data/train/audio/no/c6ee87a7_nohash_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>no</td>\n",
       "      <td>./data/train/audio/no/c6ee87a7_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>no</td>\n",
       "      <td>./data/train/audio/no/7c1d8533_nohash_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>no</td>\n",
       "      <td>./data/train/audio/no/7c1d8533_nohash_4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>no</td>\n",
       "      <td>./data/train/audio/no/bdee441c_nohash_5.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>no</td>\n",
       "      <td>./data/train/audio/no/989a2213_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>no</td>\n",
       "      <td>./data/train/audio/no/dbb40d24_nohash_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>no</td>\n",
       "      <td>./data/train/audio/no/d55aa56c_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>no</td>\n",
       "      <td>./data/train/audio/no/bdee441c_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>no</td>\n",
       "      <td>./data/train/audio/no/7c1d8533_nohash_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>on</td>\n",
       "      <td>./data/train/audio/on/50f55535_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>on</td>\n",
       "      <td>./data/train/audio/on/099d52ad_nohash_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>on</td>\n",
       "      <td>./data/train/audio/on/7fd25f7c_nohash_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>on</td>\n",
       "      <td>./data/train/audio/on/d197e3ae_nohash_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>on</td>\n",
       "      <td>./data/train/audio/on/dbb40d24_nohash_4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>on</td>\n",
       "      <td>./data/train/audio/on/db4cf12f_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>on</td>\n",
       "      <td>./data/train/audio/on/dca2797e_nohash_4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>on</td>\n",
       "      <td>./data/train/audio/on/a6d586b7_nohash_4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>on</td>\n",
       "      <td>./data/train/audio/on/7c1d8533_nohash_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>on</td>\n",
       "      <td>./data/train/audio/on/dbb40d24_nohash_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>on</td>\n",
       "      <td>./data/train/audio/on/d55aa56c_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>on</td>\n",
       "      <td>./data/train/audio/on/5fadb538_nohash_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>on</td>\n",
       "      <td>./data/train/audio/on/7c1d8533_nohash_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>on</td>\n",
       "      <td>./data/train/audio/on/794cdfc5_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/dbb40d24_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/f17be97f_nohash_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/794cdfc5_nohash_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/dd086776_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/5fadb538_nohash_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/dbb40d24_nohash_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/dbb40d24_nohash_4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/c6ee87a7_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/86478fab_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/b6ebe225_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/c6ee87a7_nohash_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/3aa6f4e2_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/dbb40d24_nohash_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/c842b5e4_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/794cdfc5_nohash_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/dbb40d24_nohash_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/5fadb538_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>off</td>\n",
       "      <td>./data/train/audio/off/c6ee87a7_nohash_4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>unknown</td>\n",
       "      <td>./data/train/audio/five/439c84f4_nohash_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>unknown</td>\n",
       "      <td>./data/train/audio/one/c6ee87a7_nohash_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>unknown</td>\n",
       "      <td>./data/train/audio/one/7fd25f7c_nohash_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>unknown</td>\n",
       "      <td>./data/train/audio/three/19b05529_nohash_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>unknown</td>\n",
       "      <td>./data/train/audio/house/cc6bae0d_nohash_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>unknown</td>\n",
       "      <td>./data/train/audio/wow/060cd039_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>unknown</td>\n",
       "      <td>./data/train/audio/house/dbb40d24_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>unknown</td>\n",
       "      <td>./data/train/audio/sheila/7c1d8533_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>unknown</td>\n",
       "      <td>./data/train/audio/marvin/6b81fead_nohash_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>unknown</td>\n",
       "      <td>./data/train/audio/five/41285056_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>unknown</td>\n",
       "      <td>./data/train/audio/bird/1bc45db9_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>unknown</td>\n",
       "      <td>./data/train/audio/one/471a0925_nohash_4.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                         wav_file\n",
       "125      left    ./data/train/audio/left/a6d586b7_nohash_4.wav\n",
       "167      left    ./data/train/audio/left/471a0925_nohash_0.wav\n",
       "173      left    ./data/train/audio/left/dbb40d24_nohash_2.wav\n",
       "255        no      ./data/train/audio/no/bdee441c_nohash_3.wav\n",
       "264        no      ./data/train/audio/no/bdee441c_nohash_4.wav\n",
       "265        no      ./data/train/audio/no/7c1d8533_nohash_0.wav\n",
       "277        no      ./data/train/audio/no/c6ee87a7_nohash_1.wav\n",
       "347        no      ./data/train/audio/no/c6ee87a7_nohash_0.wav\n",
       "360        no      ./data/train/audio/no/7c1d8533_nohash_1.wav\n",
       "362        no      ./data/train/audio/no/7c1d8533_nohash_4.wav\n",
       "369        no      ./data/train/audio/no/bdee441c_nohash_5.wav\n",
       "375        no      ./data/train/audio/no/989a2213_nohash_0.wav\n",
       "439        no      ./data/train/audio/no/dbb40d24_nohash_2.wav\n",
       "446        no      ./data/train/audio/no/d55aa56c_nohash_0.wav\n",
       "494        no      ./data/train/audio/no/bdee441c_nohash_0.wav\n",
       "501        no      ./data/train/audio/no/7c1d8533_nohash_3.wav\n",
       "521        on      ./data/train/audio/on/50f55535_nohash_0.wav\n",
       "524        on      ./data/train/audio/on/099d52ad_nohash_3.wav\n",
       "557        on      ./data/train/audio/on/7fd25f7c_nohash_3.wav\n",
       "566        on      ./data/train/audio/on/d197e3ae_nohash_2.wav\n",
       "580        on      ./data/train/audio/on/dbb40d24_nohash_4.wav\n",
       "642        on      ./data/train/audio/on/db4cf12f_nohash_0.wav\n",
       "647        on      ./data/train/audio/on/dca2797e_nohash_4.wav\n",
       "649        on      ./data/train/audio/on/a6d586b7_nohash_4.wav\n",
       "658        on      ./data/train/audio/on/7c1d8533_nohash_2.wav\n",
       "702        on      ./data/train/audio/on/dbb40d24_nohash_2.wav\n",
       "709        on      ./data/train/audio/on/d55aa56c_nohash_0.wav\n",
       "718        on      ./data/train/audio/on/5fadb538_nohash_1.wav\n",
       "760        on      ./data/train/audio/on/7c1d8533_nohash_3.wav\n",
       "769        on      ./data/train/audio/on/794cdfc5_nohash_0.wav\n",
       "...       ...                                              ...\n",
       "2331      off     ./data/train/audio/off/dbb40d24_nohash_0.wav\n",
       "2345      off     ./data/train/audio/off/f17be97f_nohash_2.wav\n",
       "2349      off     ./data/train/audio/off/794cdfc5_nohash_2.wav\n",
       "2350      off     ./data/train/audio/off/dd086776_nohash_0.wav\n",
       "2356      off     ./data/train/audio/off/5fadb538_nohash_3.wav\n",
       "2370      off     ./data/train/audio/off/dbb40d24_nohash_3.wav\n",
       "2376      off     ./data/train/audio/off/dbb40d24_nohash_4.wav\n",
       "2412      off     ./data/train/audio/off/c6ee87a7_nohash_0.wav\n",
       "2445      off     ./data/train/audio/off/86478fab_nohash_0.wav\n",
       "2450      off     ./data/train/audio/off/b6ebe225_nohash_0.wav\n",
       "2462      off     ./data/train/audio/off/c6ee87a7_nohash_3.wav\n",
       "2485      off     ./data/train/audio/off/3aa6f4e2_nohash_0.wav\n",
       "2512      off     ./data/train/audio/off/dbb40d24_nohash_2.wav\n",
       "2532      off     ./data/train/audio/off/c842b5e4_nohash_0.wav\n",
       "2541      off     ./data/train/audio/off/794cdfc5_nohash_1.wav\n",
       "2561      off     ./data/train/audio/off/dbb40d24_nohash_1.wav\n",
       "2568      off     ./data/train/audio/off/5fadb538_nohash_0.wav\n",
       "2575      off     ./data/train/audio/off/c6ee87a7_nohash_4.wav\n",
       "2863  unknown    ./data/train/audio/five/439c84f4_nohash_2.wav\n",
       "2912  unknown     ./data/train/audio/one/c6ee87a7_nohash_3.wav\n",
       "2927  unknown     ./data/train/audio/one/7fd25f7c_nohash_3.wav\n",
       "2940  unknown   ./data/train/audio/three/19b05529_nohash_1.wav\n",
       "2943  unknown   ./data/train/audio/house/cc6bae0d_nohash_1.wav\n",
       "2945  unknown     ./data/train/audio/wow/060cd039_nohash_0.wav\n",
       "2955  unknown   ./data/train/audio/house/dbb40d24_nohash_0.wav\n",
       "2961  unknown  ./data/train/audio/sheila/7c1d8533_nohash_0.wav\n",
       "2980  unknown  ./data/train/audio/marvin/6b81fead_nohash_1.wav\n",
       "3038  unknown    ./data/train/audio/five/41285056_nohash_0.wav\n",
       "3039  unknown    ./data/train/audio/bird/1bc45db9_nohash_0.wav\n",
       "3052  unknown     ./data/train/audio/one/471a0925_nohash_4.wav\n",
       "\n",
       "[154 rows x 2 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.loc[np.where(class_val_actual!=class_val_preds)[0],[\"label\",\"wav_file\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       1.00      0.96      0.98       261\n",
      "         no       0.94      0.94      0.94       270\n",
      "         up       0.91      0.95      0.93       260\n",
      "       down       0.98      0.97      0.97       264\n",
      "       left       0.97      0.98      0.97       247\n",
      "      right       0.98      0.94      0.96       256\n",
      "         on       0.98      0.95      0.96       257\n",
      "        off       0.95      0.94      0.95       256\n",
      "       stop       0.99      0.93      0.96       246\n",
      "         go       0.97      0.89      0.93       260\n",
      "    silence       0.95      1.00      0.98       257\n",
      "    unknown       0.82      0.94      0.87       257\n",
      "\n",
      "avg / total       0.95      0.95      0.95      3091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       1.00      0.96      0.98       261\n",
      "         no       0.93      0.95      0.94       270\n",
      "         up       0.92      0.94      0.93       260\n",
      "       down       0.99      0.94      0.96       264\n",
      "       left       0.96      0.98      0.97       247\n",
      "      right       0.98      0.95      0.97       256\n",
      "         on       0.96      0.95      0.95       257\n",
      "        off       0.97      0.95      0.96       256\n",
      "       stop       1.00      0.93      0.96       246\n",
      "         go       0.96      0.92      0.94       260\n",
      "    silence       1.00      1.00      1.00       257\n",
      "    unknown       0.79      0.95      0.86       257\n",
      "\n",
      "avg / total       0.95      0.95      0.95      3091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.95      0.94      0.95       261\n",
      "         no       0.82      0.85      0.84       270\n",
      "         up       0.89      0.91      0.90       260\n",
      "       down       0.92      0.88      0.90       264\n",
      "       left       0.92      0.90      0.91       247\n",
      "      right       0.97      0.86      0.91       256\n",
      "         on       0.96      0.86      0.91       257\n",
      "        off       0.92      0.88      0.90       256\n",
      "       stop       0.96      0.87      0.91       246\n",
      "         go       0.86      0.76      0.81       260\n",
      "    silence       0.98      0.99      0.98       257\n",
      "    unknown       0.62      0.92      0.74       257\n",
      "\n",
      "avg / total       0.90      0.89      0.89      3091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.93      0.95      0.94       261\n",
      "         no       0.84      0.81      0.82       270\n",
      "         up       0.88      0.90      0.89       260\n",
      "       down       0.83      0.91      0.87       264\n",
      "       left       0.92      0.88      0.90       247\n",
      "      right       0.93      0.89      0.91       256\n",
      "         on       0.89      0.89      0.89       257\n",
      "        off       0.93      0.86      0.89       256\n",
      "       stop       0.89      0.89      0.89       246\n",
      "         go       0.81      0.78      0.79       260\n",
      "    silence       1.00      1.00      1.00       257\n",
      "    unknown       0.71      0.78      0.74       257\n",
      "\n",
      "avg / total       0.88      0.88      0.88      3091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:28:14.451612Z",
     "start_time": "2017-11-17T10:28:13.307142Z"
    },
    "_cell_guid": "72f27090-c0d1-4d0b-8027-34c915429a79",
    "_uuid": "1007977fccadecdae582ec5d8d52dd3c4c3010aa"
   },
   "outputs": [],
   "source": [
    "test_paths = glob(os.path.join('./data/', 'test/audio/*wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158538"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pickle.load( open(\"cache/test_df.pik\",\"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:32:14.882322Z",
     "start_time": "2017-11-17T10:32:14.863617Z"
    },
    "_cell_guid": "c6d9b369-9979-4bcd-8540-4653e6544f84",
    "_uuid": "6a0bb3c22b7b5c43db0ec5673333ab3de8f08724"
   },
   "outputs": [],
   "source": [
    "def test_generator(test_batch_size,augment=False):\n",
    "    while True:\n",
    "        ids = list(range(test_df.shape[0]))\n",
    "        \n",
    "        for start in range(0, len(ids), test_batch_size):\n",
    "            x_batch = []\n",
    "            end = min(start + test_batch_size, len(ids))\n",
    "            i_test_batch = ids[start:end]\n",
    "#             this_paths = test_paths[start:end]\n",
    "#             for x in this_paths:\n",
    "            for i in i_test_batch:\n",
    "            #WATCHOUT > NO AUG\n",
    "#                 x_batch.append(process_wav_file(x).T) #,reshape=False,augment=augment,pval=0.5))\n",
    "                x_batch.append(test_df.loc[i,'raw'].T)\n",
    "\n",
    "            x_batch = np.array(x_batch)\n",
    "            x_batch = 1.- np.array(x_batch)/-80.\n",
    "            \n",
    "            yield x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-17T10:32:45.947Z"
    },
    "_cell_guid": "1fb8aed4-de12-43c5-84bf-b803e3d640fa",
    "_uuid": "631a38cb0013e5772f6987854145ad76ecf6c430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2478/2478 [==============================] - 66s    \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(test_generator(64,augment=False), int(np.ceil(len(test_paths)/64.)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cache/predictions_{}.npy\".format(exp_name),predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158538, 12)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_pyramid_noaug = np.load('cache/predictions_pyramid_noaug.npy')\n",
    "# predictions_model_with_ae_base_drp2_1 = np.load('cache/predictions_model_with_ae_base_drp2_1.npy')\n",
    "# predictions_dilated_convnlstm_timek23_n_freqk8_extrabn = np.load('cache/predictions_dilated_convnlstm_timek23_n_freqk8_extrabn.npy')\n",
    "blend1 =  np.load('cache/predictions_dilated_convnlstm_timek23_n_freqk8_extrabn.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.mean([predictions,blend1], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477/2478 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# num_aug = 2 \n",
    "# for i in range(num_aug):\n",
    "#     predictions +=  model.predict_generator(test_generator(64,augment=True), int(np.ceil(len(test_paths)/64.)), verbose=1)\n",
    "    \n",
    "\n",
    "# predictions = predictions/(num_aug + 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:30:44.236246Z",
     "start_time": "2017-11-17T11:30:44.21858Z"
    },
    "_cell_guid": "b1cdab5c-9816-4690-87d8-de2c97cf0e7d",
    "_uuid": "24eb7e512eace4567494e0a8e356a826f4283c4d"
   },
   "outputs": [],
   "source": [
    "classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((158538,), 158538)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.shape, len(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  6,  1, ..., 11,  6,  1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes #dilated_convnlstm_timek23_n_freqk8_extrabn\n",
    "np.argmax(blend1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.93993455],\n",
       "       [ 0.93993455,  1.        ]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(classes,np.argmax(blend1, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((classes - np.argmax(blend1, axis=1)) >0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 13096.,   6184.,   4952.,   6066.,   5293.,   7011.,   6612.,\n",
       "          5698.,   5980.,  97646.]),\n",
       " array([  0. ,   1.1,   2.2,   3.3,   4.4,   5.5,   6.6,   7.7,   8.8,\n",
       "          9.9,  11. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0a5c1ebd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(classes,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 13512.,   6159.,   4821.,   6195.,   5425.,   7134.,   6557.,\n",
       "          5586.,   6118.,  97031.]),\n",
       " array([  0. ,   1.1,   2.2,   3.3,   4.4,   5.5,   6.6,   7.7,   8.8,\n",
       "          9.9,  11. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSaZq5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e83285050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(classes,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 14036.,   6387.,   4889.,   6526.,   5729.,   7509.,   6530.,\n",
       "          5481.,   6817.,  94634.]),\n",
       " array([  0. ,   1.1,   2.2,   3.3,   4.4,   5.5,   6.6,   7.7,   8.8,\n",
       "          9.9,  11. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEkd4yBJ6hgHSVLHOEiSOv8L91IZOB+xr1IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ed436cdd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(classes,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 12769.,   6288.,   7058.,   6322.,   6488.,   7524.,   5727.,\n",
       "          6044.,   7517.,  92801.]),\n",
       " array([  0. ,   1.1,   2.2,   3.3,   4.4,   5.5,   6.6,   7.7,   8.8,\n",
       "          9.9,  11. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAD1ZJREFUeJzt3G2MnWWdx/Hvb1tRwMiDNERbsm1io6kkBmywLonZUANF\njOWFGsyuNIbYF6KiMXGLb0hUEkyMKImSEKgWl4ikktBItUsAs9kXIAWMWCphwlPbBRktD65Gsfrf\nF3OxO/Zq6Wl72ns68/0kk7nv677OOdcNzXzn3HPOSVUhSdJ0/zD0AiRJM49xkCR1jIMkqWMcJEkd\n4yBJ6hgHSVLHOEiSOsZBktQxDpKkzvyhF3CoTjvttFq8ePHQy5CkY8aDDz7426paMMrcYzYOixcv\nZuvWrUMvQ5KOGUmeHnWul5UkSR3jIEnqGAdJUsc4SJI6xkGS1DEOkqSOcZAkdYyDJKljHCRJnWP2\nHdKSNKTF6+4c5HGfuuaio/I4PnOQJHWMgySpYxwkSR3jIEnqGAdJUsc4SJI6xkGS1DEOkqSOcZAk\ndYyDJKljHCRJHeMgSeoYB0lSxzhIkjrGQZLUMQ6SpI5xkCR1jIMkqWMcJEkd4yBJ6hgHSVLHOEiS\nOsZBktQxDpKkzkhxSPL5JNuS/CrJD5K8IcmSJPcnmUjywyTHtbmvb/sT7fjiafdzZRt/LMkF08ZX\ntbGJJOvGfZKSpINzwDgkWQh8FlheVWcC84BLgK8B11bV24AXgMvaTS4DXmjj17Z5JFnWbvdOYBXw\nnSTzkswDvg1cCCwDPtbmSpIGMuplpfnA8UnmAycAzwLnARvb8Q3AxW17ddunHV+ZJG381qr6c1U9\nCUwA57Sviap6oqpeAW5tcyVJAzlgHKpqF/B14BmmovAS8CDwYlXtadN2Agvb9kJgR7vtnjb/zdPH\n97rN/sY7SdYm2Zpk6+Tk5CjnJ0k6BKNcVjqFqd/klwBvBU5k6rLQUVdVN1TV8qpavmDBgiGWIElz\nwiiXld4PPFlVk1X1F+B24Fzg5HaZCWARsKtt7wLOAGjHTwJ+N318r9vsb1ySNJBR4vAMsCLJCe1v\nByuBR4F7gQ+3OWuAO9r2prZPO35PVVUbv6S9mmkJsBT4OfAAsLS9+uk4pv5ovenwT02SdKjmH2hC\nVd2fZCPwELAHeBi4AbgTuDXJV9vYTe0mNwHfTzIB7Gbqhz1VtS3JbUyFZQ9weVX9FSDJp4EtTL0S\nan1VbRvfKUqSDtYB4wBQVVcBV+01/ARTrzTae+6fgI/s536uBq7ex/hmYPMoa5EkHXm+Q1qS1DEO\nkqSOcZAkdYyDJKljHCRJHeMgSeoYB0lSxzhIkjrGQZLUMQ6SpI5xkCR1jIMkqWMcJEkd4yBJ6hgH\nSVLHOEiSOsZBktQxDpKkjnGQJHWMgySpYxwkSR3jIEnqGAdJUsc4SJI6xkGS1DEOkqSOcZAkdYyD\nJKljHCRJHeMgSeoYB0lSxzhIkjrGQZLUMQ6SpI5xkCR1RopDkpOTbEzy6yTbk7w3yalJ7kryePt+\nSpubJNclmUjyyyRnT7ufNW3+40nWTBt/d5JH2m2uS5Lxn6okaVSjPnP4FvDTqnoH8C5gO7AOuLuq\nlgJ3t32AC4Gl7WstcD1AklOBq4D3AOcAV70alDbnk9Nut+rwTkuSdDgOGIckJwHvA24CqKpXqupF\nYDWwoU3bAFzctlcDN9eU+4CTk7wFuAC4q6p2V9ULwF3AqnbsTVV1X1UVcPO0+5IkDWCUZw5LgEng\nu0keTnJjkhOB06vq2TbnOeD0tr0Q2DHt9jvb2GuN79zHuCRpIKPEYT5wNnB9VZ0F/IH/v4QEQPuN\nv8a/vL+XZG2SrUm2Tk5OHumHk6Q5a5Q47AR2VtX9bX8jU7H4TbskRPv+fDu+Czhj2u0XtbHXGl+0\nj/FOVd1QVcuravmCBQtGWLok6VAcMA5V9RywI8nb29BK4FFgE/DqK47WAHe07U3Ape1VSyuAl9rl\npy3A+UlOaX+IPh/Y0o69nGRFe5XSpdPuS5I0gPkjzvsMcEuS44AngE8wFZbbklwGPA18tM3dDHwA\nmAD+2OZSVbuTfAV4oM37clXtbtufAr4HHA/8pH1JkgYyUhyq6hfA8n0cWrmPuQVcvp/7WQ+s38f4\nVuDMUdYiSTryfIe0JKljHCRJHeMgSeoYB0lSxzhIkjrGQZLUMQ6SpI5xkCR1jIMkqWMcJEkd4yBJ\n6hgHSVLHOEiSOsZBktQxDpKkjnGQJHWMgySpYxwkSR3jIEnqGAdJUsc4SJI6xkGS1DEOkqSOcZAk\ndYyDJKljHCRJHeMgSeoYB0lSxzhIkjrGQZLUMQ6SpI5xkCR1jIMkqWMcJEkd4yBJ6hgHSVJn5Dgk\nmZfk4SQ/bvtLktyfZCLJD5Mc18Zf3/Yn2vHF0+7jyjb+WJILpo2vamMTSdaN7/QkSYfiYJ45XAFs\nn7b/NeDaqnob8AJwWRu/DHihjV/b5pFkGXAJ8E5gFfCdFpx5wLeBC4FlwMfaXEnSQEaKQ5JFwEXA\njW0/wHnAxjZlA3Bx217d9mnHV7b5q4Fbq+rPVfUkMAGc074mquqJqnoFuLXNlSQNZNRnDt8Evgj8\nre2/GXixqva0/Z3Awra9ENgB0I6/1Ob/3/het9nfuCRpIAeMQ5IPAs9X1YNHYT0HWsvaJFuTbJ2c\nnBx6OZI0a43yzOFc4ENJnmLqks95wLeAk5PMb3MWAbva9i7gDIB2/CTgd9PH97rN/sY7VXVDVS2v\nquULFiwYYemSpENxwDhU1ZVVtaiqFjP1B+V7qupfgHuBD7dpa4A72vamtk87fk9VVRu/pL2aaQmw\nFPg58ACwtL366bj2GJvGcnaSpEMy/8BT9uvfgFuTfBV4GLipjd8EfD/JBLCbqR/2VNW2JLcBjwJ7\ngMur6q8AST4NbAHmAeuratthrEuSdJgOKg5V9TPgZ237CaZeabT3nD8BH9nP7a8Grt7H+GZg88Gs\nRZJ05PgOaUlSxzhIkjrGQZLUMQ6SpI5xkCR1jIMkqWMcJEkd4yBJ6hgHSVLHOEiSOsZBktQxDpKk\njnGQJHWMgySpYxwkSR3jIEnqGAdJUsc4SJI6xkGS1DEOkqSOcZAkdYyDJKljHCRJHeMgSeoYB0lS\nxzhIkjrGQZLUMQ6SpI5xkCR1jIMkqWMcJEkd4yBJ6hgHSVLHOEiSOsZBktQxDpKkzgHjkOSMJPcm\neTTJtiRXtPFTk9yV5PH2/ZQ2niTXJZlI8sskZ0+7rzVt/uNJ1kwbf3eSR9ptrkuSI3GykqTRjPLM\nYQ/whapaBqwALk+yDFgH3F1VS4G72z7AhcDS9rUWuB6mYgJcBbwHOAe46tWgtDmfnHa7VYd/apKk\nQ3XAOFTVs1X1UNv+PbAdWAisBja0aRuAi9v2auDmmnIfcHKStwAXAHdV1e6qegG4C1jVjr2pqu6r\nqgJunnZfkqQBHNTfHJIsBs4C7gdOr6pn26HngNPb9kJgx7Sb7WxjrzW+cx/j+3r8tUm2Jtk6OTl5\nMEuXJB2EkeOQ5I3Aj4DPVdXL04+13/hrzGvrVNUNVbW8qpYvWLDgSD+cJM1ZI8UhyeuYCsMtVXV7\nG/5NuyRE+/58G98FnDHt5ova2GuNL9rHuCRpIKO8WinATcD2qvrGtEObgFdfcbQGuGPa+KXtVUsr\ngJfa5actwPlJTml/iD4f2NKOvZxkRXusS6fdlyRpAPNHmHMu8HHgkSS/aGNfAq4BbktyGfA08NF2\nbDPwAWAC+CPwCYCq2p3kK8ADbd6Xq2p32/4U8D3geOAn7UuSNJADxqGq/gvY3/sOVu5jfgGX7+e+\n1gPr9zG+FTjzQGuRJB0dvkNaktQxDpKkjnGQJHWMgySpYxwkSR3jIEnqGAdJUsc4SJI6xkGS1DEO\nkqTOKJ+tNOssXnfnII/71DUXDfK4knSwfOYgSeoYB0lSxzhIkjrGQZLUMQ6SpI5xkCR1jIMkqWMc\nJEkd4yBJ6hgHSVLHOEiSOnPys5WkI8nP7jp6hvpvPRcYhznCH1iSDoZx0Kzlb5XSoTMOR9Fc/GE1\nF895LvL/8+xjHKRZwh/QGidfrSRJ6hgHSVLHOEiSOsZBktQxDpKkjnGQJHWMgySpYxwkSZ0ZE4ck\nq5I8lmQiybqh1yNJc9mMiEOSecC3gQuBZcDHkiwbdlWSNHfNiDgA5wATVfVEVb0C3AqsHnhNkjRn\nzZQ4LAR2TNvf2cYkSQM4pj54L8laYG3b/Z8kjx3iXZ0G/HY8q5pxPLdj12w+P89tTPK1w7r5P446\ncabEYRdwxrT9RW3s71TVDcANh/tgSbZW1fLDvZ+ZyHM7ds3m8/Pcjj0z5bLSA8DSJEuSHAdcAmwa\neE2SNGfNiGcOVbUnyaeBLcA8YH1VbRt4WZI0Z82IOABU1WZg81F6uMO+NDWDeW7Hrtl8fp7bMSZV\nNfQaJEkzzEz5m4MkaQaZU3GYzR/RkeSMJPcmeTTJtiRXDL2mcUsyL8nDSX489FrGKcnJSTYm+XWS\n7UneO/SaxinJ59u/yV8l+UGSNwy9pkOVZH2S55P8atrYqUnuSvJ4+37KkGsclzkThznwER17gC9U\n1TJgBXD5LDs/gCuA7UMv4gj4FvDTqnoH8C5m0TkmWQh8FlheVWcy9YKTS4Zd1WH5HrBqr7F1wN1V\ntRS4u+0f8+ZMHJjlH9FRVc9W1UNt+/dM/YCZNe8yT7IIuAi4cei1jFOSk4D3ATcBVNUrVfXisKsa\nu/nA8UnmAycA/z3weg5ZVf0nsHuv4dXAhra9Abj4qC7qCJlLcZgzH9GRZDFwFnD/sCsZq28CXwT+\nNvRCxmwJMAl8t10yuzHJiUMvalyqahfwdeAZ4Fngpar6j2FXNXanV9Wzbfs54PQhFzMucykOc0KS\nNwI/Aj5XVS8PvZ5xSPJB4PmqenDotRwB84Gzgeur6izgD8ySyxIA7fr7aqYi+FbgxCT/Ouyqjpya\nevnnrHgJ6FyKw0gf0XEsS/I6psJwS1XdPvR6xuhc4ENJnmLqcuB5Sf592CWNzU5gZ1W9+ixvI1Ox\nmC3eDzxZVZNV9RfgduCfBl7TuP0myVsA2vfnB17PWMylOMzqj+hIEqauW2+vqm8MvZ5xqqorq2pR\nVS1m6v/bPVU1K377rKrngB1J3t6GVgKPDrikcXsGWJHkhPZvdCWz6A/uzSZgTdteA9wx4FrGZsa8\nQ/pImwMf0XEu8HHgkSS/aGNfau8818z2GeCW9kvLE8AnBl7P2FTV/Uk2Ag8x9Yq6hzmG31Gc5AfA\nPwOnJdkJXAVcA9yW5DLgaeCjw61wfHyHtCSpM5cuK0mSRmQcJEkd4yBJ6hgHSVLHOEiSOsZBktQx\nDpKkjnGQJHX+F8MQE0BKM3oUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f61b65e2a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(classes,bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:31:11.212517Z",
     "start_time": "2017-11-17T11:31:10.786357Z"
    },
    "_cell_guid": "1da523cf-fdbf-4ab1-9300-0147155aa247",
    "_uuid": "f25d4e626202aa115bd0460f4de8d07f9727c83e"
   },
   "outputs": [],
   "source": [
    "### last batch will contain padding, so remove duplicates\n",
    "submission = dict()\n",
    "for i in range(len(test_paths)):\n",
    "    fname, label = os.path.basename(test_paths[i]), id2name[classes[i]]\n",
    "    submission[fname] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:32:05.154527Z",
     "start_time": "2017-11-17T11:32:04.983371Z"
    },
    "_cell_guid": "9a95d147-3f4b-4386-8597-5fa60be43542",
    "_uuid": "bdf63bce43a0525a02ac18ca3f90aeba06ce6e99"
   },
   "outputs": [],
   "source": [
    "with open('subm/{}_plus_dilated_convnlstm_timek23_n_freqk8_extrabn.csv'.format(exp_name), 'w') as fout:\n",
    "    fout.write('fname,label\\n')\n",
    "    for fname, label in submission.items():\n",
    "        fout.write('{},{}\\n'.format(fname, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_cell_guid": "8bea6850-15c6-44e7-bdb4-9555ad196f85",
    "_uuid": "555315ef622793711ff5643928dac874c8cb0ed2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='subm/aebase_mix_1dtimeconvswithmaxpool_finetune_plus_dilated_convnlstm_timek23_n_freqk8_extrabn.csv' target='_blank'>subm/aebase_mix_1dtimeconvswithmaxpool_finetune_plus_dilated_convnlstm_timek23_n_freqk8_extrabn.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/keyword_spotting/subm/aebase_mix_1dtimeconvswithmaxpool_finetune_plus_dilated_convnlstm_timek23_n_freqk8_extrabn.csv"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.lib.display import FileLink\n",
    "\n",
    "FileLink('subm/{}_plus_dilated_convnlstm_timek23_n_freqk8_extrabn.csv'.format(exp_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
