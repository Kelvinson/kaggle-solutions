{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:29.196238Z",
     "start_time": "2017-11-17T09:03:28.644004Z"
    },
    "_cell_guid": "679e0d3e-646d-4e96-9eb0-b362d8c6e51f",
    "_uuid": "0d05e5ce89af3e25d1c1fb244d021a1cfa1a058c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import array \n",
    "\n",
    "from pydub import AudioSegment\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Conv2D, Flatten, GlobalMaxPooling1D, MaxPooling2D, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPool2D, concatenate, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Input, GRU, RepeatVector, BatchNormalization, TimeDistributed, Conv1D\n",
    "from keras.layers import GlobalAveragePooling1D, LSTM, MaxPooling1D, CuDNNLSTM, Bidirectional\n",
    "from keras import backend as K\n",
    "from keras.layers import  Conv2D, MaxPooling2D, UpSampling2D, Lambda, Reshape\n",
    "import keras\n",
    "from keras.layers import AveragePooling1D\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:29.210749Z",
     "start_time": "2017-11-17T09:03:29.19832Z"
    },
    "_cell_guid": "8ab00801-08b9-44d3-a063-32e82dbf8f58",
    "_uuid": "53c19941676690454dd4b91109976b6c59cb7a40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "len(id2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 s, sys: 21.5 s, total: 36.3 s\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "train_df = pickle.load( open(\"cache/train_df_256_aug.pik\",\"rb\"))\n",
    "valid_df = pickle.load( open(\"cache/valid_df_256.pik\",\"rb\"))\n",
    "silent_df = pickle.load(open(\"cache/silent_df_256.pik\",\"rb\"))\n",
    "unknown_df = pickle.load(open(\"cache/unknown_df_256_aug.pik\",\"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df =  pickle.load(open(\"cache/test_df_256.pik\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(inplace=True)\n",
    "valid_df.reset_index(inplace=True)\n",
    "unknown_df.reset_index(inplace=True)\n",
    "silent_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:32.519795Z",
     "start_time": "2017-11-17T09:03:32.483881Z"
    },
    "_cell_guid": "144c6e60-8a83-437d-8b8a-ea065af90923",
    "_uuid": "22e0e6c718171167089fb6df36d3dc43a1029992"
   },
   "outputs": [],
   "source": [
    "#no augmentation since the auto encoder has already seen all the train AND test files \n",
    "\n",
    "def train_generator(train_batch_size):\n",
    "    while True:\n",
    "        \n",
    "        this_train = train_df.groupby('label_id').apply(lambda x: x.sample(n = 2000))\n",
    "        extra_data_size = int(this_train.shape[0]* 0.1)\n",
    "        this_train = pd.concat([silent_df.sample(extra_data_size),\n",
    "                                this_train,\n",
    "                                unknown_df.sample(extra_data_size*2)],axis=0 )\n",
    "        \n",
    "        this_train.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "        shuffled_ids = random.sample(range(this_train.shape[0]), this_train.shape[0])\n",
    "        \n",
    "        for start in range(0, len(shuffled_ids), train_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            end = min(start + train_batch_size, len(shuffled_ids))\n",
    "            i_train_batch = shuffled_ids[start:end]\n",
    "            for i in i_train_batch:\n",
    "                x_batch.append(this_train.loc[i,'raw'].T)\n",
    "#                 x_batch.append(process_wav_file(this_train.iloc[i], augment=True).T)\n",
    "\n",
    "                y_batch.append(this_train.label_id.values[i])\n",
    "                \n",
    "            x_batch = 1.- np.array(x_batch)/-80.\n",
    "            y_batch = to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            \n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time t = next(train_generator(256))[0][0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:32.624289Z",
     "start_time": "2017-11-17T09:03:32.521828Z"
    },
    "_cell_guid": "59a13393-9bc3-4b27-abe2-9c78b3c32ead",
    "_uuid": "6f9a8fbf6e352b1c77b9c22dddf1c5d69382bd5b"
   },
   "outputs": [],
   "source": [
    "def valid_generator(val_batch_size):\n",
    "    while True:\n",
    "        ids = list(range(valid_df.shape[0]))\n",
    "        for start in range(0, len(ids), val_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + val_batch_size, len(ids))\n",
    "            i_val_batch = ids[start:end]\n",
    "            for i in i_val_batch:\n",
    "                x_batch.append(valid_df.loc[i,'raw'].T)\n",
    "                y_batch.append(valid_df.label_id.values[i])\n",
    "\n",
    "            x_batch = 1.- np.array(x_batch)/-80.\n",
    "            y_batch = to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 32, 256)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = next(valid_generator(64))\n",
    "t[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.load(\"cache/predictions_frqmaxpool256_plus_longblend1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"id\"] = test_df.index.values\n",
    "test_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pseudo_generator(test_batch_size):\n",
    "#     this_test = test_df #.sample(int(train_df.shape[0]//5* 0.1))\n",
    "#     this_test[\"id\"] = this_test.index.values\n",
    "    \n",
    "#     this_test.reset_index(inplace=True)\n",
    "    while True:\n",
    "\n",
    "        shuffled_ids = random.sample(range(test_df.shape[0]), test_df.shape[0])\n",
    "\n",
    "        for start in range(0, len(test_df), test_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "\n",
    "            end = min(start + test_batch_size, len(shuffled_ids))\n",
    "            i_test_batch = shuffled_ids[start:end]\n",
    "\n",
    "            for i in i_test_batch:\n",
    "                x_batch.append(test_df.loc[i,'raw'].T)\n",
    "    #                 x_batch.append(process_wav_file(this_train.iloc[i], augment=True).T)\n",
    "\n",
    "                y_batch.append(test_preds[test_df.loc[i,'id']])\n",
    "\n",
    "            x_batch = 1.- np.array(x_batch)/-80.\n",
    "            y_batch = np.array(y_batch)\n",
    "\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixIterator(object):\n",
    "    def __init__(self, iters):\n",
    "        self.iters = iters\n",
    "        self.multi = type(iters) is list\n",
    "\n",
    "        self.N = 64 \n",
    "\n",
    "    def reset(self):\n",
    "        for it in self.iters: it.reset()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def next(self, *args, **kwargs):\n",
    "\n",
    "        nexts = [next(it) for it in self.iters]\n",
    "        n0 = np.concatenate([n[0] for n in nexts])\n",
    "        n1 = np.concatenate([n[1] for n in nexts])\n",
    "        return (n0, n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = MixIterator([train_generator(50), test_pseudo_generator(14)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    4221\n",
       "1      270\n",
       "3      264\n",
       "0      261\n",
       "2      260\n",
       "9      260\n",
       "10     257\n",
       "6      257\n",
       "7      256\n",
       "5      256\n",
       "4      247\n",
       "8      246\n",
       "Name: label_id, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.label_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 60 ms, sys: 12 ms, total: 72 ms\n",
      "Wall time: 66.4 ms\n"
     ]
    }
   ],
   "source": [
    "%time t = next(test_pseudo_generator(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.loc[0,'raw'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 32, 128)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a common practice is to choose a filter size in time which spans 2/3 o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_relu(x):\n",
    "    x = BatchNormalization()(x)    \n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p =0.\n",
    "def get_1dconvs_maxpool_freq_deep( x_in, filter_size=2):\n",
    "    \n",
    "    x = BatchNormalization()(x_in)\n",
    "    \n",
    "    x = Conv1D(64,filter_size,activation='relu',padding='same')(x)\n",
    "    x = Conv1D(64,filter_size,activation='relu',padding='same')(x)\n",
    "    \n",
    "    x = Dropout(p/2)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x  = MaxPooling1D(2)(x)   \n",
    "\n",
    "    \n",
    "    x = Conv1D(128,filter_size,activation='relu',padding='same')(x)\n",
    "    x = Conv1D(128,filter_size,activation='relu',padding='same')(x)\n",
    "\n",
    "    x = Dropout(p/2)(x)\n",
    "    \n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x  = MaxPooling1D(2)(x)   \n",
    "\n",
    "    x = Conv1D(256,filter_size,activation='relu',padding='same')(x)\n",
    "    x = Conv1D(256,filter_size,activation='relu',padding='same')(x)\n",
    "\n",
    "    x = Dropout(p/2)(x)    \n",
    "    \n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x  = MaxPooling1D(2)(x) \n",
    "    \n",
    "\n",
    "    x = Conv1D(512,filter_size,activation='relu',padding='same')(x)\n",
    "    x = Conv1D(512,filter_size,activation='relu',padding='same')(x)\n",
    "\n",
    "    x = Dropout(p/2)(x)    \n",
    "    \n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x  = AveragePooling1D(2)(x) \n",
    "    \n",
    "    \n",
    "    \n",
    "    x_max = GlobalMaxPooling1D()(x)\n",
    "#     x_avg = GlobalAveragePooling1D()(x)\n",
    "\n",
    "#     x = concatenate([x_max,x_avg])\n",
    "    \n",
    "    return x_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timesteps, input_dim , latent_dim = 32,256, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = 0.0\n",
    "# filter_size = 10\n",
    "\n",
    "# input_img = Input(shape=(timesteps, input_dim))  # adapt this if using `channels_first` image data format\n",
    "# # x = Reshape((input_dim, timesteps))(input_img)\n",
    "\n",
    "# x = BatchNormalization()(input_img)\n",
    "\n",
    "\n",
    "# x = Conv1D(64,10,padding='same')(x)\n",
    "# x = batch_relu(x)\n",
    "# x = Conv1D(64,10,padding='same')(x)\n",
    "# x = batch_relu(x)\n",
    "\n",
    "\n",
    "# x = Dropout(p/2)(x)\n",
    "# # x  = MaxPooling1D(2)(x)   \n",
    "\n",
    "\n",
    "\n",
    "# x = Conv1D(64,3,padding='same')(x)\n",
    "# x = batch_relu(x)\n",
    "# x = Conv1D(64,3,padding='same')(x)\n",
    "# x = batch_relu(x)\n",
    "\n",
    "# x = Dropout(p/2)(x)    \n",
    "# # x  = MaxPooling1D(2)(x) \n",
    "\n",
    "# x = Bidirectional(CuDNNLSTM(32,return_sequences=True))(x)\n",
    "# encoded = TimeDistributed(Dense(64,activation='relu'),name='latent')(x)\n",
    "\n",
    "# x = BatchNormalization()(encoded)\n",
    "\n",
    "# x = Bidirectional(CuDNNLSTM(32,return_sequences=True))(x)\n",
    "# x = TimeDistributed(Dense(64,activation='relu'))(x)\n",
    "\n",
    "# x = BatchNormalization()(x)\n",
    "\n",
    "\n",
    "# x = Conv1D(64,3,padding='same')(x)\n",
    "# x = batch_relu(x)\n",
    "# x = Conv1D(64,3,padding='same')(x)\n",
    "# x = batch_relu(x)\n",
    "\n",
    "\n",
    "\n",
    "# x = Conv1D(64,10,padding='same')(x)\n",
    "# x = batch_relu(x)\n",
    "# x = Conv1D(64,10,padding='same')(x)\n",
    "# x = batch_relu(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# decoded = Conv1D(256,5, activation='sigmoid', padding='same')(x)\n",
    "# # decoded  = Reshape((timesteps, input_dim))(decoded)\n",
    "\n",
    "# autoencoder = Model(input_img, decoded)\n",
    "# autoencoder.compile(optimizer=Adam(lr=1e-3), loss=root_mean_squared_error, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.load_weights(\"./weights/ae_wtest_time1dconvs_plus_lstm_rmse_256.hdf5\")\n",
    "\n",
    "# # best 2dconv #ae_wtest_2dconvs_rmse_256.hdf5\")\n",
    "\n",
    "# for l in autoencoder.layers:\n",
    "#     l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x = Reshape((32,64,1))(autoencoder.get_layer(\"latent\").output)\n",
    "# x = Conv2D(64, (3, 3), padding='same')(autoencoder.get_layer(\"latent\").output)\n",
    "# x = batch_relu(x)\n",
    "\n",
    "# x = MaxPooling2D((2,3),padding='same')(x)\n",
    "\n",
    "# x = Conv2D(128, (3, 3),  padding='same')(x)\n",
    "# x = batch_relu(x)\n",
    "\n",
    "\n",
    "# # x = MaxPooling2D()(x)\n",
    "\n",
    "# # x = Conv2D(256, (3, 3),  padding='same')(x)\n",
    "# # x = batch_relu(x)\n",
    "# # x = Conv2D(256, (3, 3), padding='same')(x)\n",
    "# # x = batch_relu(x)\n",
    "\n",
    "# # x = MaxPooling2D()(x)\n",
    "\n",
    "# # x = Conv2D(512, (3, 3),  padding='same')(x)\n",
    "# # x = batch_relu(x)\n",
    "# # x = Conv2D(512, (3, 3), padding='same')(x)\n",
    "# # x = batch_relu(x)\n",
    "\n",
    "# x = AveragePooling2D((2,3))(x)\n",
    "# ae_model =  GlobalMaxPool2D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.0\n",
    "\n",
    "\n",
    "def get_1dconvs_maxpool_freq_deep_fixed( x_in, filter_size=2):\n",
    "    \n",
    "    x = BatchNormalization()(x_in)\n",
    "    \n",
    "    \n",
    "\n",
    "    x = Conv1D(64,10,padding='same')(x)\n",
    "    x = batch_relu(x)\n",
    "    x = Conv1D(64,10,padding='same')(x)\n",
    "    x = batch_relu(x)\n",
    "\n",
    "    \n",
    "    x = Dropout(p/2)(x)\n",
    "    x  = MaxPooling1D(2)(x)   \n",
    "\n",
    "\n",
    "\n",
    "    x = Conv1D(128,5,padding='same')(x)\n",
    "    x = batch_relu(x)\n",
    "    x = Conv1D(128,5,padding='same')(x)\n",
    "    x = batch_relu(x)\n",
    "\n",
    "    \n",
    "    x = Dropout(p/2)(x)    \n",
    "    x  = MaxPooling1D(2)(x) \n",
    "    \n",
    "\n",
    "    x = Conv1D(256,3,padding='same')(x)\n",
    "    x = batch_relu(x)\n",
    "    x = Conv1D(256,3,padding='same')(x)\n",
    "    x = batch_relu(x)\n",
    "    \n",
    "    x = Dropout(p/2)(x)    \n",
    "    \n",
    "    \n",
    "    x = Conv1D(256,3,padding='same')(x)\n",
    "    x = batch_relu(x)\n",
    "    x = Conv1D(256,3,padding='same')(x)\n",
    "    x = batch_relu(x)\n",
    "    \n",
    "    x = Dropout(p/2)(x) \n",
    "    \n",
    "    x  = AveragePooling1D(2)(x) \n",
    "    \n",
    "    \n",
    "    \n",
    "    x_max = GlobalMaxPooling1D(name=\"freqconv_feats\")(x)\n",
    "#     x_avg = GlobalAveragePooling1D()(x)\n",
    "\n",
    "#     x = concatenate([x_max,x_avg])\n",
    "    \n",
    "    return x_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embedder(filter_size=2):\n",
    "    v_input = Input(shape=( timesteps,input_dim))\n",
    "#     x = BatchNormalization()(v_input)\n",
    "    \n",
    "    \n",
    "#     x = Conv1D(64,filter_size,padding='same')(x)\n",
    "#     x = batch_relu(x)\n",
    "#     x = Conv1D(64,filter_size,padding='same')(x)\n",
    "#     x = batch_relu(x)\n",
    "    \n",
    "    \n",
    "#     x  = MaxPooling1D(2)(x)   \n",
    "\n",
    "#     x = Conv1D(128,filter_size,padding='same')(x)\n",
    "#     x = batch_relu(x)\n",
    "#     x = Conv1D(128,filter_size,padding='same')(x)\n",
    "#     x = batch_relu(x)\n",
    " \n",
    "#     x  = AveragePooling1D(2)(x)   \n",
    "    \n",
    "# #     x = Bidirectional(CuDNNLSTM(128,return_sequences=False))(x)\n",
    "# #     x = BatchNormalization()(x)\n",
    "# #     x = Dense(128,activation='relu')(x)\n",
    "    \n",
    "#     x = GlobalMaxPooling1D()(x)\n",
    "    x = BatchNormalization()(v_input)\n",
    "    \n",
    "    x = Conv1D(64,filter_size,padding='same')(x)\n",
    "    x = batch_relu(x)\n",
    "    x = Conv1D(64,filter_size,padding='same')(x)\n",
    "    x = batch_relu(x)\n",
    "    \n",
    "    x = Conv1D(128,3,padding='same')(x)\n",
    "    x = batch_relu(x)\n",
    "    x = Conv1D(128,3,padding='same')(x)\n",
    "    x = batch_relu(x)\n",
    "       \n",
    "    x = MaxPooling1D()(x)\n",
    "    \n",
    "    x = Conv1D(256,3,padding='same')(x)\n",
    "    x = batch_relu(x)\n",
    "    x = Bidirectional(CuDNNLSTM(128,return_sequences=False))(x)\n",
    "\n",
    "    return Model(v_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/numexpr/cpuinfo.py:42: UserWarning: [Errno 12] Cannot allocate memory\n",
      "  warnings.warn(str(e), UserWarning, stacklevel=stacklevel)\n"
     ]
    }
   ],
   "source": [
    "embedding = embedder(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.load_weights(\"weights/speaker_embedding_t2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in embedding.layers:\n",
    "    l.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 256)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 256)           1024      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 32, 64)            81984     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 32, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 32, 128)           24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 32, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16, 256)           98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               395264    \n",
      "=================================================================\n",
      "Total params: 673,920\n",
      "Trainable params: 395,264\n",
      "Non-trainable params: 278,656\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = 0.3\n",
    "\n",
    "\n",
    "x_logml = Input(shape=(timesteps, input_dim)) #1 channel, 99 time, 161 freqs # S : np.ndarray [shape=(n_mels, t)]\n",
    "x_freq = Reshape((input_dim, timesteps))(x_logml)\n",
    "\n",
    "\n",
    "# x_3 = get_conv_stacks(x_logml,2)\n",
    "# x_5 = get_conv_stacks(x_logml,5)\n",
    "# x_1 = max_timeconvs(x_logml,2)\n",
    "\n",
    "# x_time = concatenate([x_1,x_2,x_3])\n",
    "\n",
    "# x_3 = get_1dconvs_maxpool_residuals(x_freq)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 0.86\n",
    "# xf_2= get_1dconvs_maxpool_freq_deep(x_freq,2)\n",
    "xf_5 = get_1dconvs_maxpool_freq_deep_fixed(x_freq,10)\n",
    "# xf_10 = get_1dconvs_maxpool_freq_deep_shortcut(x_freq,10)\n",
    "\n",
    "# x_freq = concatenate([xf_2,xf_5,xf_10])\n",
    "\n",
    "\n",
    "# xf_2= get_1dconvs_maxpool_freq_deep_shortcut (x_freq,2)\n",
    "# xf_5 = get_1dconvs_maxpool_freq_deep_shortcut(x_freq,5)\n",
    "# xf_10 = get_1dconvs_maxpool_freq_deep_shortcut(x_freq,10)\n",
    "\n",
    "# x_freq = concatenate([xf_2,xf_5,xf_10])\n",
    "\n",
    "# x = concatenate([ae_model,xf_5])\n",
    "# x_3 = get_1dconvs_maxpool_residuals(x_freq)\n",
    "# latent = autoencoder.get_layer(\"latent\").output\n",
    "# latent = AveragePooling1D()(latent)\n",
    "# latent = GlobalMaxPooling1D()(latent)\n",
    "speaker_embedding = embedding(x_logml)\n",
    "\n",
    "x = concatenate([xf_5,speaker_embedding])\n",
    "x = Dense(128, activation = 'relu')(x) #\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "\n",
    "x = Dense(len(POSSIBLE_LABELS), activation = 'softmax', name='targets')(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Model(inputs = x_logml, outputs = x)\n",
    "model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 32, 256)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 256, 32)      0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 256, 32)      128         reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)              (None, 256, 64)      20544       batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 256, 64)      256         conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 256, 64)      0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)              (None, 256, 64)      41024       activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 256, 64)      256         conv1d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 256, 64)      0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 256, 64)      0           activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 128, 64)      0           dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, 128, 128)     41088       max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 128, 128)     512         conv1d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 128, 128)     0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 128, 128)     82048       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 128, 128)     512         conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 128, 128)     0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 128, 128)     0           activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 64, 128)      0           dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, 64, 256)      98560       max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 64, 256)      1024        conv1d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 64, 256)      0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, 64, 256)      196864      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 64, 256)      1024        conv1d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 64, 256)      0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 64, 256)      0           activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_84 (Conv1D)              (None, 64, 256)      196864      dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 64, 256)      1024        conv1d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 64, 256)      0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_85 (Conv1D)              (None, 64, 256)      196864      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 64, 256)      1024        conv1d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 64, 256)      0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 64, 256)      0           activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_10 (AveragePo (None, 32, 256)      0           dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "freqconv_feats (GlobalMaxPoolin (None, 256)          0           average_pooling1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 256)          673920      input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 512)          0           freqconv_feats[0][0]             \n",
      "                                                                 model_1[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128)          65664       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 128)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "targets (Dense)                 (None, 12)           1548        dropout_50[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,620,748\n",
      "Trainable params: 1,339,212\n",
      "Non-trainable params: 281,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "exp_name = \"freq10105533_max_wspeaker_embedding_timebased\" #max_freqconvs_2510_avgshortcuts\n",
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=5,\n",
    "                           verbose=1),\n",
    "             \n",
    "             ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               epsilon=0.01,\n",
    "                              min_lr=1e-5),\n",
    "             ModelCheckpoint(monitor='val_loss',\n",
    "                             filepath='weights/{}.hdf5'.format(exp_name),\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='min')\n",
    "#              , TensorBoard(log_dir='./logs/logs_{}'.format(exp_name), histogram_freq=0, batch_size=64, write_graph=True)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "one conv, one lstm, 128\n",
    "Epoch 00029: \n",
    "461/461 [==============================] - 9s 20ms/step - loss: 0.2684 - acc: 0.9172 - val_loss: 0.1769 - val_acc: 0.9465\n",
    "\n",
    "\n",
    "Epoch 34/100, 256\n",
    "461/461 [==============================] - 10s 22ms/step - loss: 0.2585 - acc: 0.9220 - val_loss: 0.1716 - val_acc: 0.9458\n",
    "\n",
    "Epoch 28/100, 128 (3 convs, 16,8,4)\n",
    "461/461 [==============================] - 12s 27ms/step - loss: 0.2704 - acc: 0.9181 - val_loss: 0.1600 - val_acc: 0.9476\n",
    "\n",
    "\n",
    "above lstm 64\n",
    "Epoch 33/100\n",
    "461/461 [==============================] - 14s 31ms/step - loss: 0.2349 - acc: 0.9271 - val_loss: 0.1589 - val_acc: 0.9484\n",
    "lstm 128\n",
    "Epoch 23/100\n",
    "461/461 [==============================] - 14s 30ms/step - loss: 0.2068 - acc: 0.9349 - val_loss: 0.1487 - val_acc: 0.9535\n",
    "above, dense 64\n",
    "Epoch 34/100\n",
    "461/461 [==============================] - 14s 30ms/step - loss: 0.1626 - acc: 0.9467 - val_loss: 0.1455 - val_acc: 0.9552\n",
    "double lstm\n",
    "Epoch 39/100\n",
    "461/461 [==============================] - 18s 38ms/step - loss: 0.1516 - acc: 0.9497 - val_loss: 0.1462 - val_acc: 0.9565\n",
    "\n",
    "bilstm\n",
    "Epoch 23/100\n",
    "461/461 [==============================] - 19s 41ms/step - loss: 0.1740 - acc: 0.9435 - val_loss: 0.1382 - val_acc: 0.9584\n",
    "\n",
    "extra layers\n",
    "Epoch 27/100\n",
    "461/461 [==============================] - 21s 45ms/step - loss: 0.1681 - acc: 0.9451 - val_loss: 0.1474 - val_acc: 0.9577\n",
    "\n",
    "shrinking filters\n",
    "Epoch 42/100\n",
    "461/461 [==============================] - 22s 47ms/step - loss: 0.1486 - acc: 0.9499 - val_loss: 0.1383 - val_acc: 0.9575\n",
    "\n",
    "convs between 2 lstms \n",
    "Epoch 20/100\n",
    "461/461 [==============================] - 44s 96ms/step - loss: 0.2450 - acc: 0.9212 - val_loss: 0.1574 - val_acc: 0.9515\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Epoch 25/100\n",
    "461/461 [==============================] - 23s 50ms/step - loss: 0.1748 - acc: 0.9426 - val_loss: 0.1267 - val_acc: 0.9617\n",
    "Epoch 25/100 double lstm\n",
    "461/461 [==============================] - 38s 82ms/step - loss: 0.1680 - acc: 0.9459 - val_loss: 0.1415 - val_acc: 0.9599\n",
    "\n",
    "\n",
    "freqconv_deep_buggy?\n",
    "Epoch 2/100\n",
    "461/461 [==============================] - 46s 100ms/step - loss: 0.1698 - acc: 0.9460 - val_loss: 0.1111 - val_acc: 0.9644\n",
    "Epoch 34/100_fixed..\n",
    "461/461 [==============================] - 17s 38ms/step - loss: 0.1404 - acc: 0.9543 - val_loss: 0.1085 - val_acc: 0.9681\n",
    "Epoch 27/100_fixed_extralayers\n",
    "461/461 [==============================] - 30s 65ms/step - loss: 0.1244 - acc: 0.9589 - val_loss: 0.0972 - val_acc: 0.9721\n",
    "Epoch 21/100 10 5 3..\n",
    "461/461 [==============================] - 37s 80ms/step - loss: 0.1879 - acc: 0.9403 - val_loss: 0.1111 - val_acc: 0.9651\n",
    "Epoch 27/100 - retry 10 10 3 3 ..\n",
    "461/461 [==============================] - 36s 77ms/step - loss: 0.1601 - acc: 0.9486 - val_loss: 0.1068 - val_acc: 0.9690\n",
    "\n",
    "Epoch 27/100_with_maxresiduals\n",
    "461/461 [==============================] - 30s 66ms/step - loss: 0.2305 - acc: 0.9226 - val_loss: 0.1161 - val_acc: 0.9665\n",
    "Epoch 45/100 (with lstm)\n",
    "461/461 [==============================] - 44s 95ms/step - loss: 0.1339 - acc: 0.9561 - val_loss: 0.1117 - val_acc: 0.9654\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with 2dconv ae base - frozen \n",
    "Epoch 31/100\n",
    "461/461 [==============================] - 160s 347ms/step - loss: 0.1337 - acc: 0.9562 - val_loss: 0.1021 - val_acc: 0.9708\n",
    "\n",
    "Epoch 6/100 - finetuned .. wtf (freq10_max_deep_cone_64_with_aebase_finetune)\n",
    "461/461 [==============================] - 307s 665ms/step - loss: 0.1276 - acc: 0.9581 - val_loss: 0.1022 - val_acc: 0.9694\n",
    "\n",
    "\n",
    "freq15155533_max_dense256\n",
    "Epoch 27/100\n",
    "461/461 [==============================] - 38s 82ms/step - loss: 0.1378 - acc: 0.9558 - val_loss: 0.1027 - val_acc: 0.9695\n",
    "\n",
    "Epoch 16/100\n",
    "461/461 [==============================] - 109s 237ms/step - loss: 0.1362 - acc: 0.9539 - val_loss: 0.1042 - val_acc: 0.9711\n",
    "\n",
    "with lstm_ae,still in 0.1, 0.11 range\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with speaker embedding - freq based (4x unk)\n",
    "Epoch 18/100\n",
    "461/461 [==============================] - 34s 73ms/step - loss: 0.1331 - acc: 0.9560 - val_loss: 0.0939 - val_acc: 0.9697\n",
    "\n",
    "with speaker embedding -time based (2x unk) - worse than baseline\n",
    "Epoch 16/100\n",
    "329/329 [==============================] - 27s 83ms/step - loss: 0.2065 - acc: 0.9347 - val_loss: 0.1349 - val_acc: 0.9582"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:42:31.48233Z",
     "start_time": "2017-11-17T09:03:33.355603Z"
    },
    "_cell_guid": "5f3d1b09-500f-410e-820a-8eaab24b6ebb",
    "_uuid": "528ec66a0a6caca952273ab916e609625839b19e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "329/329 [==============================] - 32s 99ms/step - loss: 1.3514 - acc: 0.5364 - val_loss: 0.7820 - val_acc: 0.7403\n",
      "Epoch 2/100\n",
      " 41/329 [==>...........................] - ETA: 21s - loss: 0.8808 - acc: 0.7096"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-c01402b99710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                               validation_steps=int(np.ceil(valid_df.shape[0]/batch_size)))\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "history = model.fit_generator(generator= train_generator(batch_size),\n",
    "                              steps_per_epoch=train_df.shape[0]*(1./5)//batch_size,\n",
    "                              epochs=100,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=valid_generator(batch_size),\n",
    "                              validation_steps=int(np.ceil(valid_df.shape[0]/batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./weights/{}.hdf5'.format(exp_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### valid evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict_generator(valid_generator(64),steps=int(np.ceil(valid_df.shape[0]/64.)))\n",
    "val_preds = np.argmax(val_preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7055,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = oe.fit_transform(valid_df.label_id.values.reshape(-1, 1)).todense()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = oe.transform(val_preds.reshape(-1, 1)).todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 66s 595ms/step\n",
      "111/111 [==============================] - 65s 587ms/step\n",
      "111/111 [==============================] - 66s 593ms/step\n",
      "111/111 [==============================] - 66s 591ms/step\n"
     ]
    }
   ],
   "source": [
    "augs= []\n",
    "num_augs = 4\n",
    "for i in range(num_augs):\n",
    "    augs.append(model.predict_generator(valid_generator_aug(64),steps=int(np.ceil(valid_df.shape[0]/64.)),verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs.append(val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7055,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_aug1[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7055, 12)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(augs,axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7055, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.corrcoef(preds_aug1[:,0],val_preds[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_blend = np.mean(augs,axis=0) #np.mean([val_preds,preds_aug1],axis=0)\n",
    "val_blend = np.argmax(val_blend,axis=1)\n",
    "val_blend = oe.transform(val_blend.reshape(-1, 1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.98      0.95      0.96       261\n",
      "         no       0.90      0.93      0.91       270\n",
      "         up       0.91      0.94      0.93       260\n",
      "       down       0.97      0.95      0.96       264\n",
      "       left       0.96      0.98      0.97       247\n",
      "      right       0.98      0.94      0.96       256\n",
      "         on       0.91      0.94      0.93       257\n",
      "        off       0.87      0.95      0.91       256\n",
      "       stop       0.97      0.95      0.96       246\n",
      "         go       0.92      0.89      0.91       260\n",
      "    silence       1.00      1.00      1.00       257\n",
      "    unknown       0.98      0.98      0.98      4221\n",
      "\n",
      "avg / total       0.97      0.97      0.97      7055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_blend,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.97      0.97      0.97       261\n",
      "         no       0.93      0.93      0.93       270\n",
      "         up       0.93      0.95      0.94       260\n",
      "       down       0.95      0.97      0.96       264\n",
      "       left       0.96      0.97      0.96       247\n",
      "      right       0.96      0.97      0.96       256\n",
      "         on       0.91      0.95      0.93       257\n",
      "        off       0.91      0.98      0.94       256\n",
      "       stop       0.98      0.94      0.96       246\n",
      "         go       0.93      0.93      0.93       260\n",
      "    silence       0.99      1.00      0.99       257\n",
      "    unknown       0.99      0.98      0.98      4221\n",
      "\n",
      "avg / total       0.97      0.97      0.97      7055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.98      0.97      0.97       261\n",
      "         no       0.92      0.93      0.92       270\n",
      "         up       0.93      0.95      0.94       260\n",
      "       down       0.94      0.97      0.96       264\n",
      "       left       0.95      0.97      0.96       247\n",
      "      right       0.95      0.97      0.96       256\n",
      "         on       0.94      0.95      0.95       257\n",
      "        off       0.92      0.98      0.95       256\n",
      "       stop       0.96      0.95      0.95       246\n",
      "         go       0.93      0.93      0.93       260\n",
      "    silence       0.99      1.00      0.99       257\n",
      "    unknown       0.99      0.98      0.98      4221\n",
      "\n",
      "avg / total       0.97      0.97      0.97      7055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.98      0.97      0.97       261\n",
      "         no       0.92      0.93      0.92       270\n",
      "         up       0.93      0.95      0.94       260\n",
      "       down       0.94      0.97      0.96       264\n",
      "       left       0.95      0.97      0.96       247\n",
      "      right       0.95      0.97      0.96       256\n",
      "         on       0.94      0.95      0.95       257\n",
      "        off       0.92      0.98      0.95       256\n",
      "       stop       0.96      0.95      0.95       246\n",
      "         go       0.93      0.93      0.93       260\n",
      "    silence       0.99      1.00      0.99       257\n",
      "    unknown       0.99      0.98      0.98      4221\n",
      "\n",
      "avg / total       0.97      0.97      0.97      7055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.98      0.97      0.97       261\n",
      "         no       0.92      0.94      0.93       270\n",
      "         up       0.89      0.93      0.91       260\n",
      "       down       0.96      0.97      0.96       264\n",
      "       left       0.95      0.99      0.97       247\n",
      "      right       0.96      0.97      0.97       256\n",
      "         on       0.91      0.95      0.93       257\n",
      "        off       0.92      0.95      0.93       256\n",
      "       stop       0.97      0.95      0.96       246\n",
      "         go       0.93      0.93      0.93       260\n",
      "    silence       0.99      1.00      0.99       257\n",
      "    unknown       0.99      0.98      0.98      4221\n",
      "\n",
      "avg / total       0.97      0.97      0.97      7055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.99      0.96      0.97       261\n",
      "         no       0.91      0.94      0.92       270\n",
      "         up       0.93      0.92      0.92       260\n",
      "       down       0.93      0.97      0.95       264\n",
      "       left       0.95      0.98      0.96       247\n",
      "      right       0.95      0.95      0.95       256\n",
      "         on       0.93      0.93      0.93       257\n",
      "        off       0.87      0.95      0.91       256\n",
      "       stop       0.96      0.94      0.95       246\n",
      "         go       0.90      0.91      0.90       260\n",
      "    silence       0.99      1.00      0.99       257\n",
      "    unknown       0.98      0.97      0.98      4221\n",
      "\n",
      "avg / total       0.96      0.96      0.96      7055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.99      0.97      0.98       261\n",
      "         no       0.91      0.93      0.92       270\n",
      "         up       0.91      0.93      0.92       260\n",
      "       down       0.97      0.95      0.96       264\n",
      "       left       0.97      0.98      0.97       247\n",
      "      right       0.97      0.94      0.96       256\n",
      "         on       0.95      0.94      0.95       257\n",
      "        off       0.94      0.96      0.95       256\n",
      "       stop       0.97      0.91      0.94       246\n",
      "         go       0.88      0.87      0.87       260\n",
      "    silence       0.99      1.00      1.00       257\n",
      "    unknown       0.98      0.98      0.98      4221\n",
      "\n",
      "avg / total       0.97      0.97      0.97      7055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.99      0.96      0.97       261\n",
      "         no       0.92      0.93      0.92       270\n",
      "         up       0.83      0.95      0.89       260\n",
      "       down       0.95      0.96      0.96       264\n",
      "       left       0.95      0.98      0.97       247\n",
      "      right       0.97      0.95      0.96       256\n",
      "         on       0.94      0.94      0.94       257\n",
      "        off       0.90      0.95      0.92       256\n",
      "       stop       0.96      0.94      0.95       246\n",
      "         go       0.92      0.92      0.92       260\n",
      "    silence       1.00      1.00      1.00       257\n",
      "    unknown       0.99      0.98      0.98      4221\n",
      "\n",
      "avg / total       0.97      0.97      0.97      7055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.98      0.97      0.98       261\n",
      "         no       0.89      0.92      0.90       270\n",
      "         up       0.92      0.94      0.93       260\n",
      "       down       0.96      0.97      0.96       264\n",
      "       left       0.96      0.98      0.97       247\n",
      "      right       0.97      0.97      0.97       256\n",
      "         on       0.93      0.95      0.94       257\n",
      "        off       0.92      0.97      0.94       256\n",
      "       stop       0.97      0.94      0.96       246\n",
      "         go       0.91      0.91      0.91       260\n",
      "    silence       0.99      1.00      1.00       257\n",
      "    unknown       0.99      0.98      0.98      4221\n",
      "\n",
      "avg / total       0.97      0.97      0.97      7055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.98      0.96      0.97       261\n",
      "         no       0.88      0.91      0.89       270\n",
      "         up       0.86      0.95      0.90       260\n",
      "       down       0.92      0.95      0.93       264\n",
      "       left       0.94      0.98      0.96       247\n",
      "      right       0.94      0.95      0.95       256\n",
      "         on       0.83      0.94      0.88       257\n",
      "        off       0.87      0.94      0.90       256\n",
      "       stop       0.98      0.93      0.95       246\n",
      "         go       0.80      0.90      0.85       260\n",
      "    silence       0.95      1.00      0.98       257\n",
      "    unknown       0.98      0.95      0.97      4221\n",
      "\n",
      "avg / total       0.95      0.95      0.95      7055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.99      0.96      0.97       261\n",
      "         no       0.92      0.92      0.92       270\n",
      "         up       0.93      0.93      0.93       260\n",
      "       down       0.99      0.95      0.97       264\n",
      "       left       0.98      0.97      0.97       247\n",
      "      right       0.99      0.95      0.97       256\n",
      "         on       0.97      0.92      0.95       257\n",
      "        off       0.94      0.92      0.93       256\n",
      "       stop       0.99      0.94      0.97       246\n",
      "         go       0.95      0.88      0.92       260\n",
      "    silence       0.97      1.00      0.98       257\n",
      "    unknown       0.76      0.98      0.86       257\n",
      "\n",
      "avg / total       0.95      0.94      0.94      3091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.98      0.96      0.97       261\n",
      "         no       0.92      0.94      0.93       270\n",
      "         up       0.92      0.93      0.93       260\n",
      "       down       0.98      0.94      0.96       264\n",
      "       left       0.97      0.97      0.97       247\n",
      "      right       0.95      0.96      0.96       256\n",
      "         on       0.96      0.95      0.96       257\n",
      "        off       0.94      0.92      0.93       256\n",
      "       stop       1.00      0.94      0.97       246\n",
      "         go       0.96      0.89      0.92       260\n",
      "    silence       0.98      1.00      0.99       257\n",
      "    unknown       0.82      0.95      0.88       257\n",
      "\n",
      "avg / total       0.95      0.95      0.95      3091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.99      0.95      0.97       261\n",
      "         no       0.94      0.95      0.95       270\n",
      "         up       0.92      0.95      0.93       260\n",
      "       down       0.99      0.95      0.97       264\n",
      "       left       0.97      0.96      0.96       247\n",
      "      right       0.99      0.95      0.97       256\n",
      "         on       0.99      0.92      0.95       257\n",
      "        off       0.93      0.94      0.93       256\n",
      "       stop       0.98      0.95      0.97       246\n",
      "         go       0.94      0.90      0.92       260\n",
      "    silence       0.99      1.00      1.00       257\n",
      "    unknown       0.80      0.96      0.88       257\n",
      "\n",
      "avg / total       0.95      0.95      0.95      3091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       1.00      0.96      0.98       261\n",
      "         no       0.91      0.94      0.93       270\n",
      "         up       0.90      0.95      0.92       260\n",
      "       down       0.99      0.94      0.96       264\n",
      "       left       0.98      0.98      0.98       247\n",
      "      right       0.98      0.96      0.97       256\n",
      "         on       0.98      0.93      0.95       257\n",
      "        off       0.93      0.93      0.93       256\n",
      "       stop       0.96      0.93      0.95       246\n",
      "         go       0.95      0.90      0.92       260\n",
      "    silence       0.98      1.00      0.99       257\n",
      "    unknown       0.82      0.94      0.87       257\n",
      "\n",
      "avg / total       0.95      0.95      0.95      3091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:28:14.451612Z",
     "start_time": "2017-11-17T10:28:13.307142Z"
    },
    "_cell_guid": "72f27090-c0d1-4d0b-8027-34c915429a79",
    "_uuid": "1007977fccadecdae582ec5d8d52dd3c4c3010aa"
   },
   "outputs": [],
   "source": [
    "test_paths = glob(os.path.join('./data/', 'test/audio/*wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158538"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pickle.load( open(\"cache/test_df_256.pik\",\"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158538, 5)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:32:14.882322Z",
     "start_time": "2017-11-17T10:32:14.863617Z"
    },
    "_cell_guid": "c6d9b369-9979-4bcd-8540-4653e6544f84",
    "_uuid": "6a0bb3c22b7b5c43db0ec5673333ab3de8f08724"
   },
   "outputs": [],
   "source": [
    "def test_generator(test_batch_size,augment=False):\n",
    "    while True:\n",
    "        ids = list(range(test_df.shape[0]))\n",
    "        \n",
    "        for start in range(0, len(ids), test_batch_size):\n",
    "            x_batch = []\n",
    "            end = min(start + test_batch_size, len(ids))\n",
    "            i_test_batch = ids[start:end]\n",
    "#             this_paths = test_paths[start:end]\n",
    "#             for x in this_paths:\n",
    "            for i in i_test_batch:\n",
    "            #WATCHOUT > NO AUG\n",
    "#                 x_batch.append(process_wav_file(x).T) #,reshape=False,augment=augment,pval=0.5))\n",
    "                x_batch.append(test_df.loc[i,'raw'].T)\n",
    "\n",
    "            x_batch = np.array(x_batch)\n",
    "            x_batch = 1.- np.array(x_batch)/-80.\n",
    "            \n",
    "            yield x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-17T10:32:45.947Z"
    },
    "_cell_guid": "1fb8aed4-de12-43c5-84bf-b803e3d640fa",
    "_uuid": "631a38cb0013e5772f6987854145ad76ecf6c430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2478/2478 [==============================] - 42s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(test_generator(batch_size), int(np.ceil(len(test_paths)/float(batch_size))), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cache/predictions_{}.npy\".format(exp_name),predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.load('cache/nn_massive_freq1d/predictions_freqconvs1d_3_10_142_0.15_73_7-0.089219957183.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158538, 12)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_pyramid_noaug = np.load('cache/predictions_pyramid_noaug.npy')\n",
    "# predictions_model_with_ae_base_drp2_1 = np.load('cache/predictions_model_with_ae_base_drp2_1.npy')\n",
    "blend1 = np.load('cache/predictions_blend_dilated_conv1d_timek123_n_freqk48_pseudo_mixtimefreq1ds_plus_samewithlstm_plus_aebased_conv2d_finetuned.npy')\n",
    "# predictions_aebase_aug_drp3_finetune = np.load('cache/predictions_aebase_aug_drp3_finetune.npy')\n",
    "# predictions_conv_n_lstm = np.load(\"cache/predictions_dilated_conv_n_lstm.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend2 = np.mean([predictions,\n",
    "                       blend1], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cache/predictions_{}.npy\".format(\"frqmaxpool256_plus_longblend1\"),blend2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477/2478 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# num_aug = 2 \n",
    "# for i in range(num_aug):\n",
    "#     predictions +=  model.predict_generator(test_generator(64,augment=True), int(np.ceil(len(test_paths)/64.)), verbose=1)\n",
    "    \n",
    "\n",
    "# predictions = predictions/(num_aug + 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:30:44.236246Z",
     "start_time": "2017-11-17T11:30:44.21858Z"
    },
    "_cell_guid": "b1cdab5c-9816-4690-87d8-de2c97cf0e7d",
    "_uuid": "24eb7e512eace4567494e0a8e356a826f4283c4d"
   },
   "outputs": [],
   "source": [
    "classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((158538,), 158538)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.shape, len(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 12582.,   6037.,   5315.,   6311.,   5686.,   6582.,   6293.,\n",
       "          5509.,   5620.,  98603.]),\n",
       " array([  0. ,   1.1,   2.2,   3.3,   4.4,   5.5,   6.6,   7.7,   8.8,\n",
       "          9.9,  11. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0e43238090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(classes,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 12814.,   5817.,   5536.,   6438.,   6017.,   6818.,   6597.,\n",
       "          5552.,   5591.,  97358.]),\n",
       " array([  0. ,   1.1,   2.2,   3.3,   4.4,   5.5,   6.6,   7.7,   8.8,\n",
       "          9.9,  11. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEQhJREFUeJzt3W+sHXWdx/H3Z1tRxCggDdGWbElsNJXEgDdYl8QYMFDE\nWB4owexKlxD7QFQ0Jm4xmzTxT4KJ8Q+JkhCoFJeABElotNptAGP2AUgBIwISbvgj7YJcLX9cjWL1\nuw/Oj/VsvW1/3nPbaW/fr+TkzHznNzPfgZv7uTNnzjRVhSRJPf5h6AYkSYcPQ0OS1M3QkCR1MzQk\nSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUrfFQzcw30444YRavnz50G1I0mHl3nvv/XVVLdnfuP2G\nRpKNwPuAZ6vqlFY7HvgOsBx4Arigqp5LEuDrwHuB3wP/WlX3tXXWAv/eNvuFqtrU6m8HrgOOBrYA\nl1VV7W0f++t3+fLlbN++fX/DJEljkjzZM67n8tR1wOo9auuB26tqBXB7mwc4F1jRXuuAq1ozxwMb\ngHcApwMbkhzX1rkK+MjYeqv3sw9J0kD2GxpV9WNg1x7lNcCmNr0JOH+sfn2N3AUcm+QNwDnAtqra\n1c4WtgGr27LXVtVdNXpy4vV7bGu2fUiSBjLXD8JPrKqn2/QzwIlteinw1Ni4Ha22r/qOWer72ock\naSAT3z3VzhAO6PPV97ePJOuSbE+yfWZm5kC2IklHtLmGxq/apSXa+7OtvhM4aWzcslbbV33ZLPV9\n7eNvVNXVVTVVVVNLluz3w39J0hzNNTQ2A2vb9FrgtrH6RRlZBbzQLjFtBc5Oclz7APxsYGtb9mKS\nVe3Oq4v22NZs+5AkDaTnltsbgXcDJyTZweguqCuAm5NcAjwJXNCGb2F0u+00o1tuLwaoql1JPg/c\n08Z9rqpe/nD9o/z1ltsftBf72IckaSBZaP/c69TUVPk9DUn6+yS5t6qm9jfOx4hIkrotuMeISNKQ\nlq///iD7feKK8w7KfjzTkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUz\nNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUz\nNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUbaLQSPKp\nJA8m+XmSG5O8KsnJSe5OMp3kO0mOamNf2ean2/LlY9u5vNUfSXLOWH11q00nWT9Jr5Kkyc05NJIs\nBT4BTFXVKcAi4ELgS8BXq+pNwHPAJW2VS4DnWv2rbRxJVrb13gqsBr6ZZFGSRcA3gHOBlcCH2lhJ\n0kAmvTy1GDg6yWLg1cDTwJnALW35JuD8Nr2mzdOWn5UkrX5TVf2xqh4HpoHT22u6qh6rqpeAm9pY\nSdJA5hwaVbUT+DLwS0Zh8QJwL/B8Ve1uw3YAS9v0UuCptu7uNv714/U91tlbXZI0kEkuTx3H6C//\nk4E3Ascwurx00CVZl2R7ku0zMzNDtCBJR4RJLk+9B3i8qmaq6k/ArcAZwLHtchXAMmBnm94JnATQ\nlr8O+M14fY919lb/G1V1dVVNVdXUkiVLJjgkSdK+TBIavwRWJXl1+2ziLOAh4E7gA23MWuC2Nr25\nzdOW31FV1eoXtrurTgZWAD8B7gFWtLuxjmL0YfnmCfqVJE1o8f6HzK6q7k5yC3AfsBu4H7ga+D5w\nU5IvtNq1bZVrgW8nmQZ2MQoBqurBJDczCpzdwKVV9WeAJB8DtjK6M2tjVT04134lSZObc2gAVNUG\nYMMe5ccY3fm059g/AB/cy3a+CHxxlvoWYMskPUqS5o/fCJckdTM0JEndDA1JUjdDQ5LUzdCQJHUz\nNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUz\nNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUz\nNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0mCo0kxya5Jckvkjyc5J1Jjk+yLcmj7f24NjZJrkwyneRn\nSU4b287aNv7RJGvH6m9P8kBb58okmaRfSdJkJj3T+Drww6p6C/A24GFgPXB7Va0Abm/zAOcCK9pr\nHXAVQJLjgQ3AO4DTgQ0vB00b85Gx9VZP2K8kaQJzDo0krwPeBVwLUFUvVdXzwBpgUxu2CTi/Ta8B\nrq+Ru4Bjk7wBOAfYVlW7quo5YBuwui17bVXdVVUFXD+2LUnSACY50zgZmAG+leT+JNckOQY4saqe\nbmOeAU5s00uBp8bW39Fq+6rvmKX+N5KsS7I9yfaZmZkJDkmStC+ThMZi4DTgqqo6Ffgdf70UBUA7\nQ6gJ9tGlqq6uqqmqmlqyZMmB3p0kHbEmCY0dwI6qurvN38IoRH7VLi3R3p9ty3cCJ42tv6zV9lVf\nNktdkjSQOYdGVT0DPJXkza10FvAQsBl4+Q6otcBtbXozcFG7i2oV8EK7jLUVODvJce0D8LOBrW3Z\ni0lWtbumLhrbliRpAIsnXP/jwA1JjgIeAy5mFEQ3J7kEeBK4oI3dArwXmAZ+38ZSVbuSfB64p437\nXFXtatMfBa4DjgZ+0F6SpIFMFBpV9VNgapZFZ80ytoBL97KdjcDGWerbgVMm6VGSNH/8RrgkqZuh\nIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuh\nIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuh\nIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSp28ShkWRRkvuTfK/Nn5zk7iTTSb6T\n5KhWf2Wbn27Ll49t4/JWfyTJOWP11a02nWT9pL1KkiYzH2calwEPj81/CfhqVb0JeA64pNUvAZ5r\n9a+2cSRZCVwIvBVYDXyzBdEi4BvAucBK4ENtrCRpIBOFRpJlwHnANW0+wJnALW3IJuD8Nr2mzdOW\nn9XGrwFuqqo/VtXjwDRwentNV9VjVfUScFMbK0kayKRnGl8DPgP8pc2/Hni+qna3+R3A0ja9FHgK\noC1/oY3/v/oe6+ytLkkayJxDI8n7gGer6t557GeuvaxLsj3J9pmZmaHbkaQFa5IzjTOA9yd5gtGl\nozOBrwPHJlncxiwDdrbpncBJAG3564DfjNf3WGdv9b9RVVdX1VRVTS1ZsmSCQ5Ik7cucQ6OqLq+q\nZVW1nNEH2XdU1T8DdwIfaMPWAre16c1tnrb8jqqqVr+w3V11MrAC+AlwD7Ci3Y11VNvH5rn2K0ma\n3OL9D/m7/RtwU5IvAPcD17b6tcC3k0wDuxiFAFX1YJKbgYeA3cClVfVngCQfA7YCi4CNVfXgAehX\nktRpXkKjqn4E/KhNP8bozqc9x/wB+OBe1v8i8MVZ6luALfPRoyRpcn4jXJLUzdCQJHUzNCRJ3QwN\nSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwN\nSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwN\nSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdZtzaCQ5KcmdSR5K8mCSy1r9+CTbkjza3o9r\n9SS5Msl0kp8lOW1sW2vb+EeTrB2rvz3JA22dK5NkkoOVJE1mkjON3cCnq2olsAq4NMlKYD1we1Wt\nAG5v8wDnAivaax1wFYxCBtgAvAM4HdjwctC0MR8ZW2/1BP1KkiY059Coqqer6r42/VvgYWApsAbY\n1IZtAs5v02uA62vkLuDYJG8AzgG2VdWuqnoO2AasbsteW1V3VVUB149tS5I0gHn5TCPJcuBU4G7g\nxKp6ui16BjixTS8FnhpbbUer7au+Y5b6bPtfl2R7ku0zMzMTHYskae8mDo0krwG+C3yyql4cX9bO\nEGrSfexPVV1dVVNVNbVkyZIDvTtJOmJNFBpJXsEoMG6oqltb+Vft0hLt/dlW3wmcNLb6slbbV33Z\nLHVJ0kAmuXsqwLXAw1X1lbFFm4GX74BaC9w2Vr+o3UW1CnihXcbaCpyd5Lj2AfjZwNa27MUkq9q+\nLhrbliRpAIsnWPcM4MPAA0l+2mqfBa4Abk5yCfAkcEFbtgV4LzAN/B64GKCqdiX5PHBPG/e5qtrV\npj8KXAccDfygvSRJA5lzaFTVfwF7+97EWbOML+DSvWxrI7Bxlvp24JS59ihJml9+I1yS1M3QkCR1\nMzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHWb5NlTC87y9d8fZL9PXHHeIPuV\npL+XZxqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6uaz\np6SDZKhnm4HPN9P8MTQ0CH+BHlw+jFPzxdA4BPgL9OAa8r+3dLgzNI5w/gLVgeTP18LjB+GSpG6G\nhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqdsiHRpLVSR5JMp1k/dD9SNKR7JAOjSSLgG8A5wIr\ngQ8lWTlsV5J05DqkQwM4HZiuqseq6iXgJmDNwD1J0hHrUA+NpcBTY/M7Wk2SNIAF8eypJOuAdW32\nf5I8MsdNnQD8en66OuQs5GODhX18Htvh66AdX7408Sb+sWfQoR4aO4GTxuaXtdr/U1VXA1dPurMk\n26tqatLtHIoW8rHBwj4+j+3wtRCP71C/PHUPsCLJyUmOAi4ENg/ckyQdsQ7pM42q2p3kY8BWYBGw\nsaoeHLgtSTpiHdKhAVBVW4AtB2l3E1/iOoQt5GODhX18Htvha8EdX6pq6B4kSYeJQ/0zDUnSIcTQ\naBbq40qSnJTkziQPJXkwyWVD9zTfkixKcn+S7w3dy3xLcmySW5L8IsnDSd45dE/zJcmn2s/kz5Pc\nmORVQ/c0iSQbkzyb5OdjteOTbEvyaHs/bsge54OhwYJ/XMlu4NNVtRJYBVy6gI7tZZcBDw/dxAHy\ndeCHVfUW4G0skONMshT4BDBVVacwutHlwmG7mth1wOo9auuB26tqBXB7mz+sGRojC/ZxJVX1dFXd\n16Z/y+iXzoL5Vn2SZcB5wDVD9zLfkrwOeBdwLUBVvVRVzw/b1bxaDBydZDHwauC/B+5nIlX1Y2DX\nHuU1wKY2vQk4/6A2dQAYGiNHxONKkiwHTgXuHraTefU14DPAX4Zu5AA4GZgBvtUuv12T5Jihm5oP\nVbUT+DLwS+Bp4IWq+s9huzogTqyqp9v0M8CJQzYzHwyNI0SS1wDfBT5ZVS8O3c98SPI+4Nmqunfo\nXg6QxcBpwFVVdSrwOxbA5Q2Adm1/DaNgfCNwTJJ/GbarA6tGt6oe9rerGhojXY8rOVwleQWjwLih\nqm4dup95dAbw/iRPMLqkeGaS/xi2pXm1A9hRVS+fGd7CKEQWgvcAj1fVTFX9CbgV+KeBezoQfpXk\nDQDt/dmB+5mYoTGyYB9XkiSMrok/XFVfGbqf+VRVl1fVsqpazuj/2R1VtWD+Wq2qZ4Cnkry5lc4C\nHhqwpfn0S2BVkle3n9GzWCAf8u9hM7C2Ta8Fbhuwl3lxyH8j/GBY4I8rOQP4MPBAkp+22mfbN+11\n6Ps4cEP7Y+Yx4OKB+5kXVXV3kluA+xjd4Xc/h/m3p5PcCLwbOCHJDmADcAVwc5JLgCeBC4brcH74\njXBJUjcvT0mSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6va/DNfUHEci5pAAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0e43202c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(classes,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 12794.,   6163.,   4986.,   6304.,   5482.,   6953.,   6442.,\n",
       "          5801.,   5803.,  97810.]),\n",
       " array([  0. ,   1.1,   2.2,   3.3,   4.4,   5.5,   6.6,   7.7,   8.8,\n",
       "          9.9,  11. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEP9JREFUeJzt3W+sHXWdx/H3Z1tR0MgfaQi2ZEuyjaaSGPAG65IYIwaK\nGssDJZhdaQixD0RFY+IWnzRRSTAxoiRKQqRSXCISJKHRarcBjNkHIAWM/JNww992+XO1/HE1itXv\nPjg/ds+W2/bnPbdMe/t+JSdn5ju/mfkOtPdzz5yZaaoKSZJ6/MPQDUiSDh2GhiSpm6EhSepmaEiS\nuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkbouHbmC+HX/88bV8+fKh25CkQ8rdd9/926pasr9xCy40\nli9fzvbt24duQ5IOKUme6Bm339NTSTYmeS7J/WO145JsS/JIez+21ZPkyiTTSX6d5LSxdda28Y8k\nWTtWf1eS+9o6VybJvvYhSRpOz3ca1wKr96itB26tqhXArW0e4BxgRXutA66CUQAAG4B3A6cDG8ZC\n4Crgk2Prrd7PPiRJA9lvaFTVL4Bde5TXAJva9Cbg3LH6dTVyB3BMkhOBs4FtVbWrqp4HtgGr27I3\nV9UdNXrc7nV7bGu2fUiSBjLXq6dOqKqn2/QzwAlteinw1Ni4Ha22r/qOWer72ockaSATX3LbPiEc\n0H+UY3/7SLIuyfYk22dmZg5kK5J0WJtraDzbTi3R3p9r9Z3ASWPjlrXavurLZqnvax+vUlVXV9VU\nVU0tWbLfK8YkSXM019DYDLxyBdRa4Jax+gXtKqpVwIvtFNNW4Kwkx7YvwM8CtrZlLyVZ1a6aumCP\nbc22D0nSQPZ7n0aSHwDvA45PsoPRVVCXAzcmuQh4AjivDd8CfBCYBv4IXAhQVbuSfAW4q437clW9\n8uX6pxhdoXUk8NP2Yh/7kCQNJAvt3wifmpoqb+6TpL9Pkruramp/4xbcHeGSNKTl638yyH4fv/xD\nr8l+fGChJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZ\nGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZ\nGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqdtEoZHk80keSHJ/\nkh8keUOSk5PcmWQ6yQ+THNHGvr7NT7fly8e2c2mrP5zk7LH66labTrJ+kl4lSZObc2gkWQp8Fpiq\nqlOARcD5wNeAK6rqn4DngYvaKhcBz7f6FW0cSVa29d4BrAa+k2RRkkXAt4FzgJXAx9tYSdJAJj09\ntRg4Msli4CjgaeD9wE1t+Sbg3Da9ps3Tlp+ZJK1+Q1X9uaoeA6aB09truqoeraqXgRvaWEnSQOYc\nGlW1E/g68CSjsHgRuBt4oap2t2E7gKVteinwVFt3dxv/lvH6Huvsrf4qSdYl2Z5k+8zMzFwPSZK0\nH5OcnjqW0W/+JwNvBd7I6PTSa66qrq6qqaqaWrJkyRAtSNJhYZLTUx8AHquqmar6C3AzcAZwTDtd\nBbAM2NmmdwInAbTlRwO/G6/vsc7e6pKkgUwSGk8Cq5Ic1b6bOBN4ELgd+Ggbsxa4pU1vbvO05bdV\nVbX6+e3qqpOBFcAvgbuAFe1qrCMYfVm+eYJ+JUkTWrz/IbOrqjuT3ATcA+wG7gWuBn4C3JDkq612\nTVvlGuD7SaaBXYxCgKp6IMmNjAJnN3BxVf0VIMmnga2MrszaWFUPzLVfSdLk5hwaAFW1AdiwR/lR\nRlc+7Tn2T8DH9rKdy4DLZqlvAbZM0qMkaf54R7gkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZo\nSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZo\nSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZo\nSJK6GRqSpG6GhiSp20ShkeSYJDcl+U2Sh5K8J8lxSbYleaS9H9vGJsmVSaaT/DrJaWPbWdvGP5Jk\n7Vj9XUnua+tcmSST9CtJmsyknzS+Bfysqt4OvBN4CFgP3FpVK4Bb2zzAOcCK9loHXAWQ5DhgA/Bu\n4HRgwytB08Z8cmy91RP2K0mawJxDI8nRwHuBawCq6uWqegFYA2xqwzYB57bpNcB1NXIHcEySE4Gz\ngW1Vtauqnge2AavbsjdX1R1VVcB1Y9uSJA1gkk8aJwMzwPeS3Jvku0neCJxQVU+3Mc8AJ7TppcBT\nY+vvaLV91XfMUpckDWSS0FgMnAZcVVWnAn/g/05FAdA+IdQE++iSZF2S7Um2z8zMHOjdSdJha5LQ\n2AHsqKo72/xNjELk2XZqifb+XFu+EzhpbP1lrbav+rJZ6q9SVVdX1VRVTS1ZsmSCQ5Ik7cucQ6Oq\nngGeSvK2VjoTeBDYDLxyBdRa4JY2vRm4oF1FtQp4sZ3G2gqcleTY9gX4WcDWtuylJKvaVVMXjG1L\nkjSAxROu/xng+iRHAI8CFzIKohuTXAQ8AZzXxm4BPghMA39sY6mqXUm+AtzVxn25qna16U8B1wJH\nAj9tL0nSQCYKjar6FTA1y6IzZxlbwMV72c5GYOMs9e3AKZP0KEmaP94RLknqZmhIkroZGpKkboaG\nJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaG\nJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaG\nJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSeo2cWgkWZTk3iQ/bvMnJ7kzyXSSHyY5otVf3+an2/Ll\nY9u4tNUfTnL2WH11q00nWT9pr5KkyczHJ41LgIfG5r8GXFFV/wQ8D1zU6hcBz7f6FW0cSVYC5wPv\nAFYD32lBtAj4NnAOsBL4eBsrSRrIRKGRZBnwIeC7bT7A+4Gb2pBNwLltek2bpy0/s41fA9xQVX+u\nqseAaeD09pquqker6mXghjZWkjSQST9pfBP4IvC3Nv8W4IWq2t3mdwBL2/RS4CmAtvzFNv5/63us\ns7e6JGkgcw6NJB8Gnququ+exn7n2si7J9iTbZ2Zmhm5HkhasST5pnAF8JMnjjE4dvR/4FnBMksVt\nzDJgZ5veCZwE0JYfDfxuvL7HOnurv0pVXV1VU1U1tWTJkgkOSZK0L3MOjaq6tKqWVdVyRl9k31ZV\n/wLcDny0DVsL3NKmN7d52vLbqqpa/fx2ddXJwArgl8BdwIp2NdYRbR+b59qvJGlyi/c/5O/2b8AN\nSb4K3Atc0+rXAN9PMg3sYhQCVNUDSW4EHgR2AxdX1V8Bknwa2AosAjZW1QMHoF9JUqd5CY2q+jnw\n8zb9KKMrn/Yc8yfgY3tZ/zLgslnqW4At89GjJGly3hEuSepmaEiSuhkakqRuhoYkqZuhIUnqZmhI\nkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhI\nkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhI\nkroZGpKkboaGJKmboSFJ6mZoSJK6zTk0kpyU5PYkDyZ5IMklrX5ckm1JHmnvx7Z6klyZZDrJr5Oc\nNrattW38I0nWjtXfleS+ts6VSTLJwUqSJjPJJ43dwBeqaiWwCrg4yUpgPXBrVa0Abm3zAOcAK9pr\nHXAVjEIG2AC8Gzgd2PBK0LQxnxxbb/UE/UqSJjTn0Kiqp6vqnjb9e+AhYCmwBtjUhm0Czm3Ta4Dr\nauQO4JgkJwJnA9uqaldVPQ9sA1a3ZW+uqjuqqoDrxrYlSRrAvHynkWQ5cCpwJ3BCVT3dFj0DnNCm\nlwJPja22o9X2Vd8xS322/a9Lsj3J9pmZmYmORZK0dxOHRpI3AT8CPldVL40va58QatJ97E9VXV1V\nU1U1tWTJkgO9O0k6bE0UGklexygwrq+qm1v52XZqifb+XKvvBE4aW31Zq+2rvmyWuiRpIJNcPRXg\nGuChqvrG2KLNwCtXQK0FbhmrX9CuoloFvNhOY20FzkpybPsC/Cxga1v2UpJVbV8XjG1LkjSAxROs\newbwCeC+JL9qtS8BlwM3JrkIeAI4ry3bAnwQmAb+CFwIUFW7knwFuKuN+3JV7WrTnwKuBY4Eftpe\nkqSBzDk0quo/gb3dN3HmLOMLuHgv29oIbJylvh04Za49SpLml3eES5K6GRqSpG6GhiSpm6EhSepm\naEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkbpM8e2rBWb7+J4Ps9/HLPzTIfiXp7+UnDUlSN0ND\nktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR189lT0mtkqGebgc83\n0/wxNDQIf4C+tnwYp+aLoXEQ8AeopEOFoaHDzpAhfbjxv/XCY2gc5vxLLenv4dVTkqRuhoYkqZuh\nIUnqZmhIkroZGpKkboaGJKnbQR8aSVYneTjJdJL1Q/cjSYezgzo0kiwCvg2cA6wEPp5k5bBdSdLh\n66AODeB0YLqqHq2ql4EbgDUD9yRJh62DPTSWAk+Nze9oNUnSABbEY0SSrAPWtdn/TvLwHDd1PPDb\n+enqoLOQjw0W9vF5bIeu1+z48rWJN/GPPYMO9tDYCZw0Nr+s1f6fqroauHrSnSXZXlVTk27nYLSQ\njw0W9vF5bIeuhXh8B/vpqbuAFUlOTnIEcD6weeCeJOmwdVB/0qiq3Uk+DWwFFgEbq+qBgduSpMPW\nQR0aAFW1BdjyGu1u4lNcB7GFfGywsI/PYzt0LbjjS1UN3YMk6RBxsH+nIUk6iBgazUJ9XEmSk5Lc\nnuTBJA8kuWTonuZbkkVJ7k3y46F7mW9JjklyU5LfJHkoyXuG7mm+JPl8+zN5f5IfJHnD0D1NIsnG\nJM8luX+sdlySbUkeae/HDtnjfDA0WPCPK9kNfKGqVgKrgIsX0LG94hLgoaGbOEC+Bfysqt4OvJMF\ncpxJlgKfBaaq6hRGF7qcP2xXE7sWWL1HbT1wa1WtAG5t84c0Q2NkwT6upKqerqp72vTvGf3QWTB3\n1SdZBnwI+O7Qvcy3JEcD7wWuAaiql6vqhWG7mleLgSOTLAaOAv5r4H4mUlW/AHbtUV4DbGrTm4Bz\nX9OmDgBDY+SweFxJkuXAqcCdw3Yyr74JfBH429CNHAAnAzPA99rpt+8meePQTc2HqtoJfB14Enga\neLGq/mPYrg6IE6rq6Tb9DHDCkM3MB0PjMJHkTcCPgM9V1UtD9zMfknwYeK6q7h66lwNkMXAacFVV\nnQr8gQVwegOgndtfwygY3wq8Mcm/DtvVgVWjS1UP+ctVDY2RrseVHKqSvI5RYFxfVTcP3c88OgP4\nSJLHGZ1SfH+Sfx+2pXm1A9hRVa98MryJUYgsBB8AHquqmar6C3Az8M8D93QgPJvkRID2/tzA/UzM\n0BhZsI8rSRJG58QfqqpvDN3PfKqqS6tqWVUtZ/T/7LaqWjC/rVbVM8BTSd7WSmcCDw7Y0nx6EliV\n5Kj2Z/RMFsiX/HvYDKxt02uBWwbsZV4c9HeEvxYW+ONKzgA+AdyX5Fet9qV2p70Ofp8Brm+/zDwK\nXDhwP/Oiqu5MchNwD6Mr/O7lEL97OskPgPcBxyfZAWwALgduTHIR8ARw3nAdzg/vCJckdfP0lCSp\nm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkbv8DPwfBD8H+JFsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fae23e18f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(classes,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 13314.,   6425.,   5008.,   5968.,   5353.,   7153.,   6788.,\n",
       "          5934.,   6366.,  96229.]),\n",
       " array([  0. ,   1.1,   2.2,   3.3,   4.4,   5.5,   6.6,   7.7,   8.8,\n",
       "          9.9,  11. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDUlSt/8BXtnVYojrSqoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fae232f6910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(classes,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 12750.,   6091.,   5142.,   6350.,   5542.,   6960.,   6424.,\n",
       "          5745.,   6265.,  97269.]),\n",
       " array([  0. ,   1.1,   2.2,   3.3,   4.4,   5.5,   6.6,   7.7,   8.8,\n",
       "          9.9,  11. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f982f3ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(classes,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 13344.,   6234.,   5208.,   6607.,   5785.,   7365.,   6680.,\n",
       "          5825.,   6508.,  94982.]),\n",
       " array([  0. ,   1.1,   2.2,   3.3,   4.4,   5.5,   6.6,   7.7,   8.8,\n",
       "          9.9,  11. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkqSOcZAkdYyDJKnzv2BTFqa27TIrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3fbac050d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(classes,bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:31:11.212517Z",
     "start_time": "2017-11-17T11:31:10.786357Z"
    },
    "_cell_guid": "1da523cf-fdbf-4ab1-9300-0147155aa247",
    "_uuid": "f25d4e626202aa115bd0460f4de8d07f9727c83e"
   },
   "outputs": [],
   "source": [
    "### last batch will contain padding, so remove duplicates\n",
    "submission = dict()\n",
    "for i in range(len(test_paths)):\n",
    "    fname, label = os.path.basename(test_paths[i]), id2name[classes[i]]\n",
    "    submission[fname] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:32:05.154527Z",
     "start_time": "2017-11-17T11:32:04.983371Z"
    },
    "_cell_guid": "9a95d147-3f4b-4386-8597-5fa60be43542",
    "_uuid": "bdf63bce43a0525a02ac18ca3f90aeba06ce6e99"
   },
   "outputs": [],
   "source": [
    "with open('subm/{}.csv'.format(\"bestof_freqconvs1d_3_10_142_0_0_08\"), 'w') as fout: #_blend_conv1dlstm_and_aebased_conv2d_finetuned\n",
    "    fout.write('fname,label\\n')\n",
    "    for fname, label in submission.items():\n",
    "        fout.write('{},{}\\n'.format(fname, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_cell_guid": "8bea6850-15c6-44e7-bdb4-9555ad196f85",
    "_uuid": "555315ef622793711ff5643928dac874c8cb0ed2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='subm/bestof_freqconvs1d_3_10_142_0_0_08.csv' target='_blank'>subm/bestof_freqconvs1d_3_10_142_0_0_08.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/keyword_spotting/subm/bestof_freqconvs1d_3_10_142_0_0_08.csv"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.lib.display import FileLink\n",
    "\n",
    "FileLink('subm/{}.csv'.format(\"bestof_freqconvs1d_3_10_142_0_0_08\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
