{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c2883459-a9c2-45f1-9df1-1986a0488f07",
    "_uuid": "8e9ff83b354d98b475b9924ddeb81984c7f1f02f"
   },
   "source": [
    "Based on tensorflow starter code from https://www.kaggle.com/alexozerin/end-to-end-baseline-tf-estimator-lb-0-72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:29.196238Z",
     "start_time": "2017-11-17T09:03:28.644004Z"
    },
    "_cell_guid": "679e0d3e-646d-4e96-9eb0-b362d8c6e51f",
    "_uuid": "0d05e5ce89af3e25d1c1fb244d021a1cfa1a058c"
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import array \n",
    "\n",
    "from pydub import AudioSegment\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Conv2D, Flatten, MaxPooling2D, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPool2D, concatenate, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:29.210749Z",
     "start_time": "2017-11-17T09:03:29.19832Z"
    },
    "_cell_guid": "8ab00801-08b9-44d3-a063-32e82dbf8f58",
    "_uuid": "53c19941676690454dd4b91109976b6c59cb7a40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "len(id2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:29.325023Z",
     "start_time": "2017-11-17T09:03:29.215137Z"
    },
    "_cell_guid": "8d7ebf53-700b-4c06-b5c2-ccf9ed5f27e0",
    "_uuid": "133424c750b26df37900f9cebcfd2f2fb803cb8b"
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    np.random.seed = 1\n",
    "    \n",
    "    \"\"\" Return 2 lists of tuples:\n",
    "    [(class_id, user_id, path), ...] for train\n",
    "    [(class_id, user_id, path), ...] for validation\n",
    "    \"\"\"\n",
    "    # Just a simple regexp for paths with three groups:\n",
    "    # prefix, label, user_id\n",
    "#     pattern = re.compile(\"(.+\\/)?(\\w+)\\/([^_]+)_.+wav\")\n",
    "    pattern  =  re.compile(\"(.+[\\/\\\\\\\\])?(\\w+)[\\/\\\\\\\\]([^_]+)_.+wav\")\n",
    "    all_files = glob(os.path.join(data_dir, 'train/audio/*/*wav'))\n",
    "\n",
    "    with open(os.path.join(data_dir, 'train/validation_list.txt'), 'r') as fin:\n",
    "        validation_files = fin.readlines()\n",
    "        \n",
    "    valset = set()\n",
    "    for entry in validation_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            valset.add(r.group(3))\n",
    "    \n",
    "    possible = set(POSSIBLE_LABELS)\n",
    "    \n",
    "    train, val, silent, unknown = [], [],[],[]\n",
    "    \n",
    "    for entry in all_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            label, uid = r.group(2), r.group(3)\n",
    "            \n",
    "            if label == '_background_noise_': #we've already split up noise files into 1 seg chunks under 'silence' folder\n",
    "                continue\n",
    "                \n",
    "            if label not in possible:\n",
    "                label = 'unknown'\n",
    "\n",
    "            label_id = name2id[label]\n",
    "            sample = (label, label_id, uid, entry)\n",
    "            \n",
    "            if label == \"unknown\":\n",
    "                unknown.append(sample)\n",
    "            elif label == \"silence\":\n",
    "                silent.append(sample)\n",
    "                \n",
    "            elif uid in valset:    \n",
    "                val.append(sample)\n",
    "            else:\n",
    "                train.append(sample)\n",
    "\n",
    "    print('There are {} train and {} val samples'.format(len(train), len(val)))\n",
    "    \n",
    "    columns_list = ['label', 'label_id', 'user_id', 'wav_file']\n",
    "    \n",
    "\n",
    "    train_df = pd.DataFrame(train, columns = columns_list)\n",
    "    valid_df = pd.DataFrame(val, columns = columns_list)\n",
    "    silent_df = pd.DataFrame(silent, columns = columns_list)\n",
    "    unknown_df = pd.DataFrame(unknown, columns = columns_list)\n",
    "    \n",
    "    return train_df, valid_df, unknown_df, silent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:30.166379Z",
     "start_time": "2017-11-17T09:03:29.327228Z"
    },
    "_cell_guid": "27b5bff1-e5f8-409d-ab51-46e698342eb1",
    "_uuid": "ad204124a777e6677dcca8aac32d34de8e0cfc5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21105 train and 2577 val samples\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df, unknown_df, silent_df = load_data('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:30.195961Z",
     "start_time": "2017-11-17T09:03:30.171067Z"
    },
    "_cell_guid": "3fc0b536-7c1f-41de-8266-94221d53d7dd",
    "_uuid": "5f5434462366b087b747875c071a02a49a0509c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>wav_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left</td>\n",
       "      <td>4</td>\n",
       "      <td>cb8f8307</td>\n",
       "      <td>./data/train/audio/left/cb8f8307_nohash_1.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  label_id   user_id                                       wav_file\n",
       "0  left         4  cb8f8307  ./data/train/audio/left/cb8f8307_nohash_1.wav"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:30.297759Z",
     "start_time": "2017-11-17T09:03:30.197702Z"
    },
    "_cell_guid": "2e846e85-3902-4f06-95c5-e83a25a074d2",
    "_uuid": "44caca4db5dd9a17807b602a1bc1f79c2a8b3450"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stop     2134\n",
       "yes      2116\n",
       "up       2115\n",
       "go       2112\n",
       "right    2111\n",
       "on       2110\n",
       "left     2106\n",
       "no       2105\n",
       "off      2101\n",
       "down     2095\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no       270\n",
       "down     264\n",
       "yes      261\n",
       "up       260\n",
       "go       260\n",
       "on       257\n",
       "off      256\n",
       "right    256\n",
       "left     247\n",
       "stop     246\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augment validation set with silence and unknown files, made with step=250 when generating silence files\n",
    "extra_data_size = int(valid_df.shape[0]*0.1)\n",
    "\n",
    "unknown_val = unknown_df.sample(extra_data_size,random_state=1)\n",
    "unknown_df = unknown_df[~unknown_df.index.isin(unknown_val.index.values)]\n",
    "\n",
    "silent_val = silent_df.sample(extra_data_size,random_state=1)\n",
    "silent_df = silent_df[~silent_df.index.isin(silent_val.index.values)]\n",
    "\n",
    "\n",
    "valid_df = pd.concat([valid_df,silent_val,unknown_val],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:30.448259Z",
     "start_time": "2017-11-17T09:03:30.299457Z"
    },
    "_cell_guid": "65ea1b22-6563-4879-a622-f45d8818e465",
    "_uuid": "4ebfe2201a69fa3bbfd83eff917645ea4a0a0d22"
   },
   "outputs": [],
   "source": [
    "# silence_files = train_df[train_df.label == 'silence']\n",
    "# train_df      = train_df[train_df.label != 'silence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 196 ms, sys: 64 ms, total: 260 ms\n",
      "Wall time: 260 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "silence_files_AS = [AudioSegment.from_wav(x) for x in silent_df.wav_file.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    <audio controls>\n",
       "                        <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\"/>\n",
       "                        Your browser does not support the audio element.\n",
       "                    </audio>\n",
       "                  "
      ],
      "text/plain": [
       "<pydub.audio_segment.AudioSegment at 0x7f9dd8310d10>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(silence_files_AS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filler = AudioSegment.silent(duration=1000, frame_rate = 16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_to_1sec(wav):\n",
    "    #fill to 1 second\n",
    "    L = 1000 #16000  # 1 sec\n",
    "    sample_rate = 16000\n",
    "    \n",
    "    if len(wav) > L:\n",
    "        i = np.random.randint(0, len(wav) - L)\n",
    "        wav = wav[i:(i+L)]\n",
    "    elif len(wav) < L:\n",
    "        rem_len = L - len(wav)\n",
    "        wav = AudioSegment.silent(rem_len,frame_rate=sample_rate) + wav\n",
    "        \n",
    "    return wav    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_wav(wav,pval=0.5):\n",
    "    sample_rate = 16000\n",
    "    L = 1000 #16000  # 1 sec\n",
    "    \n",
    "    #adjust speed, with 50% chance\n",
    "    wav = speed_change(wav,1.+random.uniform(-1, 1)*0.05) if np.random.random() < pval else wav\n",
    "    \n",
    "    \n",
    "    #adjust volume\n",
    "    db_adjustment = random.uniform(-1, 1)*10\n",
    "    wav = wav + db_adjustment if np.random.random() < pval else wav\n",
    "     \n",
    "        \n",
    "    #fill to 1 second\n",
    "    wav = fill_to_1sec(wav)        \n",
    "        \n",
    "    #shift the audio by 10 ms\n",
    "    shift_length = 100\n",
    "    if np.random.random() < 0.5: #shift to left\n",
    "        wav = wav[:L-shift_length]+ AudioSegment.silent(shift_length,frame_rate=sample_rate)\n",
    "    else: #shift to right\n",
    "        wav = AudioSegment.silent(shift_length,frame_rate=sample_rate) + wav[shift_length:]\n",
    "        \n",
    "        \n",
    "        \n",
    "    #blend original file with background noise     \n",
    "    if np.random.random() < pval:\n",
    "        noise = random.choice(silence_files_AS)\n",
    "        db_delta = (wav.dBFS - noise.dBFS) -10.\n",
    "\n",
    "        if db_delta< 0: #reduce intensity of loud background; if it's too silent, leave it be\n",
    "            noise = noise  + db_delta\n",
    "        wav = wav.overlay(noise)\n",
    " \n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:31.144688Z",
     "start_time": "2017-11-17T09:03:31.105987Z"
    },
    "_cell_guid": "9e32f039-712e-4f1d-9173-ed9804d7771f",
    "_uuid": "36562e906f4fd6739b55582239ab55d947a80766"
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_wav_file(record, reshape=False, augment=True,pval=0.5):\n",
    "    \n",
    "    if type(record) == str: # test files\n",
    "        fname = record\n",
    "        label = \"test\"\n",
    "    else:    \n",
    "        fname  = record.wav_file\n",
    "        label = record.label\n",
    "    \n",
    "    wav = AudioSegment.from_wav(fname)\n",
    "\n",
    "    \n",
    "    if (not label in [\"silence\"]) and augment: #no augmentation for sample files \n",
    "        wav = augment_wav(wav,pval)\n",
    "\n",
    "    else:\n",
    "        #make sure segment is 1 second\n",
    "        wav = fill_to_1sec(wav)\n",
    "\n",
    "    samples = AS_to_raw(wav)\n",
    "    \n",
    "\n",
    "    return log_mel(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:32.519795Z",
     "start_time": "2017-11-17T09:03:32.483881Z"
    },
    "_cell_guid": "144c6e60-8a83-437d-8b8a-ea065af90923",
    "_uuid": "22e0e6c718171167089fb6df36d3dc43a1029992"
   },
   "outputs": [],
   "source": [
    "def train_generator(train_batch_size):\n",
    "    while True:\n",
    "        this_train = train_df.groupby('label_id').apply(lambda x: x.sample(n = 2000))\n",
    "        extra_data_size = int(this_train.shape[0]* 0.1)\n",
    "        this_train = pd.concat([silent_df.sample(extra_data_size),\n",
    "                                this_train,\n",
    "                                unknown_df.sample(extra_data_size)])\n",
    "        \n",
    "        shuffled_ids = random.sample(range(this_train.shape[0]), this_train.shape[0])\n",
    "        for start in range(0, len(shuffled_ids), train_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + train_batch_size, len(shuffled_ids))\n",
    "            i_train_batch = shuffled_ids[start:end]\n",
    "            for i in i_train_batch:\n",
    "                x_batch.append(process_wav_file(this_train.iloc[i],reshape=True))\n",
    "                y_batch.append(this_train.label_id.values[i])\n",
    "            x_batch = np.array(x_batch)\n",
    "            y_batch = to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:32.624289Z",
     "start_time": "2017-11-17T09:03:32.521828Z"
    },
    "_cell_guid": "59a13393-9bc3-4b27-abe2-9c78b3c32ead",
    "_uuid": "6f9a8fbf6e352b1c77b9c22dddf1c5d69382bd5b"
   },
   "outputs": [],
   "source": [
    "def valid_generator(val_batch_size):\n",
    "    while True:\n",
    "        ids = list(range(valid_df.shape[0]))\n",
    "        for start in range(0, len(ids), val_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + val_batch_size, len(ids))\n",
    "            i_val_batch = ids[start:end]\n",
    "            for i in i_val_batch:\n",
    "                x_batch.append(process_wav_file(valid_df.iloc[i],reshape=True,augment=False))\n",
    "                y_batch.append(valid_df.label_id.values[i])\n",
    "#                 try:\n",
    "#                     if np.array(x_batch[-1]).shape != (128,32,1):\n",
    "#                         print np.array(x_batch[-1]).shape\n",
    "#                 except:\n",
    "#                     print x_batch[-1] \n",
    "            x_batch = np.array(x_batch)\n",
    "            y_batch = to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "exp_name = \"pyramid_conv\"\n",
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=5,\n",
    "                           verbose=1,\n",
    "                           mode='min'),\n",
    "             ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               epsilon=0.01,\n",
    "                               mode='min'),\n",
    "             ModelCheckpoint(monitor='val_loss',\n",
    "                             filepath='weights/starter_{}.hdf5'.format(exp_name),\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='min'),\n",
    "#              TQDMNotebookCallback(), \n",
    "            TensorBoard(log_dir='./logs_{}'.format(exp_name), histogram_freq=0, batch_size=64, write_graph=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a common practice is to choose a filter size in time which spans 2/3 o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:33.180074Z",
     "start_time": "2017-11-17T09:03:32.625939Z"
    },
    "_cell_guid": "0e13c01e-5662-4679-9b31-bf9347080ae5",
    "_uuid": "a17b3ea5c15c781260f3473f37dd0d36a932a565"
   },
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "\n",
    "x_in = Input(shape = (128,32,1)) #1 channel, 99 time, 161 freqs # S : np.ndarray [shape=(n_mels, t)]\n",
    "\n",
    "x = BatchNormalization()(x_in)\n",
    "\n",
    "x = Conv2D(64, (9,10),activation='relu',padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3,2),padding='same')(x)\n",
    "\n",
    "x = Conv2D(128, (4,5),activation='relu',padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3,2),padding='same')(x)\n",
    "\n",
    "\n",
    "x = Conv2D(128, (2,2),activation='relu',padding='same')(x)\n",
    "x = Dropout(p)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(padding='same')(x)\n",
    "\n",
    "\n",
    "\n",
    "x = GlobalMaxPool2D()(x)\n",
    "\n",
    "# x = Flatten()(x)\n",
    "x = Dense(64, activation = 'relu')(x) #\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "# x = Dense(64, activation = 'relu')(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(len(POSSIBLE_LABELS), activation = 'softmax', name='targets')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs = x_in, outputs = x)\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 128, 32, 1)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 128, 32, 1)        4         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 128, 32, 64)       5824      \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 128, 32, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 128, 32, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 43, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 43, 16, 128)       163968    \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 43, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 43, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 15, 8, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 15, 8, 128)        65664     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 15, 8, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 15, 8, 128)        512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 8, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_9 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "targets (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 245,776\n",
      "Trainable params: 245,134\n",
      "Non-trainable params: 642\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('weights/starter.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.shape[0]/64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 14/100\n",
    "300/300 [==============================] - 214s - loss: 0.7612 - acc: 0.7370 - val_loss: 1.0481 - val_acc: 0.6508\n",
    "\n",
    "\n",
    "\n",
    "Epoch 31/100\n",
    "350/350 [==============================] - 227s - loss: 0.4294 - acc: 0.8518 - val_loss: 0.9436 - val_acc: 0.7179\n",
    "Epoch 32/100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:42:31.48233Z",
     "start_time": "2017-11-17T09:03:33.355603Z"
    },
    "_cell_guid": "5f3d1b09-500f-410e-820a-8eaab24b6ebb",
    "_uuid": "528ec66a0a6caca952273ab916e609625839b19e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "329/329 [==============================] - 183s - loss: 2.3884 - acc: 0.1688 - val_loss: 2.4542 - val_acc: 0.1081\n",
      "Epoch 2/100\n",
      "329/329 [==============================] - 181s - loss: 2.2381 - acc: 0.1920 - val_loss: 2.4275 - val_acc: 0.1077\n",
      "Epoch 3/100\n",
      "329/329 [==============================] - 184s - loss: 2.1934 - acc: 0.1967 - val_loss: 2.3040 - val_acc: 0.1862\n",
      "Epoch 4/100\n",
      "329/329 [==============================] - 183s - loss: 2.1199 - acc: 0.2055 - val_loss: 2.2777 - val_acc: 0.2077\n",
      "Epoch 5/100\n",
      "329/329 [==============================] - 182s - loss: 2.0460 - acc: 0.2271 - val_loss: 2.1666 - val_acc: 0.2331\n",
      "Epoch 6/100\n",
      "329/329 [==============================] - 187s - loss: 1.9692 - acc: 0.2685 - val_loss: 2.1237 - val_acc: 0.3066\n",
      "Epoch 7/100\n",
      "329/329 [==============================] - 184s - loss: 1.8317 - acc: 0.3185 - val_loss: 2.0171 - val_acc: 0.3643\n",
      "Epoch 8/100\n",
      "329/329 [==============================] - 185s - loss: 1.7181 - acc: 0.3600 - val_loss: 1.7930 - val_acc: 0.4629\n",
      "Epoch 9/100\n",
      "329/329 [==============================] - 189s - loss: 1.5452 - acc: 0.4163 - val_loss: 1.8369 - val_acc: 0.4082\n",
      "Epoch 10/100\n",
      "329/329 [==============================] - 183s - loss: 1.4101 - acc: 0.4655 - val_loss: 1.5928 - val_acc: 0.5212\n",
      "Epoch 11/100\n",
      "329/329 [==============================] - 187s - loss: 1.3577 - acc: 0.4763 - val_loss: 1.4610 - val_acc: 0.6146\n",
      "Epoch 12/100\n",
      "329/329 [==============================] - 183s - loss: 1.3057 - acc: 0.4991 - val_loss: 1.4606 - val_acc: 0.6364\n",
      "Epoch 13/100\n",
      "329/329 [==============================] - 185s - loss: 1.2749 - acc: 0.5125 - val_loss: 1.3982 - val_acc: 0.6784\n",
      "Epoch 14/100\n",
      "329/329 [==============================] - 187s - loss: 1.2443 - acc: 0.5213 - val_loss: 1.2992 - val_acc: 0.7350\n",
      "Epoch 15/100\n",
      "329/329 [==============================] - 182s - loss: 1.2200 - acc: 0.5281 - val_loss: 1.3514 - val_acc: 0.6751\n",
      "Epoch 16/100\n",
      "329/329 [==============================] - 183s - loss: 1.1906 - acc: 0.5502 - val_loss: 1.3187 - val_acc: 0.6602\n",
      "Epoch 17/100\n",
      "329/329 [==============================] - 182s - loss: 1.1657 - acc: 0.5583 - val_loss: 1.2803 - val_acc: 0.7493\n",
      "Epoch 18/100\n",
      "329/329 [==============================] - 183s - loss: 1.1477 - acc: 0.5712 - val_loss: 1.3040 - val_acc: 0.7021\n",
      "Epoch 19/100\n",
      "329/329 [==============================] - 183s - loss: 1.1351 - acc: 0.5768 - val_loss: 1.2811 - val_acc: 0.7005\n",
      "Epoch 20/100\n",
      "329/329 [==============================] - 185s - loss: 1.1336 - acc: 0.5693 - val_loss: 1.1321 - val_acc: 0.7809\n",
      "Epoch 21/100\n",
      "329/329 [==============================] - 189s - loss: 1.1033 - acc: 0.5904 - val_loss: 1.1469 - val_acc: 0.7982\n",
      "Epoch 22/100\n",
      "329/329 [==============================] - 192s - loss: 1.0950 - acc: 0.5909 - val_loss: 1.1654 - val_acc: 0.7412\n",
      "Epoch 23/100\n",
      "329/329 [==============================] - 186s - loss: 1.0711 - acc: 0.6043 - val_loss: 1.1887 - val_acc: 0.6999\n",
      "Epoch 24/100\n",
      "329/329 [==============================] - 187s - loss: 1.0419 - acc: 0.6181 - val_loss: 1.1080 - val_acc: 0.7295\n",
      "Epoch 25/100\n",
      "329/329 [==============================] - 182s - loss: 1.0245 - acc: 0.6311 - val_loss: 1.0479 - val_acc: 0.7695\n",
      "Epoch 26/100\n",
      "329/329 [==============================] - 189s - loss: 0.9856 - acc: 0.6479 - val_loss: 1.1707 - val_acc: 0.6735\n",
      "Epoch 27/100\n",
      "329/329 [==============================] - 183s - loss: 0.9691 - acc: 0.6517 - val_loss: 0.9986 - val_acc: 0.7904\n",
      "Epoch 28/100\n",
      "329/329 [==============================] - 182s - loss: 0.9559 - acc: 0.6596 - val_loss: 0.9650 - val_acc: 0.8053\n",
      "Epoch 29/100\n",
      "329/329 [==============================] - 186s - loss: 0.9460 - acc: 0.6605 - val_loss: 1.0277 - val_acc: 0.7812\n",
      "Epoch 30/100\n",
      "329/329 [==============================] - 184s - loss: 0.9193 - acc: 0.6756 - val_loss: 0.9177 - val_acc: 0.8115\n",
      "Epoch 31/100\n",
      "329/329 [==============================] - 184s - loss: 0.9029 - acc: 0.6779 - val_loss: 0.9408 - val_acc: 0.7975\n",
      "Epoch 32/100\n",
      "329/329 [==============================] - 189s - loss: 0.9044 - acc: 0.6777 - val_loss: 0.9905 - val_acc: 0.7757\n",
      "Epoch 33/100\n",
      "329/329 [==============================] - 189s - loss: 0.9072 - acc: 0.6795 - val_loss: 0.9537 - val_acc: 0.8044\n",
      "Epoch 34/100\n",
      "329/329 [==============================] - 181s - loss: 0.8906 - acc: 0.6863 - val_loss: 0.9065 - val_acc: 0.7969\n",
      "Epoch 35/100\n",
      "329/329 [==============================] - 183s - loss: 0.8672 - acc: 0.6932 - val_loss: 0.9246 - val_acc: 0.8027\n",
      "Epoch 36/100\n",
      "329/329 [==============================] - 183s - loss: 0.8582 - acc: 0.6931 - val_loss: 0.8836 - val_acc: 0.8086\n",
      "Epoch 37/100\n",
      "329/329 [==============================] - 183s - loss: 0.8558 - acc: 0.6983 - val_loss: 0.8213 - val_acc: 0.8337\n",
      "Epoch 38/100\n",
      "329/329 [==============================] - 191s - loss: 0.8536 - acc: 0.7024 - val_loss: 0.9549 - val_acc: 0.7669\n",
      "Epoch 39/100\n",
      "329/329 [==============================] - 186s - loss: 0.8423 - acc: 0.7054 - val_loss: 0.9063 - val_acc: 0.7949\n",
      "Epoch 40/100\n",
      "329/329 [==============================] - 186s - loss: 0.8291 - acc: 0.7109 - val_loss: 0.8890 - val_acc: 0.8268\n",
      "Epoch 41/100\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.8278 - acc: 0.7097\n",
      "Epoch 00040: reducing learning rate to 0.00010000000475.\n",
      "329/329 [==============================] - 181s - loss: 0.8282 - acc: 0.7095 - val_loss: 0.8375 - val_acc: 0.8294\n",
      "Epoch 42/100\n",
      "329/329 [==============================] - 186s - loss: 0.7844 - acc: 0.7267 - val_loss: 0.7631 - val_acc: 0.8639\n",
      "Epoch 43/100\n",
      "329/329 [==============================] - 186s - loss: 0.7625 - acc: 0.7365 - val_loss: 0.7530 - val_acc: 0.8630\n",
      "Epoch 44/100\n",
      "329/329 [==============================] - 186s - loss: 0.7584 - acc: 0.7370 - val_loss: 0.7522 - val_acc: 0.8623\n",
      "Epoch 45/100\n",
      "329/329 [==============================] - 182s - loss: 0.7744 - acc: 0.7339 - val_loss: 0.7504 - val_acc: 0.8672\n",
      "Epoch 46/100\n",
      "329/329 [==============================] - 189s - loss: 0.7629 - acc: 0.7346 - val_loss: 0.7374 - val_acc: 0.8652\n",
      "Epoch 47/100\n",
      "329/329 [==============================] - 184s - loss: 0.7460 - acc: 0.7410 - val_loss: 0.7353 - val_acc: 0.8665\n",
      "Epoch 48/100\n",
      "329/329 [==============================] - 186s - loss: 0.7534 - acc: 0.7378 - val_loss: 0.7359 - val_acc: 0.8594\n",
      "Epoch 49/100\n",
      "329/329 [==============================] - 184s - loss: 0.7456 - acc: 0.7448 - val_loss: 0.7385 - val_acc: 0.8626\n",
      "Epoch 50/100\n",
      "329/329 [==============================] - 183s - loss: 0.7458 - acc: 0.7427 - val_loss: 0.7257 - val_acc: 0.8636\n",
      "Epoch 51/100\n",
      "329/329 [==============================] - 187s - loss: 0.7337 - acc: 0.7461 - val_loss: 0.7298 - val_acc: 0.8714\n",
      "Epoch 52/100\n",
      "329/329 [==============================] - 188s - loss: 0.7478 - acc: 0.7440 - val_loss: 0.7276 - val_acc: 0.8717\n",
      "Epoch 53/100\n",
      "329/329 [==============================] - 184s - loss: 0.7375 - acc: 0.7471 - val_loss: 0.7335 - val_acc: 0.8783\n",
      "Epoch 54/100\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.7477 - acc: 0.7453\n",
      "Epoch 00053: reducing learning rate to 1.0000000475e-05.\n",
      "329/329 [==============================] - 185s - loss: 0.7479 - acc: 0.7453 - val_loss: 0.7160 - val_acc: 0.8721\n",
      "Epoch 55/100\n",
      "329/329 [==============================] - 182s - loss: 0.7368 - acc: 0.7479 - val_loss: 0.7124 - val_acc: 0.8750\n",
      "Epoch 56/100\n",
      "329/329 [==============================] - 187s - loss: 0.7351 - acc: 0.7477 - val_loss: 0.7154 - val_acc: 0.8776\n",
      "Epoch 57/100\n",
      "329/329 [==============================] - 185s - loss: 0.7322 - acc: 0.7482 - val_loss: 0.7176 - val_acc: 0.8773\n",
      "Epoch 58/100\n",
      "329/329 [==============================] - 184s - loss: 0.7252 - acc: 0.7501 - val_loss: 0.7152 - val_acc: 0.8776\n",
      "Epoch 59/100\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.7286 - acc: 0.7521\n",
      "Epoch 00058: reducing learning rate to 1.00000006569e-06.\n",
      "329/329 [==============================] - 191s - loss: 0.7292 - acc: 0.7521 - val_loss: 0.7132 - val_acc: 0.8770\n",
      "Epoch 60/100\n",
      "329/329 [==============================] - 184s - loss: 0.7324 - acc: 0.7504 - val_loss: 0.7126 - val_acc: 0.8776\n",
      "Epoch 61/100\n",
      "329/329 [==============================] - 187s - loss: 0.7268 - acc: 0.7511 - val_loss: 0.7140 - val_acc: 0.8766\n",
      "Epoch 00060: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_generator(64),\n",
    "                              steps_per_epoch=train_df.shape[0]/64,\n",
    "                              epochs=100,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=valid_generator(64),\n",
    "                              validation_steps=int(np.ceil(valid_df.shape[0]/64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:24:59.198625Z",
     "start_time": "2017-11-17T10:24:59.081762Z"
    },
    "_cell_guid": "0c99ba3b-e8ca-40cb-8d29-2b0e89a385c7",
    "_uuid": "429139ca4f71487c6cfe3e8dfbb6a659eb9bb9c8"
   },
   "outputs": [],
   "source": [
    "model.load_weights('./weights/starter_pyramid_conv.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:28:14.451612Z",
     "start_time": "2017-11-17T10:28:13.307142Z"
    },
    "_cell_guid": "72f27090-c0d1-4d0b-8027-34c915429a79",
    "_uuid": "1007977fccadecdae582ec5d8d52dd3c4c3010aa"
   },
   "outputs": [],
   "source": [
    "test_paths = glob(os.path.join('./data/', 'test/audio/*wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158538"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:32:14.882322Z",
     "start_time": "2017-11-17T10:32:14.863617Z"
    },
    "_cell_guid": "c6d9b369-9979-4bcd-8540-4653e6544f84",
    "_uuid": "6a0bb3c22b7b5c43db0ec5673333ab3de8f08724"
   },
   "outputs": [],
   "source": [
    "def test_generator(test_batch_size,augment=False):\n",
    "    while True:\n",
    "        for start in range(0, len(test_paths), test_batch_size):\n",
    "            x_batch = []\n",
    "            end = min(start + test_batch_size, len(test_paths))\n",
    "            this_paths = test_paths[start:end]\n",
    "            for x in this_paths:\n",
    "                x_batch.append(process_wav_file(x,reshape=True,augment=augment,pval=0.5))\n",
    "            x_batch = np.array(x_batch)\n",
    "            yield x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-17T10:32:45.947Z"
    },
    "_cell_guid": "1fb8aed4-de12-43c5-84bf-b803e3d640fa",
    "_uuid": "631a38cb0013e5772f6987854145ad76ecf6c430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2478/2478 [==============================] - 1230s  \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(test_generator(64,augment=False), int(np.ceil(len(test_paths)/64.)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cache/predictions_pyramid_noaug.npy\",predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477/2478 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "num_aug = 2 \n",
    "for i in range(num_aug):\n",
    "    predictions +=  model.predict_generator(test_generator(64,augment=True), int(np.ceil(len(test_paths)/64.)), verbose=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions/(num_aug + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:30:44.236246Z",
     "start_time": "2017-11-17T11:30:44.21858Z"
    },
    "_cell_guid": "b1cdab5c-9816-4690-87d8-de2c97cf0e7d",
    "_uuid": "24eb7e512eace4567494e0a8e356a826f4283c4d"
   },
   "outputs": [],
   "source": [
    "classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:31:11.212517Z",
     "start_time": "2017-11-17T11:31:10.786357Z"
    },
    "_cell_guid": "1da523cf-fdbf-4ab1-9300-0147155aa247",
    "_uuid": "f25d4e626202aa115bd0460f4de8d07f9727c83e"
   },
   "outputs": [],
   "source": [
    "# last batch will contain padding, so remove duplicates\n",
    "submission = dict()\n",
    "for i in range(len(test_paths)):\n",
    "    fname, label = os.path.basename(test_paths[i]), id2name[classes[i]]\n",
    "    submission[fname] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:32:05.154527Z",
     "start_time": "2017-11-17T11:32:04.983371Z"
    },
    "_cell_guid": "9a95d147-3f4b-4386-8597-5fa60be43542",
    "_uuid": "bdf63bce43a0525a02ac18ca3f90aeba06ce6e99"
   },
   "outputs": [],
   "source": [
    "with open('subm/starter_submission{}_3xtta.csv'.format(exp_name), 'w') as fout:\n",
    "    fout.write('fname,label\\n')\n",
    "    for fname, label in submission.items():\n",
    "        fout.write('{},{}\\n'.format(fname, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "8bea6850-15c6-44e7-bdb4-9555ad196f85",
    "_uuid": "555315ef622793711ff5643928dac874c8cb0ed2",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
