{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:29.196238Z",
     "start_time": "2017-11-17T09:03:28.644004Z"
    },
    "_cell_guid": "679e0d3e-646d-4e96-9eb0-b362d8c6e51f",
    "_uuid": "0d05e5ce89af3e25d1c1fb244d021a1cfa1a058c"
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import array \n",
    "\n",
    "from pydub import AudioSegment\n",
    "import numba \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [x[0].split('/')[-1] for x in os.walk(\"data/train/audio/\")]\n",
    " \n",
    "\n",
    "\n",
    "exclusions = [\"\",\"_background_noise_\"]\n",
    "POSSIBLE_LABELS = [item for item in all_labels if item not in exclusions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:29.210749Z",
     "start_time": "2017-11-17T09:03:29.19832Z"
    },
    "_cell_guid": "8ab00801-08b9-44d3-a063-32e82dbf8f58",
    "_uuid": "53c19941676690454dd4b91109976b6c59cb7a40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "len(id2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'silence',\n",
       " 'left',\n",
       " 'eight',\n",
       " 'silence_many',\n",
       " 'no',\n",
       " 'tree',\n",
       " 'nine',\n",
       " 'bed',\n",
       " 'dog',\n",
       " '_background_noise_',\n",
       " 'house',\n",
       " 'cat',\n",
       " 'bird',\n",
       " 'four',\n",
       " 'zero',\n",
       " 'on',\n",
       " 'right',\n",
       " 'sheila',\n",
       " 'train',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'down',\n",
       " 'one',\n",
       " 'go',\n",
       " 'happy',\n",
       " 'two',\n",
       " 'yes',\n",
       " 'up',\n",
       " 'three',\n",
       " 'five',\n",
       " 'marvin',\n",
       " 'stop',\n",
       " 'wow',\n",
       " 'off']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:29.325023Z",
     "start_time": "2017-11-17T09:03:29.215137Z"
    },
    "_cell_guid": "8d7ebf53-700b-4c06-b5c2-ccf9ed5f27e0",
    "_uuid": "133424c750b26df37900f9cebcfd2f2fb803cb8b"
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    np.random.seed = 1\n",
    "    \n",
    "    \"\"\" Return 2 lists of tuples:\n",
    "    [(class_id, user_id, path), ...] for train\n",
    "    [(class_id, user_id, path), ...] for validation\n",
    "    \"\"\"\n",
    "    # Just a simple regexp for paths with three groups:\n",
    "    # prefix, label, user_id\n",
    "#     pattern = re.compile(\"(.+\\/)?(\\w+)\\/([^_]+)_.+wav\")\n",
    "    pattern  =  re.compile(\"(.+[\\/\\\\\\\\])?(\\w+)[\\/\\\\\\\\]([^_]+)_.+wav\")\n",
    "    all_files = glob(os.path.join(data_dir, 'train/audio/*/*wav'))\n",
    "\n",
    "    with open(os.path.join(data_dir, 'train/validation_list.txt'), 'r') as fin:\n",
    "        validation_files = fin.readlines()\n",
    "        \n",
    "    valset = set()\n",
    "    for entry in validation_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            valset.add(r.group(3))\n",
    "    \n",
    "    possible = set(POSSIBLE_LABELS)\n",
    "    \n",
    "    train, val, silent, unknown = [], [],[],[]\n",
    "    \n",
    "    for entry in all_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            label, uid = r.group(2), r.group(3)\n",
    "            \n",
    "            if label == '_background_noise_': #we've already split up noise files into 1 seg chunks under 'silence' folder\n",
    "                continue\n",
    "                \n",
    "#             if label not in possible:\n",
    "#                 label = 'unknown'\n",
    "\n",
    "            label_id = name2id[label]\n",
    "            sample = (label, label_id, uid, entry)\n",
    "            \n",
    "            if label == \"unknown\":\n",
    "                unknown.append(sample)\n",
    "            elif label == \"silence\":\n",
    "                silent.append(sample)\n",
    "                \n",
    "            elif uid in valset:    \n",
    "                val.append(sample)\n",
    "            else:\n",
    "                train.append(sample)\n",
    "\n",
    "    print('There are {} train and {} val samples'.format(len(train), len(val)))\n",
    "    \n",
    "    columns_list = ['label', 'label_id', 'user_id', 'wav_file']\n",
    "    \n",
    "\n",
    "    train_df = pd.DataFrame(train, columns = columns_list)\n",
    "    valid_df = pd.DataFrame(val, columns = columns_list)\n",
    "    silent_df = pd.DataFrame(silent, columns = columns_list)\n",
    "    unknown_df = pd.DataFrame(unknown, columns = columns_list)\n",
    "    \n",
    "    return train_df, valid_df, unknown_df, silent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:30.166379Z",
     "start_time": "2017-11-17T09:03:29.327228Z"
    },
    "_cell_guid": "27b5bff1-e5f8-409d-ab51-46e698342eb1",
    "_uuid": "ad204124a777e6677dcca8aac32d34de8e0cfc5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58321 train and 6798 val samples\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df, unknown_df, silent_df = load_data('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>wav_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>cb8f8307</td>\n",
       "      <td>./data/train/audio/left/cb8f8307_nohash_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>b7a0754f</td>\n",
       "      <td>./data/train/audio/left/b7a0754f_nohash_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>0132a06d</td>\n",
       "      <td>./data/train/audio/left/0132a06d_nohash_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>f92e49f3</td>\n",
       "      <td>./data/train/audio/left/f92e49f3_nohash_4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>88053e92</td>\n",
       "      <td>./data/train/audio/left/88053e92_nohash_1.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  label_id   user_id                                       wav_file\n",
       "0  left         1  cb8f8307  ./data/train/audio/left/cb8f8307_nohash_1.wav\n",
       "1  left         1  b7a0754f  ./data/train/audio/left/b7a0754f_nohash_2.wav\n",
       "2  left         1  0132a06d  ./data/train/audio/left/0132a06d_nohash_3.wav\n",
       "3  left         1  f92e49f3  ./data/train/audio/left/f92e49f3_nohash_4.wav\n",
       "4  left         1  88053e92  ./data/train/audio/left/88053e92_nohash_1.wav"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wav_scp(df,path):\n",
    "    with open(path+\"wav.scp\",\"w\") as f:\n",
    "        for i, row in df.iterrows(): #row.label+\"_\"\n",
    "            f.write(\"{} sox -t wav {} -r 16k -b 16 -t wav - remix - |\\n\".format( os.path.basename(row.wav_file)[:-4].replace(\"_\",\"-\"), \n",
    "                                                                              os.path.abspath(row.wav_file)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_wav_scp(train_df,\"data/kaldi/train/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create segments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.19722457734\n",
      "-1.38629436112\n",
      "-0.847297860387\n",
      "-0.405465108108\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "x = [0.1,0.2,0.3,0.4]\n",
    "s = 0\n",
    "for i in x:\n",
    "    print scipy.special.logit(i)\n",
    "    s += scipy.special.logit(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segments(df,path):\n",
    "    with open(path+\"segments\",\"w\") as f:\n",
    "        for i, row in df.iterrows():\n",
    "            process = subprocess.Popen(['ffmpeg',  '-i', row.wav_file], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "            stdout, stderr = process.communicate()\n",
    "            matches = re.search(r\"Duration:\\s{1}(?P<hours>\\d+?):(?P<minutes>\\d+?):(?P<seconds>\\d+\\.\\d+?),\", stdout, re.DOTALL).groupdict()\n",
    "            f.write(\"segm_{} {} 0 {}\\n\".format(os.path.basename(row.wav_file)[:-4],\n",
    "                                                  os.path.basename(row.wav_file)[:-4], \n",
    "                                                                              float(matches['seconds'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_segments(train_df,\"data/kaldi/train/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create utt2spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_utt2spk(df,path):\n",
    "    with open(path+\"utt2spk\",\"w\") as f:\n",
    "        for i, row in df.iterrows():\n",
    "            f.write(\"segm_{} {}\\n\".format(os.path.basename(row.wav_file)[:-4],row.label+'_'+row.user_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_utt2spk(train_df,\"data/kaldi/train/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text(df,path):\n",
    "    with open(path+\"text\",\"w\") as f:\n",
    "        for i, row in df.iterrows():\n",
    "            f.write(\"segm_{} {}\\n\".format(os.path.basename(row.wav_file)[:-4],row.label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_text(train_df,\"data/kaldi/train/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create validation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augment validation set with silence and unknown files, made with step=250 when generating silence files\n",
    "extra_data_size = int(valid_df.shape[0]*0.1)\n",
    "\n",
    "# unknown_val = unknown_df.sample(extra_data_size,random_state=1)\n",
    "# unknown_df = unknown_df[~unknown_df.index.isin(unknown_val.index.values)]\n",
    "\n",
    "silent_val = silent_df.sample(extra_data_size,random_state=1)\n",
    "silent_df = silent_df[~silent_df.index.isin(silent_val.index.values)]\n",
    "\n",
    "\n",
    "valid_df = pd.concat([valid_df,silent_val],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:30.448259Z",
     "start_time": "2017-11-17T09:03:30.299457Z"
    },
    "_cell_guid": "65ea1b22-6563-4879-a622-f45d8818e465",
    "_uuid": "4ebfe2201a69fa3bbfd83eff917645ea4a0a0d22"
   },
   "outputs": [],
   "source": [
    "# silence_files = train_df[train_df.label == 'silence']\n",
    "# train_df      = train_df[train_df.label != 'silence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 216 ms, sys: 96 ms, total: 312 ms\n",
      "Wall time: 2.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "silence_files_AS = [AudioSegment.from_wav(x) for x in silent_df.wav_file.values]\n",
    "\n",
    "filler = AudioSegment.silent(duration=1000, frame_rate = 16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one       2140\n",
       "two       2137\n",
       "stop      2134\n",
       "nine      2134\n",
       "yes       2116\n",
       "zero      2116\n",
       "five      2115\n",
       "up        2115\n",
       "seven     2114\n",
       "go        2112\n",
       "right     2111\n",
       "on        2110\n",
       "eight     2109\n",
       "three     2108\n",
       "six       2107\n",
       "left      2106\n",
       "no        2105\n",
       "off       2101\n",
       "down      2095\n",
       "four      2092\n",
       "marvin    1586\n",
       "wow       1579\n",
       "house     1577\n",
       "dog       1576\n",
       "bird      1569\n",
       "tree      1567\n",
       "cat       1565\n",
       "sheila    1558\n",
       "happy     1553\n",
       "bed       1516\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "silence    679\n",
       "four       280\n",
       "no         270\n",
       "down       264\n",
       "seven      263\n",
       "six        262\n",
       "yes        261\n",
       "go         260\n",
       "up         260\n",
       "zero       260\n",
       "on         257\n",
       "right      256\n",
       "off        256\n",
       "three      248\n",
       "left       247\n",
       "stop       246\n",
       "eight      243\n",
       "five       242\n",
       "two        236\n",
       "one        230\n",
       "nine       230\n",
       "bed        197\n",
       "happy      189\n",
       "sheila     176\n",
       "house      173\n",
       "dog        170\n",
       "cat        168\n",
       "wow        166\n",
       "tree       166\n",
       "bird       162\n",
       "marvin     160\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction, augmentation, caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def augment_wav(wav,pval=0.5):\n",
    "    sample_rate = 16000\n",
    "    L = 1000 #16000  # 1 sec\n",
    "    \n",
    "    #adjust speed, with 50% chance\n",
    "#     wav = speed_change(wav,1.+random.uniform(-1, 1)*0.05) if np.random.random() < pval else wav\n",
    "    \n",
    "    \n",
    "    #adjust volume\n",
    "    db_adjustment = random.uniform(-1, 1)*10\n",
    "    wav = wav + db_adjustment if np.random.random() < pval else wav\n",
    "     \n",
    "        \n",
    "    #fill to 1 second\n",
    "    wav = fill_to_1sec(wav)        \n",
    "        \n",
    "    #shift the audio by 10 ms\n",
    "    shift_length = 100\n",
    "    if np.random.random() < 0.5: #shift to left\n",
    "        wav = wav[:L-shift_length]+ AudioSegment.silent(shift_length,frame_rate=sample_rate)\n",
    "    else: #shift to right\n",
    "        wav = AudioSegment.silent(shift_length,frame_rate=sample_rate) + wav[shift_length:]\n",
    "        \n",
    "        \n",
    "        \n",
    "    #blend original file with background noise     \n",
    "    if np.random.random() < pval:\n",
    "        noise = random.choice(silence_files_AS)\n",
    "        db_delta = (wav.dBFS - noise.dBFS) -10.\n",
    "\n",
    "        if db_delta< 0: #reduce intensity of loud background; if it's too silent, leave it be\n",
    "            noise = noise  + db_delta\n",
    "        wav = wav.overlay(noise)\n",
    " \n",
    "    return wav\n",
    "\n",
    "\n",
    "\n",
    "def process_wav_file(record, reshape=False, augment=False,pval=0.5 ,output_format='logmel',n_mels=128 ):\n",
    "    \n",
    "    if type(record) == str: # test files\n",
    "        fname = record\n",
    "        label = \"test\"\n",
    "    else:    \n",
    "        fname  = record.wav_file\n",
    "        label = record.label\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    if \"raw_AS_wav\" in record: \n",
    "        wav = record.raw_AS_wav\n",
    "    else:\n",
    "        wav = AudioSegment.from_wav(fname.replace(\"\\\\\",\"/\"))\n",
    "        \n",
    "        \n",
    "    \n",
    "    if (not label in [\"silence\"]) and augment: #no augmentation for sample files \n",
    "        wav = augment_wav(wav,pval)\n",
    "\n",
    "    else: #make sure segment is 1 second\n",
    "        wav = fill_to_1sec(wav)\n",
    "\n",
    "        \n",
    "    samples = AS_to_raw(wav)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if output_format == \"logmel\":\n",
    "        output = log_mel(samples,reshape=reshape,n_mels=n_mels)\n",
    "        \n",
    "    elif output_format == \"mfcc\":\n",
    "        log_S = log_mel(samples,reshape=False,n_mels=n_mels)\n",
    "        mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=40) #hirese mfcc\n",
    "        delta1 = librosa.feature.delta(mfcc, order=1)#hirese mfcc\n",
    "        delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "        output = np.stack([mfcc,delta1,delta2])\n",
    "        \n",
    "    elif  output_format == \"cqt\":   \n",
    "        output = librosa.cqt(samples, sr=16000)\n",
    "    else:\n",
    "        output = samples\n",
    "    \n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load existing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.16 s, sys: 6.71 s, total: 11.9 s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "# %%time \n",
    "\n",
    "# train_df = pickle.load( open(\"cache/train_df_waug.pik\",\"rb\"))\n",
    "# valid_df = pickle.load( open(\"cache/valid_df.pik\",\"rb\"))\n",
    "# silent_df = pickle.load(open(\"cache/silent_df.pik\",\"rb\"))\n",
    "# unknown_df = pickle.load(open(\"cache/unknown_df_waug.pik\",\"rb\"))\n",
    "# test_df =  pickle.load(open(\"cache/test_df.pik\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore augmentations \n",
    "# train_df = train_df.iloc[:train_df.shape[0]/5]\n",
    "# unknown_df = unknown_df.iloc[:unknown_df.shape[0]/5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( train_df,open(\"cache/train_df.pik\",\"wb\"),protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(valid_df, open(\"cache/valid_df.pik\",\"wb\"),protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(silent_df, open(\"cache/silent_df.pik\",\"wb\"),protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(unknown_df, open(\"cache/unknown_df.pik\",\"wb\"),protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract logmel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 43s, sys: 14 s, total: 2min 57s\n",
      "Wall time: 1min 33s\n",
      "CPU times: user 17min 56s, sys: 1min 30s, total: 19min 27s\n",
      "Wall time: 10min 11s\n"
     ]
    }
   ],
   "source": [
    "%time valid_df[\"raw\"]  = valid_df.wav_file.apply(lambda x : process_wav_file(x,augment=False,n_mels=256))\n",
    "%time train_df[\"raw\"]  = train_df.wav_file.apply(lambda x : process_wav_file(x,augment=False,n_mels=256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_df,open(\"cache/train_df_all_labels.pik\",\"wb\"),protocol=pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(valid_df,open(\"cache/valid_df_all_labels.pik\",\"wb\"),protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# pickle.dump(silent_df, open(\"cache/silent_df_all_labels.pik\",\"wb\"),protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# pickle.dump(unknown_df, open(\"cache/unknown_df.pik\",\"wb\"),protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### precompute augmentations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precomputing augs for faster neural net training\n",
    "def precompute_augmentations(df,num_repeats=4):\n",
    "    \n",
    "    df_aug= pd.concat([df]*num_repeats)\n",
    "    df_aug['raw'] = df_aug.wav_file.apply(lambda x :  process_wav_file(x,augment=True,n_mels=128))\n",
    "    df = pd.concat([df, df_aug])\n",
    "    \n",
    "    return df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50min 24s, sys: 54.1 s, total: 51min 18s\n",
      "Wall time: 26min 1s\n"
     ]
    }
   ],
   "source": [
    "%time train_df = precompute_augmentations(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( train_df,open(\"cache/train_df_all_labels.pik\",\"wb\"),protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
