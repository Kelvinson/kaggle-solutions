{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:29.196238Z",
     "start_time": "2017-11-17T09:03:28.644004Z"
    },
    "_cell_guid": "679e0d3e-646d-4e96-9eb0-b362d8c6e51f",
    "_uuid": "0d05e5ce89af3e25d1c1fb244d021a1cfa1a058c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import array \n",
    "\n",
    "from pydub import AudioSegment\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Conv2D, Flatten, MaxPooling2D, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPool2D, concatenate, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Input, GRU, RepeatVector, BatchNormalization, TimeDistributed, Conv1D\n",
    "from keras import backend as K\n",
    "from keras.layers import  Conv2D, MaxPooling2D, UpSampling2D, Lambda, Reshape\n",
    "\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:29.210749Z",
     "start_time": "2017-11-17T09:03:29.19832Z"
    },
    "_cell_guid": "8ab00801-08b9-44d3-a063-32e82dbf8f58",
    "_uuid": "53c19941676690454dd4b91109976b6c59cb7a40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "len(id2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.58 s, sys: 5.25 s, total: 10.8 s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "train_df = pickle.load( open(\"cache/train_df_256.pik\",\"rb\"))\n",
    "valid_df = pickle.load( open(\"cache/valid_df_256.pik\",\"rb\"))\n",
    "silent_df = pickle.load(open(\"cache/silent_df_256.pik\",\"rb\"))\n",
    "unknown_df = pickle.load(open(\"cache/unknown_df_256.pik\",\"rb\"))\n",
    "# test_df =  pickle.load(open(\"cache/test_df.pik\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:32.519795Z",
     "start_time": "2017-11-17T09:03:32.483881Z"
    },
    "_cell_guid": "144c6e60-8a83-437d-8b8a-ea065af90923",
    "_uuid": "22e0e6c718171167089fb6df36d3dc43a1029992"
   },
   "outputs": [],
   "source": [
    "#no augmentation since the auto encoder has already seen all the train AND test files \n",
    "\n",
    "def train_generator(train_batch_size):\n",
    "    while True:\n",
    "        \n",
    "        this_train = train_df.groupby('label_id').apply(lambda x: x.sample(n = 2000))\n",
    "        extra_data_size = int(this_train.shape[0]* 0.1)\n",
    "        this_train = pd.concat([silent_df.sample(extra_data_size),\n",
    "                                this_train,\n",
    "                                unknown_df.sample(extra_data_size*4)],axis=0 )\n",
    "        \n",
    "        this_train.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "        shuffled_ids = random.sample(range(this_train.shape[0]), this_train.shape[0])\n",
    "        \n",
    "        for start in range(0, len(shuffled_ids), train_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            end = min(start + train_batch_size, len(shuffled_ids))\n",
    "            i_train_batch = shuffled_ids[start:end]\n",
    "            for i in i_train_batch:\n",
    "                x_batch.append(this_train.loc[i,'raw'].T)\n",
    "#                 x_batch.append(process_wav_file(this_train.iloc[i], augment=True).T)\n",
    "\n",
    "                y_batch.append(this_train.label_id.values[i])\n",
    "                \n",
    "            x_batch = 1.- np.array(x_batch)/-80.\n",
    "            y_batch = to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            \n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 72 ms, sys: 8 ms, total: 80 ms\n",
      "Wall time: 95.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time t = next(train_generator(256))[0][0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:03:32.624289Z",
     "start_time": "2017-11-17T09:03:32.521828Z"
    },
    "_cell_guid": "59a13393-9bc3-4b27-abe2-9c78b3c32ead",
    "_uuid": "6f9a8fbf6e352b1c77b9c22dddf1c5d69382bd5b"
   },
   "outputs": [],
   "source": [
    "def valid_generator(val_batch_size):\n",
    "    while True:\n",
    "        ids = list(range(valid_df.shape[0]))\n",
    "        for start in range(0, len(ids), val_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + val_batch_size, len(ids))\n",
    "            i_val_batch = ids[start:end]\n",
    "            for i in i_val_batch:\n",
    "                x_batch.append(valid_df.loc[i,'raw'].T)\n",
    "                y_batch.append(valid_df.label_id.values[i])\n",
    "\n",
    "            x_batch = 1.- np.array(x_batch)/-80.\n",
    "            y_batch = to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a common practice is to choose a filter size in time which spans 2/3 o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps, input_dim , latent_dim = 32,256, 128\n",
    "\n",
    "input_img = Input(shape=(timesteps, input_dim))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Reshape((timesteps, input_dim,1))(input_img)\n",
    "\n",
    "\n",
    "#original\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (5, 5), activation='relu', padding='same')(x)\n",
    "x = Conv2D(64, (5, 5), activation='relu', padding='same')(x)\n",
    "\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "encoded = MaxPooling2D((2, 2), padding='same', name=\"latent\")(x)\n",
    "\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "\n",
    "x = Conv2D(64, (5, 5), activation='relu', padding='same')(x)\n",
    "x = Conv2D(64, (5, 5), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "decoded  = Reshape((timesteps, input_dim))(decoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights(\"./weights/ae_wtest_conv_rmse_highres.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in autoencoder.layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = BatchNormalization()(autoencoder.get_layer(\"latent\").output)\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p/2)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p/2)(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p/2)(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Dropout(p/2)(x)\n",
    "\n",
    "x_max = GlobalMaxPool2D()(x)\n",
    "x_avg = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x =  concatenate([x_max,x_avg])\n",
    "\n",
    "x = Dense(128, activation = 'relu')(x) #\n",
    "x = Dropout(p)(x)\n",
    "\n",
    "\n",
    "x = Dense(len(POSSIBLE_LABELS), activation = 'softmax', name='targets')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Model(inputs=[input_img], outputs = x)\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 32, 256)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)              (None, 32, 256, 1)    0           input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 32, 256, 1)    4           reshape_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 32, 256, 64)   1664        batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 32, 256, 64)   102464      conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 16, 128, 64)   0           conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 16, 128, 32)   18464       max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 16, 128, 32)   9248        conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "latent (MaxPooling2D)            (None, 8, 64, 32)     0           conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 8, 64, 32)     128         latent[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, 8, 64, 64)     18496       batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 8, 64, 64)     0           conv2d_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)               (None, 8, 64, 64)     36928       dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 8, 64, 64)     0           conv2d_41[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 8, 64, 64)     256         dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)               (None, 8, 64, 128)    73856       batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 8, 64, 128)    0           conv2d_42[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)               (None, 8, 64, 128)    147584      dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 8, 64, 128)    0           conv2d_43[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalMa (None, 128)           0           dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 128)           0           dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 256)           0           global_max_pooling2d_1[0][0]     \n",
      "                                                                   global_average_pooling2d_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           32896       concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 128)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "targets (Dense)                  (None, 12)            1548        dropout_17[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 443,536\n",
      "Trainable params: 311,500\n",
      "Non-trainable params: 132,036\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 14/100\n",
    "300/300 [==============================] - 214s - loss: 0.7612 - acc: 0.7370 - val_loss: 1.0481 - val_acc: 0.6508\n",
    "\n",
    "\n",
    "\n",
    "Epoch 31/100\n",
    "350/350 [==============================] - 227s - loss: 0.4294 - acc: 0.8518 - val_loss: 0.9436 - val_acc: 0.7179\n",
    "Epoch 32/100\n",
    "\n",
    "\n",
    "\n",
    "Epoch 00058: reducing learning rate to 1.00000006569e-06.\n",
    "329/329 [==============================] - 191s - loss: 0.7292 - acc: 0.7521 - val_loss: 0.7132 - val_acc: 0.8770\n",
    "\n",
    "\n",
    "with ae, p=0.\n",
    "Epoch 28/100\n",
    "329/329 [==============================] - 7s - loss: 0.3312 - acc: 0.8829 - val_loss: 0.4124 - val_acc: 0.8579\n",
    "\n",
    "with p=0.4 and /2 for convs \n",
    "Epoch 28/100\n",
    "329/329 [==============================] - 7s - loss: 0.5534 - acc: 0.8056 - val_loss: 0.5074 - val_acc: 0.8312\n",
    "\n",
    "with p=0.2 and /2\n",
    "Epoch 00035: reducing learning rate to 1.0000000475e-05.\n",
    "329/329 [==============================] - 7s - loss: 0.2414 - acc: 0.9137 - val_loss: 0.3686 - val_acc: 0.8811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395.71875"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0]*(1.2)//64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"aebase_256_noaug_drp3_frozen\"\n",
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=5,\n",
    "                           verbose=1),\n",
    "             \n",
    "             ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               epsilon=0.01,\n",
    "                              min_lr=1e-4),\n",
    "             ModelCheckpoint(monitor='val_loss',\n",
    "                             filepath='weights/{}.hdf5'.format(exp_name),\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='min')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:42:31.48233Z",
     "start_time": "2017-11-17T09:03:33.355603Z"
    },
    "_cell_guid": "5f3d1b09-500f-410e-820a-8eaab24b6ebb",
    "_uuid": "528ec66a0a6caca952273ab916e609625839b19e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "461/461 [==============================] - 60s - loss: 1.7964 - acc: 0.3911 - val_loss: 2.1263 - val_acc: 0.2809\n",
      "Epoch 2/100\n",
      "461/461 [==============================] - 57s - loss: 1.1111 - acc: 0.6096 - val_loss: 0.8016 - val_acc: 0.7195\n",
      "Epoch 3/100\n",
      "461/461 [==============================] - 55s - loss: 0.8245 - acc: 0.7109 - val_loss: 0.7039 - val_acc: 0.7582\n",
      "Epoch 4/100\n",
      "461/461 [==============================] - 55s - loss: 0.6683 - acc: 0.7696 - val_loss: 0.5869 - val_acc: 0.7929\n",
      "Epoch 5/100\n",
      "461/461 [==============================] - 55s - loss: 0.5943 - acc: 0.7962 - val_loss: 0.5245 - val_acc: 0.8196\n",
      "Epoch 6/100\n",
      "461/461 [==============================] - 55s - loss: 0.5155 - acc: 0.8234 - val_loss: 0.4890 - val_acc: 0.8335\n",
      "Epoch 7/100\n",
      "461/461 [==============================] - 55s - loss: 0.4830 - acc: 0.8315 - val_loss: 0.5239 - val_acc: 0.8216\n",
      "Epoch 8/100\n",
      "461/461 [==============================] - 55s - loss: 0.4459 - acc: 0.8469 - val_loss: 0.4931 - val_acc: 0.8226\n",
      "Epoch 9/100\n",
      "461/461 [==============================] - 55s - loss: 0.4246 - acc: 0.8548 - val_loss: 0.3786 - val_acc: 0.8705\n",
      "Epoch 10/100\n",
      "461/461 [==============================] - 55s - loss: 0.3964 - acc: 0.8653 - val_loss: 0.3766 - val_acc: 0.8708\n",
      "Epoch 11/100\n",
      "461/461 [==============================] - 55s - loss: 0.3775 - acc: 0.8721 - val_loss: 0.3751 - val_acc: 0.8702\n",
      "Epoch 12/100\n",
      "461/461 [==============================] - 55s - loss: 0.3605 - acc: 0.8765 - val_loss: 0.3640 - val_acc: 0.8791\n",
      "Epoch 13/100\n",
      "461/461 [==============================] - 55s - loss: 0.3461 - acc: 0.8836 - val_loss: 0.3642 - val_acc: 0.8745\n",
      "Epoch 14/100\n",
      "461/461 [==============================] - 55s - loss: 0.3301 - acc: 0.8905 - val_loss: 0.3500 - val_acc: 0.8768\n",
      "Epoch 15/100\n",
      "461/461 [==============================] - 55s - loss: 0.3239 - acc: 0.8909 - val_loss: 0.3731 - val_acc: 0.8821\n",
      "Epoch 16/100\n",
      "461/461 [==============================] - 55s - loss: 0.3184 - acc: 0.8939 - val_loss: 0.3912 - val_acc: 0.8672\n",
      "Epoch 17/100\n",
      "461/461 [==============================] - 55s - loss: 0.3119 - acc: 0.8952 - val_loss: 0.3513 - val_acc: 0.8807\n",
      "Epoch 18/100\n",
      "461/461 [==============================] - 55s - loss: 0.2968 - acc: 0.8970 - val_loss: 0.3347 - val_acc: 0.8887\n",
      "Epoch 19/100\n",
      "461/461 [==============================] - 55s - loss: 0.2918 - acc: 0.9007 - val_loss: 0.3435 - val_acc: 0.8870\n",
      "Epoch 20/100\n",
      "461/461 [==============================] - 55s - loss: 0.2788 - acc: 0.9057 - val_loss: 0.3314 - val_acc: 0.8923\n",
      "Epoch 21/100\n",
      "461/461 [==============================] - 55s - loss: 0.2734 - acc: 0.9086 - val_loss: 0.3401 - val_acc: 0.8870\n",
      "Epoch 22/100\n",
      "460/461 [============================>.] - ETA: 0s - loss: 0.2659 - acc: 0.9091\n",
      "Epoch 00021: reducing learning rate to 0.00010000000475.\n",
      "461/461 [==============================] - 55s - loss: 0.2656 - acc: 0.9092 - val_loss: 0.3468 - val_acc: 0.8877\n",
      "Epoch 23/100\n",
      "461/461 [==============================] - 55s - loss: 0.2122 - acc: 0.9296 - val_loss: 0.3140 - val_acc: 0.9006\n",
      "Epoch 24/100\n",
      "461/461 [==============================] - 55s - loss: 0.1900 - acc: 0.9353 - val_loss: 0.3004 - val_acc: 0.9029\n",
      "Epoch 25/100\n",
      " 47/461 [==>...........................] - ETA: 47s - loss: 0.1959 - acc: 0.9362"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-877cce601fd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                               validation_steps=int(np.ceil(valid_df.shape[0]/batch_size)))\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "history = model.fit_generator(generator=train_generator(batch_size),\n",
    "                              steps_per_epoch=train_df.shape[0]*(1.4)//batch_size,\n",
    "                              epochs=100,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=valid_generator(batch_size),\n",
    "                              validation_steps=int(np.ceil(valid_df.shape[0]/batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.layers:\n",
    "    l.trainable = True\n",
    "    \n",
    "    \n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:24:59.198625Z",
     "start_time": "2017-11-17T10:24:59.081762Z"
    },
    "_cell_guid": "0c99ba3b-e8ca-40cb-8d29-2b0e89a385c7",
    "_uuid": "429139ca4f71487c6cfe3e8dfbb6a659eb9bb9c8"
   },
   "outputs": [],
   "source": [
    "model.load_weights('./weights/{}.hdf5'.format(exp_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"aebase_256_noaug_drp3_finetune\"\n",
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=5,\n",
    "                           verbose=1),\n",
    "             \n",
    "             ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=3,\n",
    "                               verbose=1,\n",
    "                               epsilon=0.01,\n",
    "                              min_lr=1e-6),\n",
    "             ModelCheckpoint(monitor='val_loss',\n",
    "                             filepath='weights/{}.hdf5'.format(exp_name),\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "494/494 [==============================] - 122s - loss: 0.1890 - acc: 0.9360 - val_loss: 0.3053 - val_acc: 0.9030\n",
      "Epoch 2/100\n",
      "494/494 [==============================] - 119s - loss: 0.1825 - acc: 0.9371 - val_loss: 0.2947 - val_acc: 0.9092\n",
      "Epoch 3/100\n",
      "494/494 [==============================] - 119s - loss: 0.1743 - acc: 0.9412 - val_loss: 0.2877 - val_acc: 0.9065\n",
      "Epoch 4/100\n",
      "494/494 [==============================] - 119s - loss: 0.1689 - acc: 0.9435 - val_loss: 0.2846 - val_acc: 0.9085\n",
      "Epoch 5/100\n",
      "494/494 [==============================] - 119s - loss: 0.1650 - acc: 0.9449 - val_loss: 0.3172 - val_acc: 0.9019\n",
      "Epoch 6/100\n",
      " 51/494 [==>...........................] - ETA: 104s - loss: 0.1618 - acc: 0.9470"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-7c4e8a2378b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                               validation_steps=int(np.ceil(valid_df.shape[0]/batch_size)))\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "history = model.fit_generator(generator=train_generator(batch_size),\n",
    "                              steps_per_epoch=train_df.shape[0]*(1.5)//batch_size,\n",
    "                              epochs=100,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=valid_generator(batch_size),\n",
    "                              validation_steps=int(np.ceil(valid_df.shape[0]/batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./weights/{}.hdf5'.format(exp_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### valid evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict_generator(valid_generator(64),steps=int(np.ceil(valid_df.shape[0]/64.)))\n",
    "val_preds = np.argmax(val_preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3091, 12)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = oe.fit_transform(valid_df.label_id.values.reshape(-1, 1)).todense()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = oe.transform(val_preds.reshape(-1, 1)).todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.95      0.94      0.95       261\n",
      "         no       0.82      0.85      0.84       270\n",
      "         up       0.89      0.91      0.90       260\n",
      "       down       0.92      0.88      0.90       264\n",
      "       left       0.92      0.90      0.91       247\n",
      "      right       0.97      0.86      0.91       256\n",
      "         on       0.96      0.86      0.91       257\n",
      "        off       0.92      0.88      0.90       256\n",
      "       stop       0.96      0.87      0.91       246\n",
      "         go       0.86      0.76      0.81       260\n",
      "    silence       0.98      0.99      0.98       257\n",
      "    unknown       0.62      0.92      0.74       257\n",
      "\n",
      "avg / total       0.90      0.89      0.89      3091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        yes       0.93      0.95      0.94       261\n",
      "         no       0.84      0.81      0.82       270\n",
      "         up       0.88      0.90      0.89       260\n",
      "       down       0.83      0.91      0.87       264\n",
      "       left       0.92      0.88      0.90       247\n",
      "      right       0.93      0.89      0.91       256\n",
      "         on       0.89      0.89      0.89       257\n",
      "        off       0.93      0.86      0.89       256\n",
      "       stop       0.89      0.89      0.89       246\n",
      "         go       0.81      0.78      0.79       260\n",
      "    silence       1.00      1.00      1.00       257\n",
      "    unknown       0.71      0.78      0.74       257\n",
      "\n",
      "avg / total       0.88      0.88      0.88      3091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,val_preds,target_names=POSSIBLE_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:28:14.451612Z",
     "start_time": "2017-11-17T10:28:13.307142Z"
    },
    "_cell_guid": "72f27090-c0d1-4d0b-8027-34c915429a79",
    "_uuid": "1007977fccadecdae582ec5d8d52dd3c4c3010aa"
   },
   "outputs": [],
   "source": [
    "test_paths = glob(os.path.join('./data/', 'test/audio/*wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158538"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pickle.load( open(\"cache/test_df.pik\",\"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:32:14.882322Z",
     "start_time": "2017-11-17T10:32:14.863617Z"
    },
    "_cell_guid": "c6d9b369-9979-4bcd-8540-4653e6544f84",
    "_uuid": "6a0bb3c22b7b5c43db0ec5673333ab3de8f08724"
   },
   "outputs": [],
   "source": [
    "def test_generator(test_batch_size,augment=False):\n",
    "    while True:\n",
    "        ids = list(range(test_df.shape[0]))\n",
    "        \n",
    "        for start in range(0, len(ids), test_batch_size):\n",
    "            x_batch = []\n",
    "            end = min(start + test_batch_size, len(ids))\n",
    "            i_test_batch = ids[start:end]\n",
    "#             this_paths = test_paths[start:end]\n",
    "#             for x in this_paths:\n",
    "            for i in i_test_batch:\n",
    "            #WATCHOUT > NO AUG\n",
    "#                 x_batch.append(process_wav_file(x).T) #,reshape=False,augment=augment,pval=0.5))\n",
    "                x_batch.append(test_df.loc[i,'raw'].T)\n",
    "\n",
    "            x_batch = np.array(x_batch)\n",
    "            x_batch = 1.- np.array(x_batch)/-80.\n",
    "            \n",
    "            yield x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_generator(val_batch_size):\n",
    "    while True:\n",
    "        ids = list(range(valid_df.shape[0]))\n",
    "        for start in range(0, len(ids), val_batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + val_batch_size, len(ids))\n",
    "            i_val_batch = ids[start:end]\n",
    "            for i in i_val_batch:\n",
    "                x_batch.append(valid_df.loc[i,'raw'].T)\n",
    "                y_batch.append(valid_df.label_id.values[i])\n",
    "\n",
    "            x_batch = 1.- np.array(x_batch)/-80.\n",
    "            y_batch = to_categorical(y_batch, num_classes = len(POSSIBLE_LABELS))\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-17T10:32:45.947Z"
    },
    "_cell_guid": "1fb8aed4-de12-43c5-84bf-b803e3d640fa",
    "_uuid": "631a38cb0013e5772f6987854145ad76ecf6c430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/620 [==============================] - 34s    \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(test_generator(256,augment=False), int(np.ceil(len(test_paths)/256.)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cache/predictions_{}.npy\".format(exp_name),predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158538, 12)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pyramid_noaug = np.load('cache/predictions_pyramid_noaug.npy')\n",
    "predictions_model_with_ae_base_drp2_1 = np.load('cache/predictions_model_with_ae_base_drp2_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.mean([predictions,predictions_pyramid_noaug,predictions_model_with_ae_base_drp2_1], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477/2478 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# num_aug = 2 \n",
    "# for i in range(num_aug):\n",
    "#     predictions +=  model.predict_generator(test_generator(64,augment=True), int(np.ceil(len(test_paths)/64.)), verbose=1)\n",
    "    \n",
    "\n",
    "# predictions = predictions/(num_aug + 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:30:44.236246Z",
     "start_time": "2017-11-17T11:30:44.21858Z"
    },
    "_cell_guid": "b1cdab5c-9816-4690-87d8-de2c97cf0e7d",
    "_uuid": "24eb7e512eace4567494e0a8e356a826f4283c4d"
   },
   "outputs": [],
   "source": [
    "classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((158538,), 158538)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.shape, len(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 12769.,   6288.,   7058.,   6322.,   6488.,   7524.,   5727.,\n",
       "          6044.,   7517.,  92801.]),\n",
       " array([  0. ,   1.1,   2.2,   3.3,   4.4,   5.5,   6.6,   7.7,   8.8,\n",
       "          9.9,  11. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDpKkjnGQJHX+F8MQE0BKM3oUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f61b65e2a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(classes,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 12482.,   6260.,   6059.,   6403.,   5591.,   7249.,   6102.,\n",
       "          6070.,   7064.,  95258.]),\n",
       " array([  0. ,   1.1,   2.2,   3.3,   4.4,   5.5,   6.6,   7.7,   8.8,\n",
       "          9.9,  11. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVI3Q0OS1M3QkCR1MzQkSd3+H69CtA3A8hTeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f621de23090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(classes,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 13909.,   6442.,  10015.,   6507.,   8567.,   8867.,   5738.,\n",
       "          6198.,   9714.,  82581.]),\n",
       " array([  0. ,   1.1,   2.2,   3.3,   4.4,   5.5,   6.6,   7.7,   8.8,\n",
       "          9.9,  11. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fed01ff2e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(classes,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 14037.,   7124.,  12571.,   6486.,  10360.,  11502.,   6549.,\n",
       "          6624.,  10275.,  73010.]),\n",
       " array([  0. ,   1.1,   2.2,   3.3,   4.4,   5.5,   6.6,   7.7,   8.8,\n",
       "          9.9,  11. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1cad211550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(classes,bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:31:11.212517Z",
     "start_time": "2017-11-17T11:31:10.786357Z"
    },
    "_cell_guid": "1da523cf-fdbf-4ab1-9300-0147155aa247",
    "_uuid": "f25d4e626202aa115bd0460f4de8d07f9727c83e"
   },
   "outputs": [],
   "source": [
    "### last batch will contain padding, so remove duplicates\n",
    "submission = dict()\n",
    "for i in range(len(test_paths)):\n",
    "    fname, label = os.path.basename(test_paths[i]), id2name[classes[i]]\n",
    "    submission[fname] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:32:05.154527Z",
     "start_time": "2017-11-17T11:32:04.983371Z"
    },
    "_cell_guid": "9a95d147-3f4b-4386-8597-5fa60be43542",
    "_uuid": "bdf63bce43a0525a02ac18ca3f90aeba06ce6e99"
   },
   "outputs": [],
   "source": [
    "with open('subm/submission_{}.csv'.format(exp_name), 'w') as fout:\n",
    "    fout.write('fname,label\\n')\n",
    "    for fname, label in submission.items():\n",
    "        fout.write('{},{}\\n'.format(fname, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "_cell_guid": "8bea6850-15c6-44e7-bdb4-9555ad196f85",
    "_uuid": "555315ef622793711ff5643928dac874c8cb0ed2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='subm/submission_aebase_aug_drp3_finetune_blend.csv' target='_blank'>subm/submission_aebase_aug_drp3_finetune_blend.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/keyword_spotting/subm/submission_aebase_aug_drp3_finetune_blend.csv"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.lib.display import FileLink\n",
    "\n",
    "FileLink('subm/submission_{}.csv'.format(exp_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
